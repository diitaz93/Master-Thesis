{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECAGON Training\n",
    "Test notebook for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psutil & time BEGIN\n",
    "start = time.time() #in seconds\n",
    "pid = os.getpid()\n",
    "ps= psutil.Process(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data from previous computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input file. Goes as parameter in script\n",
    "in_file = './data/data_structures/DECAGON/DECAGON_toy_DSE_9688_BDM_genes_16266_drugs_627_se_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = in_file.split('_')\n",
    "DSE = False\n",
    "if 'DSE' in words: DSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se_mono_name2idx Imported successfully\n",
      "gene2idx Imported successfully\n",
      "nonzero_feat Imported successfully\n",
      "edge_type2dim Imported successfully\n",
      "adj_mats_orig Imported successfully\n",
      "edge_type2decoder Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "degrees Imported successfully\n",
      "edge_types Imported successfully\n",
      "num_edge_types Imported successfully\n",
      "num_feat Imported successfully\n",
      "feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "with open(in_file, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16266 627 6 9688 True\n"
     ]
    }
   ],
   "source": [
    "n_genes = len(gene2idx)\n",
    "n_drugs = len(drug2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)\n",
    "print(n_genes,n_drugs,n_se_combo,n_se_mono,DSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "def accuracy(edges_pos,edges_neg,pred):\n",
    "    \"\"\"Gives the accuracy of the model given a set of positive and negative entries of \n",
    "    a matrix, and the probability scores of each entry. The method uses np.round to turn\n",
    "    probabilities into labels 0 or 1 and feed them to the accuracy_score method of sci-kit\n",
    "    learn.\n",
    "    \"\"\"\n",
    "    pos_labels = np.ones(np.shape(edges_pos)[0])\n",
    "    neg_labels = np.zeros(np.shape(edges_neg)[0])\n",
    "    labels = np.hstack((pos_labels,neg_labels))\n",
    "    pos_preds=[]\n",
    "    scores = np.round(sigmoid(pred))\n",
    "    for i,j in edges_pos:\n",
    "        pos_preds.append(scores[i,j])\n",
    "    neg_preds=[]\n",
    "    for i,j in edges_neg:\n",
    "        neg_preds.append(scores[i,j])\n",
    "    predictions=np.hstack((pos_preds,neg_preds))\n",
    "    return metrics.accuracy_score(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "\n",
    "    # Predict on set of edges\n",
    "    preds = []\n",
    "    #actual = []\n",
    "    #predicted = []\n",
    "    edge_ind = 0\n",
    "    for u, v in edges_pos[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 1, 'Problem 1'\n",
    "\n",
    "        #actual.append(edge_ind)\n",
    "        #predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "\n",
    "        #predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    #predicted = list(zip(*sorted(predicted, reverse=True, key=itemgetter(0))))[1]\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    #apk_sc = rank_metrics.apk(actual, predicted, k=50)\n",
    "    acc = metrics.accuracy_score(labels_all, np.round(preds_all))\n",
    "\n",
    "    return roc_sc, aupr_sc, acc\n",
    "\n",
    "\n",
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_size = 0.15\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 10, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 128, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')\n",
    "# Important -- Do not evaluate/print validation performance every iteration as it can take\n",
    "# substantial amount of time\n",
    "#PRINT_PROGRESS_EVERY = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHETAZO!! Soluciona el bug de Jupyter con tensorflow que proporciona un flag -f\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create minibatch iterator, model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 1, 0)\n",
      "Constructing test edges= 0000/1997\n",
      "Constructing test edges= 1000/1997\n",
      "Constructing val edges= 0000/1997\n",
      "Constructing val edges= 1000/1997\n",
      "Constructing train edges= 0000/9322\n",
      "Constructing train edges= 1000/9322\n",
      "Constructing train edges= 2000/9322\n",
      "Constructing train edges= 3000/9322\n",
      "Constructing train edges= 4000/9322\n",
      "Constructing train edges= 5000/9322\n",
      "Constructing train edges= 6000/9322\n",
      "Constructing train edges= 7000/9322\n",
      "Constructing train edges= 8000/9322\n",
      "Constructing train edges= 9000/9322\n",
      "Train edges= 9322\n",
      "Val edges= 1997\n",
      "Test edges= 1997\n",
      "Minibatch edge type: (1, 0, 0)\n",
      "Constructing test edges= 0000/1997\n",
      "Constructing test edges= 1000/1997\n",
      "Constructing val edges= 0000/1997\n",
      "Constructing val edges= 1000/1997\n",
      "Constructing train edges= 0000/9322\n",
      "Constructing train edges= 1000/9322\n",
      "Constructing train edges= 2000/9322\n",
      "Constructing train edges= 3000/9322\n",
      "Constructing train edges= 4000/9322\n",
      "Constructing train edges= 4000/9322\n",
      "Constructing train edges= 5000/9322\n",
      "Constructing train edges= 6000/9322\n",
      "Constructing train edges= 7000/9322\n",
      "Constructing train edges= 7000/9322\n",
      "Constructing train edges= 8000/9322\n",
      "Constructing train edges= 9000/9322\n",
      "Train edges= 9322\n",
      "Val edges= 1997\n",
      "Test edges= 1997\n",
      "Minibatch edge type: (0, 0, 0)\n",
      "Constructing test edges= 0000/1952\n",
      "Constructing test edges= 1000/1952\n",
      "Constructing val edges= 0000/1952\n",
      "Constructing val edges= 0000/1952\n",
      "Constructing val edges= 1000/1952\n",
      "Constructing train edges= 0000/9110\n",
      "Constructing train edges= 1000/9110\n",
      "Constructing train edges= 2000/9110\n",
      "Constructing train edges= 3000/9110\n",
      "Constructing train edges= 3000/9110\n",
      "Constructing train edges= 4000/9110\n",
      "Constructing train edges= 4000/9110\n",
      "Constructing train edges= 5000/9110\n",
      "Constructing train edges= 6000/9110\n",
      "Constructing train edges= 6000/9110\n",
      "Constructing train edges= 7000/9110\n",
      "Constructing train edges= 8000/9110\n",
      "Constructing train edges= 8000/9110\n",
      "Constructing train edges= 9000/9110\n",
      "Train edges= 9110\n",
      "Val edges= 1952\n",
      "Test edges= 1952\n",
      "Minibatch edge type: (0, 0, 1)\n",
      "Constructing test edges= 0000/1952\n",
      "Constructing test edges= 1000/1952\n",
      "Constructing val edges= 0000/1952\n",
      "Constructing val edges= 1000/1952\n",
      "Constructing train edges= 0000/9110\n",
      "Constructing train edges= 1000/9110\n",
      "Constructing train edges= 2000/9110\n",
      "Constructing train edges= 3000/9110\n",
      "Constructing train edges= 4000/9110\n",
      "Constructing train edges= 5000/9110\n",
      "Constructing train edges= 5000/9110\n",
      "Constructing train edges= 6000/9110\n",
      "Constructing train edges= 6000/9110\n",
      "Constructing train edges= 6000/9110\n",
      "Constructing train edges= 7000/9110\n",
      "Constructing train edges= 8000/9110\n",
      "Constructing train edges= 9000/9110\n",
      "Train edges= 9110\n",
      "Val edges= 1952\n",
      "Test edges= 1952\n",
      "Minibatch edge type: (1, 1, 0)\n",
      "Constructing test edges= 0000/1150\n",
      "Constructing test edges= 1000/1150\n",
      "Constructing val edges= 0000/1150\n",
      "Constructing val edges= 1000/1150\n",
      "Constructing train edges= 0000/5372\n",
      "Constructing train edges= 1000/5372\n",
      "Constructing train edges= 2000/5372\n",
      "Constructing train edges= 3000/5372\n",
      "Constructing train edges= 4000/5372\n",
      "Constructing train edges= 5000/5372\n",
      "Train edges= 5372\n",
      "Val edges= 1150\n",
      "Test edges= 1150\n",
      "Minibatch edge type: (1, 1, 1)\n",
      "Constructing test edges= 0000/0416\n",
      "Constructing val edges= 0000/0416\n",
      "Constructing train edges= 0000/1946\n",
      "Constructing train edges= 1000/1946\n",
      "Train edges= 1946\n",
      "Val edges= 0416\n",
      "Test edges= 0416\n",
      "Minibatch edge type: (1, 1, 2)\n",
      "Constructing test edges= 0000/0138\n",
      "Constructing val edges= 0000/0138\n",
      "Constructing train edges= 0000/0644\n",
      "Train edges= 0644\n",
      "Val edges= 0138\n",
      "Test edges= 0138\n",
      "Minibatch edge type: (1, 1, 3)\n",
      "Constructing test edges= 0000/1150\n",
      "Constructing test edges= 1000/1150\n",
      "Constructing val edges= 0000/1150\n",
      "Constructing val edges= 1000/1150\n",
      "Constructing train edges= 0000/5372\n",
      "Constructing train edges= 1000/5372\n",
      "Constructing train edges= 2000/5372\n",
      "Constructing train edges= 3000/5372\n",
      "Constructing train edges= 4000/5372\n",
      "Constructing train edges= 5000/5372\n",
      "Train edges= 5372\n",
      "Val edges= 1150\n",
      "Test edges= 1150\n",
      "Minibatch edge type: (1, 1, 4)\n",
      "Constructing test edges= 0000/0416\n",
      "Constructing val edges= 0000/0416\n",
      "Constructing train edges= 0000/1946\n",
      "Constructing train edges= 1000/1946\n",
      "Train edges= 1946\n",
      "Val edges= 0416\n",
      "Test edges= 0416\n",
      "Minibatch edge type: (1, 1, 5)\n",
      "Constructing test edges= 0000/0138\n",
      "Constructing val edges= 0000/0138\n",
      "Constructing train edges= 0000/0644\n",
      "Train edges= 0644\n",
      "Val edges= 0138\n",
      "Test edges= 0138\n"
     ]
    }
   ],
   "source": [
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    val_test_size=val_test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "WARNING:tensorflow:From decagon/deep/layers.py:93: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_training/TRAIN_toy_DSE_9688_genes_16266_drugs_627_se_6_epochs_10_h1_64_h2_32_lr_0.001_dropout_0.1\n"
     ]
    }
   ],
   "source": [
    "out_file = 'results_training/TRAIN_'+words[2]+DSE*('_DSE_'+str(n_se_mono))+'_genes_'+\\\n",
    "            str(n_genes)+'_drugs_'+str(n_drugs)+'_se_'+str(n_se_combo)+'_epochs_'+\\\n",
    "            str(FLAGS.epochs)+'_h1_'+str(FLAGS.hidden1)+'_h2_'+str(FLAGS.hidden2)+\\\n",
    "            '_lr_'+str(FLAGS.learning_rate)+'_dropout_'+str(FLAGS.dropout)\n",
    "#out_file = 'results_training/sandboxish'\n",
    "print(out_file)\n",
    "output_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Epoch: 0001 Iter: 0001 Edge: 0002 train_loss= 179.50494 val_roc= 0.50898 val_auprc= 0.50943 val_acc= 0.50154 time= 1.60595\n",
      "Epoch: 0001 Iter: 0002 Edge: 0000 train_loss= 178.23502 val_roc= 0.48973 val_auprc= 0.48715 val_acc= 0.49099 time= 0.18080\n",
      "Epoch: 0001 Iter: 0003 Edge: 0001 train_loss= 180.37849 val_roc= 0.50924 val_auprc= 0.51362 val_acc= 0.50876 time= 0.56859\n",
      "Epoch: 0001 Iter: 0004 Edge: 0004 train_loss= 177.51157 val_roc= 0.47126 val_auprc= 0.46918 val_acc= 0.49565 time= 0.12262\n",
      "Epoch: 0001 Iter: 0012 Edge: 0003 train_loss= 180.93983 val_roc= 0.49241 val_auprc= 0.48739 val_acc= 0.50435 time= 0.49746\n",
      "Epoch: 0001 Iter: 0020 Edge: 0009 train_loss= 177.63342 val_roc= 0.54952 val_auprc= 0.51526 val_acc= 0.49638 time= 0.04493\n",
      "Epoch: 0001 Iter: 0028 Edge: 0008 train_loss= 177.46402 val_roc= 0.46721 val_auprc= 0.47214 val_acc= 0.49639 time= 0.11610\n",
      "Epoch: 0001 Iter: 0060 Edge: 0005 train_loss= 177.45804 val_roc= 0.46905 val_auprc= 0.45796 val_acc= 0.49159 time= 0.04999\n",
      "Epoch: 0001 Iter: 0092 Edge: 0007 train_loss= 177.41005 val_roc= 0.54419 val_auprc= 0.52159 val_acc= 0.51261 time= 0.28096\n",
      "Epoch: 0001 Iter: 0140 Edge: 0006 train_loss= 177.43973 val_roc= 0.49464 val_auprc= 0.48158 val_acc= 0.52899 time= 0.02817\n",
      "Epoch: 0002 Iter: 0001 Edge: 0002 train_loss= 171.08101 val_roc= 0.57977 val_auprc= 0.57122 val_acc= 0.55353 time= 0.17716\n",
      "Epoch: 0002 Iter: 0002 Edge: 0000 train_loss= 153.39653 val_roc= 0.58644 val_auprc= 0.56916 val_acc= 0.56084 time= 0.17963\n",
      "Epoch: 0002 Iter: 0003 Edge: 0001 train_loss= 160.77016 val_roc= 0.59591 val_auprc= 0.58183 val_acc= 0.56935 time= 0.47877\n",
      "Epoch: 0002 Iter: 0004 Edge: 0003 train_loss= 168.88701 val_roc= 0.59013 val_auprc= 0.58063 val_acc= 0.56788 time= 0.48008\n",
      "Epoch: 0002 Iter: 0008 Edge: 0008 train_loss= 177.49155 val_roc= 0.55151 val_auprc= 0.55665 val_acc= 0.53486 time= 0.10890\n",
      "Epoch: 0002 Iter: 0012 Edge: 0009 train_loss= 177.21225 val_roc= 0.61216 val_auprc= 0.61535 val_acc= 0.57246 time= 0.04627\n",
      "Epoch: 0002 Iter: 0016 Edge: 0004 train_loss= 177.14859 val_roc= 0.56105 val_auprc= 0.55523 val_acc= 0.54043 time= 0.11028\n",
      "Epoch: 0002 Iter: 0020 Edge: 0005 train_loss= 177.04503 val_roc= 0.56373 val_auprc= 0.54865 val_acc= 0.53966 time= 0.05339\n",
      "Epoch: 0002 Iter: 0028 Edge: 0007 train_loss= 176.07784 val_roc= 0.58767 val_auprc= 0.57100 val_acc= 0.56565 time= 0.27481\n",
      "Epoch: 0002 Iter: 0060 Edge: 0006 train_loss= 176.82298 val_roc= 0.64403 val_auprc= 0.63732 val_acc= 0.58333 time= 0.02710\n",
      "Epoch: 0003 Iter: 0001 Edge: 0002 train_loss= 158.29428 val_roc= 0.63268 val_auprc= 0.61714 val_acc= 0.59785 time= 0.18311\n",
      "Epoch: 0003 Iter: 0002 Edge: 0000 train_loss= 159.48343 val_roc= 0.62268 val_auprc= 0.60597 val_acc= 0.58187 time= 0.18218\n",
      "Epoch: 0003 Iter: 0003 Edge: 0001 train_loss= 148.85411 val_roc= 0.62187 val_auprc= 0.60769 val_acc= 0.58988 time= 0.48521\n",
      "Epoch: 0003 Iter: 0004 Edge: 0005 train_loss= 175.69768 val_roc= 0.59381 val_auprc= 0.57742 val_acc= 0.57091 time= 0.05104\n",
      "Epoch: 0003 Iter: 0012 Edge: 0008 train_loss= 174.57291 val_roc= 0.64995 val_auprc= 0.63662 val_acc= 0.59976 time= 0.09999\n",
      "Epoch: 0003 Iter: 0016 Edge: 0003 train_loss= 170.24860 val_roc= 0.65149 val_auprc= 0.63115 val_acc= 0.60809 time= 0.48312\n",
      "Epoch: 0003 Iter: 0020 Edge: 0006 train_loss= 174.45367 val_roc= 0.68389 val_auprc= 0.68775 val_acc= 0.63043 time= 0.02810\n",
      "Epoch: 0003 Iter: 0024 Edge: 0004 train_loss= 175.63504 val_roc= 0.60034 val_auprc= 0.59513 val_acc= 0.56391 time= 0.11186\n",
      "Epoch: 0003 Iter: 0064 Edge: 0009 train_loss= 175.67682 val_roc= 0.64335 val_auprc= 0.63752 val_acc= 0.61594 time= 0.04610\n",
      "Epoch: 0003 Iter: 0084 Edge: 0007 train_loss= 176.30716 val_roc= 0.60569 val_auprc= 0.58980 val_acc= 0.57391 time= 0.27268\n",
      "Epoch: 0004 Iter: 0001 Edge: 0002 train_loss= 148.42955 val_roc= 0.66387 val_auprc= 0.64022 val_acc= 0.62346 time= 0.17508\n",
      "Epoch: 0004 Iter: 0002 Edge: 0000 train_loss= 145.30116 val_roc= 0.64325 val_auprc= 0.62240 val_acc= 0.59765 time= 0.17199\n",
      "Epoch: 0004 Iter: 0003 Edge: 0001 train_loss= 148.01219 val_roc= 0.64292 val_auprc= 0.62748 val_acc= 0.60891 time= 0.52112\n",
      "Epoch: 0004 Iter: 0004 Edge: 0009 train_loss= 172.23035 val_roc= 0.70810 val_auprc= 0.69287 val_acc= 0.63043 time= 0.05041\n",
      "Epoch: 0004 Iter: 0008 Edge: 0005 train_loss= 171.65416 val_roc= 0.62476 val_auprc= 0.60201 val_acc= 0.57452 time= 0.05231\n",
      "Epoch: 0004 Iter: 0012 Edge: 0008 train_loss= 175.81921 val_roc= 0.66551 val_auprc= 0.64743 val_acc= 0.61418 time= 0.10747\n",
      "Epoch: 0004 Iter: 0016 Edge: 0007 train_loss= 175.88834 val_roc= 0.61862 val_auprc= 0.59713 val_acc= 0.58739 time= 0.27931\n",
      "Epoch: 0004 Iter: 0024 Edge: 0003 train_loss= 162.26648 val_roc= 0.68030 val_auprc= 0.65807 val_acc= 0.63499 time= 0.49128\n",
      "Epoch: 0004 Iter: 0028 Edge: 0006 train_loss= 170.32730 val_roc= 0.71534 val_auprc= 0.71450 val_acc= 0.63768 time= 0.02914\n",
      "Epoch: 0004 Iter: 0044 Edge: 0004 train_loss= 174.93938 val_roc= 0.60592 val_auprc= 0.59310 val_acc= 0.57522 time= 0.11771\n",
      "Epoch: 0005 Iter: 0001 Edge: 0002 train_loss= 149.06519 val_roc= 0.67096 val_auprc= 0.63878 val_acc= 0.61936 time= 0.17523\n",
      "Epoch: 0005 Iter: 0002 Edge: 0000 train_loss= 141.26044 val_roc= 0.65394 val_auprc= 0.63095 val_acc= 0.59790 time= 0.17583\n",
      "Epoch: 0005 Iter: 0003 Edge: 0001 train_loss= 121.82481 val_roc= 0.65524 val_auprc= 0.63498 val_acc= 0.61392 time= 0.48174\n",
      "Epoch: 0005 Iter: 0004 Edge: 0008 train_loss= 170.08156 val_roc= 0.65841 val_auprc= 0.63160 val_acc= 0.61659 time= 0.10567\n",
      "Epoch: 0005 Iter: 0008 Edge: 0005 train_loss= 168.50076 val_roc= 0.64057 val_auprc= 0.61084 val_acc= 0.60457 time= 0.04968\n",
      "Epoch: 0005 Iter: 0012 Edge: 0007 train_loss= 172.22896 val_roc= 0.63408 val_auprc= 0.61703 val_acc= 0.59783 time= 0.27421\n",
      "Epoch: 0005 Iter: 0016 Edge: 0004 train_loss= 172.65305 val_roc= 0.62294 val_auprc= 0.60261 val_acc= 0.57870 time= 0.10862\n",
      "Epoch: 0005 Iter: 0024 Edge: 0006 train_loss= 169.44986 val_roc= 0.72973 val_auprc= 0.72891 val_acc= 0.64855 time= 0.03068\n",
      "Epoch: 0005 Iter: 0044 Edge: 0003 train_loss= 150.95457 val_roc= 0.70054 val_auprc= 0.66854 val_acc= 0.64524 time= 0.45987\n",
      "Epoch: 0005 Iter: 0052 Edge: 0009 train_loss= 171.61534 val_roc= 0.67743 val_auprc= 0.65712 val_acc= 0.65217 time= 0.04550\n",
      "Epoch: 0006 Iter: 0001 Edge: 0002 train_loss= 149.74957 val_roc= 0.68486 val_auprc= 0.65859 val_acc= 0.63012 time= 0.17030\n",
      "Epoch: 0006 Iter: 0002 Edge: 0000 train_loss= 144.29849 val_roc= 0.66176 val_auprc= 0.64020 val_acc= 0.60165 time= 0.17219\n",
      "Epoch: 0006 Iter: 0003 Edge: 0001 train_loss= 135.89507 val_roc= 0.65964 val_auprc= 0.64281 val_acc= 0.61042 time= 0.47959\n",
      "Epoch: 0006 Iter: 0004 Edge: 0008 train_loss= 166.29126 val_roc= 0.67984 val_auprc= 0.65826 val_acc= 0.63702 time= 0.10432\n",
      "Epoch: 0006 Iter: 0008 Edge: 0009 train_loss= 166.69818 val_roc= 0.72417 val_auprc= 0.70564 val_acc= 0.63406 time= 0.04587\n",
      "Epoch: 0006 Iter: 0012 Edge: 0004 train_loss= 172.17068 val_roc= 0.64061 val_auprc= 0.61608 val_acc= 0.59304 time= 0.11793\n",
      "Epoch: 0006 Iter: 0028 Edge: 0003 train_loss= 150.37451 val_roc= 0.71019 val_auprc= 0.67869 val_acc= 0.65343 time= 0.47005\n",
      "Epoch: 0006 Iter: 0048 Edge: 0006 train_loss= 157.48059 val_roc= 0.75200 val_auprc= 0.74127 val_acc= 0.65942 time= 0.03069\n",
      "Epoch: 0006 Iter: 0056 Edge: 0007 train_loss= 164.82129 val_roc= 0.63966 val_auprc= 0.62789 val_acc= 0.60217 time= 0.26155\n",
      "Epoch: 0006 Iter: 0164 Edge: 0005 train_loss= 168.30066 val_roc= 0.65627 val_auprc= 0.62717 val_acc= 0.61538 time= 0.04967\n",
      "Epoch: 0007 Iter: 0001 Edge: 0002 train_loss= 139.35355 val_roc= 0.69630 val_auprc= 0.66385 val_acc= 0.64267 time= 0.17646\n",
      "Epoch: 0007 Iter: 0002 Edge: 0000 train_loss= 149.51962 val_roc= 0.66561 val_auprc= 0.64266 val_acc= 0.61617 time= 0.18234\n",
      "Epoch: 0007 Iter: 0003 Edge: 0001 train_loss= 134.68875 val_roc= 0.67031 val_auprc= 0.65345 val_acc= 0.62394 time= 0.47073\n",
      "Epoch: 0007 Iter: 0004 Edge: 0007 train_loss= 165.35648 val_roc= 0.65094 val_auprc= 0.63594 val_acc= 0.60304 time= 0.26531\n",
      "Epoch: 0007 Iter: 0008 Edge: 0003 train_loss= 143.97121 val_roc= 0.72387 val_auprc= 0.69308 val_acc= 0.66650 time= 0.48396\n",
      "Epoch: 0007 Iter: 0012 Edge: 0005 train_loss= 160.75900 val_roc= 0.66850 val_auprc= 0.64068 val_acc= 0.62740 time= 0.05022\n",
      "Epoch: 0007 Iter: 0016 Edge: 0009 train_loss= 162.81731 val_roc= 0.72606 val_auprc= 0.72026 val_acc= 0.64493 time= 0.04600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0007 Iter: 0020 Edge: 0008 train_loss= 154.99869 val_roc= 0.67973 val_auprc= 0.64661 val_acc= 0.63221 time= 0.10565\n",
      "Epoch: 0007 Iter: 0032 Edge: 0004 train_loss= 167.41205 val_roc= 0.66308 val_auprc= 0.63241 val_acc= 0.62043 time= 0.10921\n",
      "Epoch: 0007 Iter: 0100 Edge: 0006 train_loss= 156.17516 val_roc= 0.76722 val_auprc= 0.75966 val_acc= 0.66667 time= 0.02577\n",
      "Epoch: 0008 Iter: 0001 Edge: 0002 train_loss= 132.46365 val_roc= 0.70505 val_auprc= 0.67166 val_acc= 0.65548 time= 0.17508\n",
      "Epoch: 0008 Iter: 0002 Edge: 0000 train_loss= 122.98051 val_roc= 0.67988 val_auprc= 0.65702 val_acc= 0.61918 time= 0.17449\n",
      "Epoch: 0008 Iter: 0003 Edge: 0001 train_loss= 132.99316 val_roc= 0.67547 val_auprc= 0.65750 val_acc= 0.62494 time= 0.48483\n",
      "Epoch: 0008 Iter: 0004 Edge: 0005 train_loss= 148.89516 val_roc= 0.67398 val_auprc= 0.63277 val_acc= 0.63942 time= 0.05000\n",
      "Epoch: 0008 Iter: 0016 Edge: 0006 train_loss= 159.12935 val_roc= 0.75410 val_auprc= 0.73493 val_acc= 0.66304 time= 0.02681\n",
      "Epoch: 0008 Iter: 0020 Edge: 0004 train_loss= 167.25568 val_roc= 0.66927 val_auprc= 0.63174 val_acc= 0.63957 time= 0.10556\n",
      "Epoch: 0008 Iter: 0028 Edge: 0008 train_loss= 156.57945 val_roc= 0.68126 val_auprc= 0.65461 val_acc= 0.62620 time= 0.09891\n",
      "Epoch: 0008 Iter: 0048 Edge: 0003 train_loss= 149.37099 val_roc= 0.73650 val_auprc= 0.70265 val_acc= 0.67725 time= 0.46669\n",
      "Epoch: 0008 Iter: 0092 Edge: 0007 train_loss= 163.86334 val_roc= 0.66102 val_auprc= 0.63611 val_acc= 0.61043 time= 0.26859\n",
      "Epoch: 0008 Iter: 0100 Edge: 0009 train_loss= 162.39294 val_roc= 0.73614 val_auprc= 0.72469 val_acc= 0.62681 time= 0.04431\n",
      "Epoch: 0009 Iter: 0001 Edge: 0002 train_loss= 135.89348 val_roc= 0.71138 val_auprc= 0.67543 val_acc= 0.64421 time= 0.20247\n",
      "Epoch: 0009 Iter: 0002 Edge: 0000 train_loss= 139.37872 val_roc= 0.68029 val_auprc= 0.65354 val_acc= 0.61167 time= 0.21065\n",
      "Epoch: 0009 Iter: 0003 Edge: 0001 train_loss= 135.22220 val_roc= 0.67855 val_auprc= 0.66294 val_acc= 0.62344 time= 0.54932\n",
      "Epoch: 0009 Iter: 0004 Edge: 0007 train_loss= 158.88449 val_roc= 0.67207 val_auprc= 0.64028 val_acc= 0.63217 time= 0.31136\n",
      "Epoch: 0009 Iter: 0008 Edge: 0003 train_loss= 142.12601 val_roc= 0.73950 val_auprc= 0.70694 val_acc= 0.67085 time= 0.51108\n",
      "Epoch: 0009 Iter: 0012 Edge: 0004 train_loss= 157.10318 val_roc= 0.68793 val_auprc= 0.64888 val_acc= 0.63652 time= 0.11281\n",
      "Epoch: 0009 Iter: 0028 Edge: 0006 train_loss= 150.80157 val_roc= 0.78770 val_auprc= 0.76706 val_acc= 0.71377 time= 0.03080\n",
      "Epoch: 0009 Iter: 0040 Edge: 0005 train_loss= 159.68828 val_roc= 0.68252 val_auprc= 0.63864 val_acc= 0.63822 time= 0.05053\n",
      "Epoch: 0009 Iter: 0044 Edge: 0009 train_loss= 160.19016 val_roc= 0.73587 val_auprc= 0.72074 val_acc= 0.64130 time= 0.04671\n",
      "Epoch: 0009 Iter: 0076 Edge: 0008 train_loss= 159.13815 val_roc= 0.68712 val_auprc= 0.65488 val_acc= 0.63702 time= 0.10947\n",
      "Epoch: 0010 Iter: 0001 Edge: 0002 train_loss= 138.05432 val_roc= 0.71842 val_auprc= 0.67574 val_acc= 0.65881 time= 0.18085\n",
      "Epoch: 0010 Iter: 0002 Edge: 0000 train_loss= 130.68167 val_roc= 0.68130 val_auprc= 0.65125 val_acc= 0.62619 time= 0.18424\n",
      "Epoch: 0010 Iter: 0003 Edge: 0001 train_loss= 123.89287 val_roc= 0.68462 val_auprc= 0.66647 val_acc= 0.62719 time= 0.51068\n",
      "Epoch: 0010 Iter: 0004 Edge: 0009 train_loss= 144.05771 val_roc= 0.74527 val_auprc= 0.71872 val_acc= 0.66304 time= 0.04903\n",
      "Epoch: 0010 Iter: 0008 Edge: 0004 train_loss= 159.24518 val_roc= 0.70098 val_auprc= 0.65808 val_acc= 0.65261 time= 0.11776\n",
      "Epoch: 0010 Iter: 0012 Edge: 0007 train_loss= 158.75272 val_roc= 0.68282 val_auprc= 0.65110 val_acc= 0.62870 time= 0.28663\n",
      "Epoch: 0010 Iter: 0020 Edge: 0008 train_loss= 159.50130 val_roc= 0.70250 val_auprc= 0.65596 val_acc= 0.62981 time= 0.11086\n",
      "Epoch: 0010 Iter: 0028 Edge: 0006 train_loss= 146.53902 val_roc= 0.80246 val_auprc= 0.77697 val_acc= 0.71739 time= 0.03913\n",
      "Epoch: 0010 Iter: 0044 Edge: 0005 train_loss= 151.14728 val_roc= 0.69139 val_auprc= 0.66566 val_acc= 0.64062 time= 0.07362\n",
      "Epoch: 0010 Iter: 0076 Edge: 0003 train_loss= 156.30334 val_roc= 0.74957 val_auprc= 0.71476 val_acc= 0.69134 time= 0.47851\n",
      "Optimization finished!\n",
      "Edge type= [00, 01, 00]\n",
      "Edge type: 0000 Test AUROC score 0.67611\n",
      "Edge type: 0000 Test AUPRC score 0.65364\n",
      "Edge type: 0000 Test Accuracy score 0.61968\n",
      "\n",
      "Edge type= [01, 00, 00]\n",
      "Edge type: 0001 Test AUROC score 0.70205\n",
      "Edge type: 0001 Test AUPRC score 0.67185\n",
      "Edge type: 0001 Test Accuracy score 0.64772\n",
      "\n",
      "Edge type= [00, 00, 00]\n",
      "Edge type: 0002 Test AUROC score 0.70652\n",
      "Edge type: 0002 Test AUPRC score 0.67287\n",
      "Edge type: 0002 Test Accuracy score 0.65036\n",
      "\n",
      "Edge type= [00, 00, 01]\n",
      "Edge type: 0003 Test AUROC score 0.73967\n",
      "Edge type: 0003 Test AUPRC score 0.70236\n",
      "Edge type: 0003 Test Accuracy score 0.67469\n",
      "\n",
      "Edge type= [01, 01, 00]\n",
      "Edge type: 0004 Test AUROC score 0.67822\n",
      "Edge type: 0004 Test AUPRC score 0.64053\n",
      "Edge type: 0004 Test Accuracy score 0.62478\n",
      "\n",
      "Edge type= [01, 01, 01]\n",
      "Edge type: 0005 Test AUROC score 0.71223\n",
      "Edge type: 0005 Test AUPRC score 0.68151\n",
      "Edge type: 0005 Test Accuracy score 0.65505\n",
      "\n",
      "Edge type= [01, 01, 02]\n",
      "Edge type: 0006 Test AUROC score 0.74753\n",
      "Edge type: 0006 Test AUPRC score 0.71471\n",
      "Edge type: 0006 Test Accuracy score 0.69565\n",
      "\n",
      "Edge type= [01, 01, 03]\n",
      "Edge type: 0007 Test AUROC score 0.69566\n",
      "Edge type: 0007 Test AUPRC score 0.65002\n",
      "Edge type: 0007 Test Accuracy score 0.64826\n",
      "\n",
      "Edge type= [01, 01, 04]\n",
      "Edge type: 0008 Test AUROC score 0.72429\n",
      "Edge type: 0008 Test AUPRC score 0.68297\n",
      "Edge type: 0008 Test Accuracy score 0.67428\n",
      "\n",
      "Edge type= [01, 01, 05]\n",
      "Edge type: 0009 Test AUROC score 0.77342\n",
      "Edge type: 0009 Test AUPRC score 0.77123\n",
      "Edge type: 0009 Test Accuracy score 0.69203\n",
      "\n",
      "Virtual memory: 3300151296\n",
      "RSS Memory: 371974144\n",
      "Total time: 271.094285965\n"
     ]
    }
   ],
   "source": [
    "# Metric structures initialization\n",
    "validation_metrics = np.zeros([num_edge_types,3,1])\n",
    "train_acc = np.zeros([FLAGS.epochs,num_edge_types])\n",
    "val_acc = np.zeros([FLAGS.epochs,num_edge_types])\n",
    "vm_layer = np.zeros([num_edge_types,3,1])\n",
    "# Start training\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    edge_count = range(num_edge_types)\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "        t = time.time()\n",
    "\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        train_cost = outs[1]\n",
    "        batch_edge_type = outs[2]\n",
    "        # Metrics\n",
    "        if batch_edge_type in edge_count:\n",
    "            val_auc, val_auprc, val_acs = get_accuracy_scores(\n",
    "                minibatch.val_edges, minibatch.val_edges_false,\n",
    "                minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n",
    "            step_time = time.time() - t\n",
    "            vm_layer[batch_edge_type,:,0] = [val_auc,val_auprc,val_acs]\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch + 1), \"Iter:\", \"%04d\" % (itr + 1), \n",
    "                  \"Edge:\", \"%04d\" % batch_edge_type,\n",
    "                  \"train_loss=\", \"{:.5f}\".format(train_cost),\n",
    "                  \"val_roc=\", \"{:.5f}\".format(val_auc),\n",
    "                  \"val_auprc=\", \"{:.5f}\".format(val_auprc),\n",
    "                  \"val_acc=\", \"{:.5f}\".format(val_acs),\n",
    "                  \"time=\", \"{:.5f}\".format(step_time))\n",
    "            edge_count.remove(batch_edge_type)\n",
    "        itr += 1\n",
    "    # Train accuracy over all train data per epoch\n",
    "    for r in range(num_edge_types):\n",
    "        i,j,k = minibatch.idx2edge_type[r]\n",
    "        true_train_edges = minibatch.train_edges[i,j][k]\n",
    "        false_train_edges = minibatch.train_edges_false[i,j][k]\n",
    "        true_val_edges = minibatch.val_edges[i,j][k]\n",
    "        false_val_edges = minibatch.val_edges_false[i,j][k]\n",
    "        feed_dict.update({placeholders['batch_edge_type_idx']:k})\n",
    "        feed_dict.update({placeholders['batch_row_edge_type']: i})\n",
    "        feed_dict.update({placeholders['batch_col_edge_type']: j})\n",
    "        pred = sess.run(opt.predictions,feed_dict=feed_dict)\n",
    "        train_acc[epoch,r] = accuracy(true_train_edges,false_train_edges,pred)\n",
    "        val_acc[epoch,r] = accuracy(true_val_edges,false_val_edges,pred)\n",
    "    validation_metrics = np.concatenate((validation_metrics,vm_layer),axis=2)\n",
    "    output_data['val_auc'] = validation_metrics[:,0,1:]\n",
    "    output_data['val_auprc'] = validation_metrics[:,1,1:]\n",
    "    output_data['train_acc'] = train_acc\n",
    "    output_data['val_acc'] = val_acc\n",
    "    output_data['epoch'] = epoch + 1\n",
    "    \n",
    "    with open(out_file,'wb') as f:\n",
    "        pickle.dump(output_data, f, protocol=2)\n",
    "    vm_layer = np.zeros([num_edge_types,3,1])\n",
    "    \n",
    "# End of training. Metric structure handling   \n",
    "print(\"Optimization finished!\")\n",
    "test_scores = np.zeros([num_edge_types,3])\n",
    "for et in range(num_edge_types):\n",
    "    roc_score, auprc_score, acc_score = get_accuracy_scores(\n",
    "        minibatch.test_edges, minibatch.test_edges_false, minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type=\", \"[%02d, %02d, %02d]\" % minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(roc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(auprc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test Accuracy score\", \"{:.5f}\".format(acc_score))\n",
    "    print()\n",
    "    test_scores[et,0] = roc_score\n",
    "    test_scores[et,1] = auprc_score\n",
    "    test_scores[et,2] = acc_score\n",
    "output_data['test_scores'] = test_scores\n",
    "memUse = ps.memory_info()\n",
    "print('Virtual memory:', memUse.vms)\n",
    "print('RSS Memory:', memUse.rss)\n",
    "total_time=time.time()-start\n",
    "output_data['time'] = total_time\n",
    "output_data['vms'] = memUse.vms\n",
    "output_data['rss'] = memUse.rss\n",
    "with open(out_file,'wb') as f:\n",
    "    pickle.dump(output_data, f, protocol=2)\n",
    "print(\"Total time:\",total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
