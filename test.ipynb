{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECAGON Training\n",
    "Test notebook for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psutil & time BEGIN\n",
    "start = time.time() #in seconds\n",
    "pid = os.getpid()\n",
    "ps= psutil.Process(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data from previous computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input file. Goes as parameter in script\n",
    "in_file = './data/data_structures/DECAGON/DECAGON_toy_genes_500_drugs_400_se_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = in_file.split('_')\n",
    "DSE = False\n",
    "BDM = False\n",
    "DOCK = False\n",
    "BIND = False\n",
    "if 'DSE' in words: DSE = True\n",
    "if 'BDM' in words: BDM = True\n",
    "if 'docking' in words: DOCK = True\n",
    "elif 'binding' in words: BIND = True\n",
    "d_text = DOCK*'_docking'+BIND*'_binding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge2name Imported successfully\n",
      "se_mono_name2idx Imported successfully\n",
      "gene2idx Imported successfully\n",
      "nonzero_feat Imported successfully\n",
      "edge_type2dim Imported successfully\n",
      "adj_mats_orig Imported successfully\n",
      "edge_type2decoder Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "degrees Imported successfully\n",
      "edge_types Imported successfully\n",
      "num_edge_types Imported successfully\n",
      "num_feat Imported successfully\n",
      "feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "with open(in_file, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 400 4 600 False\n"
     ]
    }
   ],
   "source": [
    "n_genes = len(gene2idx)\n",
    "n_drugs = len(drug2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)\n",
    "print(n_genes,n_drugs,n_se_combo,n_se_mono,DSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type, noise=False):\n",
    "    \"\"\" Returns the AUROC, AUPRC and Accuracy of the dataset corresponding to the edge\n",
    "    'edge_type' given as a tuple. The parameters 'edges_pos' and 'edges_neg' are the list \n",
    "    of edges of positive and negative interactions respectively of a given dataset, i.e., \n",
    "    train, test or validation.\n",
    "    \"\"\"\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "    # Predict on set of edges\n",
    "    preds = []\n",
    "    for u, v in edges_pos:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        if not noise:\n",
    "            assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] > 0, 'Problem 1'\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        if not noise:\n",
    "            assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    acc = metrics.accuracy_score(labels_all, np.round(preds_all))\n",
    "\n",
    "    return roc_sc, aupr_sc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.05\n",
    "val_test_size = 0.15\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 10, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 128, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHETAZO!! Soluciona el bug de Jupyter con tensorflow que proporciona un flag -f\n",
    "flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_structures/MINIBATCH/MINIBATCH_toy_genes_500_drugs_400_se_4_batchsize_128_valsize_0.15_noise_0.05\n"
     ]
    }
   ],
   "source": [
    "noise_str = bool(noise)*('_noise_' + str(noise))\n",
    "mb_file = 'data/data_structures/MINIBATCH/MINIBATCH_'+words[2]+d_text+\\\n",
    "            '_genes_'+str(n_genes)+'_drugs_'+\\\n",
    "            str(n_drugs)+'_se_'+str(n_se_combo)+'_batchsize_'+str(FLAGS.batch_size)+\\\n",
    "            '_valsize_'+str(val_test_size) + noise_str\n",
    "print(mb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mb_file, 'rb') as f:\n",
    "    minibatch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch.feat = feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "WARNING:tensorflow:From decagon/deep/layers.py:93: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}\n",
    "pre_train_time = time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_training/TRAIN_toy_genes_500_drugs_400_se_4_epochs_10_h1_64_h2_32_lr_0.001_dropout_0.1_valsize_0.15_noise_0.05\n"
     ]
    }
   ],
   "source": [
    "out_file = 'results_training/TRAIN_'+words[2]+d_text+DSE*('_DSE_'+str(n_se_mono))+BDM*('_BDM')\\\n",
    "            +'_genes_'+str(n_genes)+'_drugs_'+str(n_drugs)+'_se_'+str(n_se_combo)+'_epochs_'+\\\n",
    "            str(FLAGS.epochs)+'_h1_'+str(FLAGS.hidden1)+'_h2_'+str(FLAGS.hidden2)+\\\n",
    "            '_lr_'+str(FLAGS.learning_rate)+'_dropout_'+str(FLAGS.dropout)+'_valsize_'+\\\n",
    "            str(val_test_size) + noise_str\n",
    "#out_file = 'results_training/sandboxish'\n",
    "print(out_file)\n",
    "output_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "======================================================================================================================\n",
      "Epoch 0001 finished!\n",
      "Time= 7.72882\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.8344 Validation= 0.6191 AUPRC:Train= 0.8749 Validation= 0.6317 Accuracy:Train= 0.8182 Validation= 0.6038\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.8458 Validation= 0.6572 AUPRC:Train= 0.8924 Validation= 0.6946 Accuracy:Train= 0.8024 Validation= 0.5660\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9681 Validation= 0.7991 AUPRC:Train= 0.9612 Validation= 0.7883 Accuracy:Train= 0.9304 Validation= 0.7880\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5052 Validation= 0.4914 AUPRC:Train= 0.5072 Validation= 0.4965 Accuracy:Train= 0.5018 Validation= 0.4989\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5034 Validation= 0.4998 AUPRC:Train= 0.4975 Validation= 0.5030 Accuracy:Train= 0.5004 Validation= 0.4990\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.4911 Validation= 0.5138 AUPRC:Train= 0.4918 Validation= 0.4996 Accuracy:Train= 0.4950 Validation= 0.5090\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.5150 Validation= 0.5716 AUPRC:Train= 0.4968 Validation= 0.5861 Accuracy:Train= 0.5300 Validation= 0.5263\n",
      "======================================================================================================================\n",
      "Epoch 0002 finished!\n",
      "Time= 6.43834\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9263 Validation= 0.7245 AUPRC:Train= 0.9366 Validation= 0.7257 Accuracy:Train= 0.8715 Validation= 0.6226\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9260 Validation= 0.6924 AUPRC:Train= 0.9465 Validation= 0.7327 Accuracy:Train= 0.8617 Validation= 0.6226\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9908 Validation= 0.8325 AUPRC:Train= 0.9905 Validation= 0.8332 Accuracy:Train= 0.9594 Validation= 0.8207\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5077 Validation= 0.4990 AUPRC:Train= 0.5084 Validation= 0.5000 Accuracy:Train= 0.5051 Validation= 0.5018\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5186 Validation= 0.4972 AUPRC:Train= 0.5134 Validation= 0.4996 Accuracy:Train= 0.5175 Validation= 0.5007\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5129 Validation= 0.5048 AUPRC:Train= 0.5160 Validation= 0.5014 Accuracy:Train= 0.5058 Validation= 0.5146\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.5912 Validation= 0.5177 AUPRC:Train= 0.5631 Validation= 0.5137 Accuracy:Train= 0.5805 Validation= 0.4912\n",
      "======================================================================================================================\n",
      "Epoch 0003 finished!\n",
      "Time= 6.34037\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9391 Validation= 0.7885 AUPRC:Train= 0.9489 Validation= 0.7707 Accuracy:Train= 0.8715 Validation= 0.6321\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9528 Validation= 0.7099 AUPRC:Train= 0.9625 Validation= 0.7420 Accuracy:Train= 0.8735 Validation= 0.6132\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9900 Validation= 0.8465 AUPRC:Train= 0.9874 Validation= 0.8816 Accuracy:Train= 0.9710 Validation= 0.8098\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5105 Validation= 0.4996 AUPRC:Train= 0.5101 Validation= 0.5005 Accuracy:Train= 0.5066 Validation= 0.5064\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5209 Validation= 0.4989 AUPRC:Train= 0.5176 Validation= 0.5067 Accuracy:Train= 0.5123 Validation= 0.4934\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5145 Validation= 0.4747 AUPRC:Train= 0.5145 Validation= 0.4908 Accuracy:Train= 0.5077 Validation= 0.5056\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.6445 Validation= 0.4949 AUPRC:Train= 0.6098 Validation= 0.5422 Accuracy:Train= 0.5974 Validation= 0.5175\n",
      "======================================================================================================================\n",
      "Epoch 0004 finished!\n",
      "Time= 6.50751\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9668 Validation= 0.7953 AUPRC:Train= 0.9643 Validation= 0.7768 Accuracy:Train= 0.9111 Validation= 0.6132\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9749 Validation= 0.7722 AUPRC:Train= 0.9808 Validation= 0.8043 Accuracy:Train= 0.9170 Validation= 0.6321\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9931 Validation= 0.8562 AUPRC:Train= 0.9881 Validation= 0.8922 Accuracy:Train= 0.9745 Validation= 0.8152\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5129 Validation= 0.4975 AUPRC:Train= 0.5136 Validation= 0.4960 Accuracy:Train= 0.5082 Validation= 0.5018\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5280 Validation= 0.5103 AUPRC:Train= 0.5219 Validation= 0.5129 Accuracy:Train= 0.5193 Validation= 0.5106\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5394 Validation= 0.4652 AUPRC:Train= 0.5361 Validation= 0.4803 Accuracy:Train= 0.5233 Validation= 0.4854\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.6668 Validation= 0.5125 AUPRC:Train= 0.6485 Validation= 0.5281 Accuracy:Train= 0.6180 Validation= 0.4912\n",
      "======================================================================================================================\n",
      "Epoch 0005 finished!\n",
      "Time= 6.24347\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9714 Validation= 0.8341 AUPRC:Train= 0.9665 Validation= 0.8421 Accuracy:Train= 0.9130 Validation= 0.6887\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9843 Validation= 0.8060 AUPRC:Train= 0.9877 Validation= 0.8265 Accuracy:Train= 0.9348 Validation= 0.6415\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9944 Validation= 0.8716 AUPRC:Train= 0.9895 Validation= 0.9136 Accuracy:Train= 0.9768 Validation= 0.8424\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5172 Validation= 0.4945 AUPRC:Train= 0.5165 Validation= 0.4933 Accuracy:Train= 0.5105 Validation= 0.4947\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5309 Validation= 0.5175 AUPRC:Train= 0.5213 Validation= 0.5144 Accuracy:Train= 0.5222 Validation= 0.5116\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5577 Validation= 0.4906 AUPRC:Train= 0.5508 Validation= 0.4895 Accuracy:Train= 0.5377 Validation= 0.5112\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7059 Validation= 0.5756 AUPRC:Train= 0.6803 Validation= 0.5896 Accuracy:Train= 0.6442 Validation= 0.5702\n",
      "======================================================================================================================\n",
      "Epoch 0006 finished!\n",
      "Time= 6.20650\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9816 Validation= 0.8366 AUPRC:Train= 0.9787 Validation= 0.8579 Accuracy:Train= 0.9249 Validation= 0.6415\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9861 Validation= 0.7743 AUPRC:Train= 0.9884 Validation= 0.8010 Accuracy:Train= 0.9229 Validation= 0.6132\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9985 Validation= 0.8728 AUPRC:Train= 0.9983 Validation= 0.9131 Accuracy:Train= 0.9838 Validation= 0.8424\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5202 Validation= 0.4940 AUPRC:Train= 0.5177 Validation= 0.4956 Accuracy:Train= 0.5154 Validation= 0.4944\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5344 Validation= 0.5075 AUPRC:Train= 0.5243 Validation= 0.5057 Accuracy:Train= 0.5237 Validation= 0.5126\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5720 Validation= 0.4925 AUPRC:Train= 0.5622 Validation= 0.4944 Accuracy:Train= 0.5488 Validation= 0.4854\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7188 Validation= 0.5783 AUPRC:Train= 0.6878 Validation= 0.5976 Accuracy:Train= 0.6348 Validation= 0.5526\n",
      "======================================================================================================================\n",
      "Epoch 0007 finished!\n",
      "Time= 6.16648\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9858 Validation= 0.8537 AUPRC:Train= 0.9819 Validation= 0.8707 Accuracy:Train= 0.9387 Validation= 0.6981\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9941 Validation= 0.8067 AUPRC:Train= 0.9954 Validation= 0.8345 Accuracy:Train= 0.9545 Validation= 0.6321\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9963 Validation= 0.8759 AUPRC:Train= 0.9864 Validation= 0.9175 Accuracy:Train= 0.9896 Validation= 0.8696\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5256 Validation= 0.4989 AUPRC:Train= 0.5226 Validation= 0.5000 Accuracy:Train= 0.5159 Validation= 0.5003\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5368 Validation= 0.5079 AUPRC:Train= 0.5263 Validation= 0.5086 Accuracy:Train= 0.5274 Validation= 0.5069\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5781 Validation= 0.4928 AUPRC:Train= 0.5659 Validation= 0.4943 Accuracy:Train= 0.5557 Validation= 0.5022\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7593 Validation= 0.6011 AUPRC:Train= 0.7257 Validation= 0.6301 Accuracy:Train= 0.6685 Validation= 0.5263\n",
      "======================================================================================================================\n",
      "Epoch 0008 finished!\n",
      "Time= 6.15563\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9905 Validation= 0.8459 AUPRC:Train= 0.9870 Validation= 0.8444 Accuracy:Train= 0.9605 Validation= 0.6415\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9954 Validation= 0.8046 AUPRC:Train= 0.9957 Validation= 0.8368 Accuracy:Train= 0.9526 Validation= 0.6509\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9962 Validation= 0.8703 AUPRC:Train= 0.9913 Validation= 0.9133 Accuracy:Train= 0.9919 Validation= 0.8587\n",
      "Metrics for  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:Train= 0.5297 Validation= 0.4995 AUPRC:Train= 0.5247 Validation= 0.4990 Accuracy:Train= 0.5204 Validation= 0.4986\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5366 Validation= 0.5067 AUPRC:Train= 0.5267 Validation= 0.5098 Accuracy:Train= 0.5207 Validation= 0.5000\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.6062 Validation= 0.5163 AUPRC:Train= 0.5927 Validation= 0.5105 Accuracy:Train= 0.5795 Validation= 0.5135\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7773 Validation= 0.6140 AUPRC:Train= 0.7467 Validation= 0.6469 Accuracy:Train= 0.6948 Validation= 0.5526\n",
      "======================================================================================================================\n",
      "Epoch 0009 finished!\n",
      "Time= 6.23137\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9872 Validation= 0.8277 AUPRC:Train= 0.9840 Validation= 0.8453 Accuracy:Train= 0.9427 Validation= 0.6604\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9936 Validation= 0.8120 AUPRC:Train= 0.9946 Validation= 0.8545 Accuracy:Train= 0.9565 Validation= 0.6604\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9957 Validation= 0.8736 AUPRC:Train= 0.9899 Validation= 0.9157 Accuracy:Train= 0.9872 Validation= 0.8533\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5322 Validation= 0.5043 AUPRC:Train= 0.5284 Validation= 0.5044 Accuracy:Train= 0.5190 Validation= 0.5031\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5425 Validation= 0.5069 AUPRC:Train= 0.5306 Validation= 0.5125 Accuracy:Train= 0.5285 Validation= 0.4950\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.6160 Validation= 0.5161 AUPRC:Train= 0.5970 Validation= 0.5131 Accuracy:Train= 0.5887 Validation= 0.5146\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7555 Validation= 0.5977 AUPRC:Train= 0.7228 Validation= 0.6241 Accuracy:Train= 0.6966 Validation= 0.5614\n",
      "======================================================================================================================\n",
      "Epoch 0010 finished!\n",
      "Time= 6.24979\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9910 Validation= 0.8341 AUPRC:Train= 0.9898 Validation= 0.8473 Accuracy:Train= 0.9506 Validation= 0.6509\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9966 Validation= 0.7964 AUPRC:Train= 0.9970 Validation= 0.8430 Accuracy:Train= 0.9723 Validation= 0.6509\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9975 Validation= 0.8840 AUPRC:Train= 0.9867 Validation= 0.9228 Accuracy:Train= 0.9884 Validation= 0.8587\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5391 Validation= 0.5104 AUPRC:Train= 0.5317 Validation= 0.5094 Accuracy:Train= 0.5262 Validation= 0.5071\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5509 Validation= 0.5131 AUPRC:Train= 0.5372 Validation= 0.5128 Accuracy:Train= 0.5379 Validation= 0.5106\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.6320 Validation= 0.5141 AUPRC:Train= 0.6088 Validation= 0.5127 Accuracy:Train= 0.5935 Validation= 0.5067\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7667 Validation= 0.5820 AUPRC:Train= 0.7269 Validation= 0.6263 Accuracy:Train= 0.7004 Validation= 0.5526\n",
      "Optimization finished!\n",
      "Edge type= DTI\n",
      "Edge type: 0000 Test AUROC score 0.71464\n",
      "Edge type: 0000 Test AUPRC score 0.67948\n",
      "Edge type: 0000 Test Accuracy score 0.59434\n",
      "\n",
      "Edge type= TDI\n",
      "Edge type: 0001 Test AUROC score 0.83621\n",
      "Edge type: 0001 Test AUPRC score 0.80154\n",
      "Edge type: 0001 Test Accuracy score 0.64151\n",
      "\n",
      "Edge type= PPI\n",
      "Edge type: 0002 Test AUROC score 0.79475\n",
      "Edge type: 0002 Test AUPRC score 0.81962\n",
      "Edge type: 0002 Test Accuracy score 0.80435\n",
      "\n",
      "Edge type= 0\n",
      "Edge type: 0003 Test AUROC score 0.49903\n",
      "Edge type: 0003 Test AUPRC score 0.50020\n",
      "Edge type: 0003 Test Accuracy score 0.50145\n",
      "\n",
      "Edge type= 1\n",
      "Edge type: 0004 Test AUROC score 0.51724\n",
      "Edge type: 0004 Test AUPRC score 0.51175\n",
      "Edge type: 0004 Test Accuracy score 0.51470\n",
      "\n",
      "Edge type= 2\n",
      "Edge type: 0005 Test AUROC score 0.51991\n",
      "Edge type: 0005 Test AUPRC score 0.52891\n",
      "Edge type: 0005 Test Accuracy score 0.51236\n",
      "\n",
      "Edge type= 3\n",
      "Edge type: 0006 Test AUROC score 0.55185\n",
      "Edge type: 0006 Test AUPRC score 0.58816\n",
      "Edge type: 0006 Test Accuracy score 0.55263\n",
      "\n",
      "Virtual memory: 3.261902848 Gb\n",
      "RSS Memory: 0.34676736 Gb\n",
      "Total time: 0:01:35.290925\n"
     ]
    }
   ],
   "source": [
    "# Metric structures initialization\n",
    "val_metrics = np.zeros([FLAGS.epochs,num_edge_types,3])\n",
    "train_metrics = np.zeros([FLAGS.epochs,num_edge_types,3])\n",
    "# Start training\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    t = time.time()\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        if (itr+1)%1000==0:print('Iteration',itr)\n",
    "        itr += 1\n",
    "    # Train & validation accuracy over all train data per epoch\n",
    "    print('======================================================================================================================')\n",
    "    print(\"Epoch\", \"%04d\" % (epoch + 1),'finished!')\n",
    "    print(\"Time=\", \"{:.5f}\".format(time.time()-t))\n",
    "    for r in range(num_edge_types):\n",
    "        i,j,k = minibatch.idx2edge_type[r]\n",
    "        print('Metrics for ', edge2name[i,j][k])\n",
    "        train_metrics[epoch,r,:] = get_accuracy_scores(\n",
    "            minibatch.train_edges[i,j][k], minibatch.train_edges_false[i,j][k],(i,j,k))\n",
    "        val_metrics[epoch,r,:] = get_accuracy_scores(\n",
    "            minibatch.val_edges[i,j][k], minibatch.val_edges_false[i,j][k],(i,j,k))\n",
    "        print(\"AUROC:Train=\", \"{:.4f}\".format(train_metrics[epoch,r,0])\n",
    "              ,\"Validation=\", \"{:.4f}\".format(val_metrics[epoch,r,0])\n",
    "              ,\"AUPRC:Train=\", \"{:.4f}\".format(train_metrics[epoch,r,1])\n",
    "              ,\"Validation=\", \"{:.4f}\".format(val_metrics[epoch,r,1])\n",
    "              ,\"Accuracy:Train=\", \"{:.4f}\".format(train_metrics[epoch,r,2])\n",
    "              ,\"Validation=\", \"{:.4f}\".format(val_metrics[epoch,r,2]))\n",
    "    output_data['val_metrics'] = val_metrics\n",
    "    output_data['train_metrics'] = train_metrics\n",
    "    output_data['epoch'] = epoch + 1\n",
    "    with open(out_file,'wb') as f:\n",
    "        pickle.dump(output_data, f, protocol=2)\n",
    "    \n",
    "# End of training. Metric structure handling   \n",
    "print(\"Optimization finished!\")\n",
    "test_metrics = np.zeros([num_edge_types,3])\n",
    "for et in range(num_edge_types):\n",
    "    i,j,k = minibatch.idx2edge_type[et]\n",
    "    test_metrics[et,:] = get_accuracy_scores(\n",
    "        minibatch.test_edges[i,j][k], minibatch.test_edges_false[i,j][k], (i,j,k),\n",
    "        noise=bool(noise))\n",
    "    print(\"Edge type=\", edge2name[i,j][k])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(test_metrics[et,0]))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(test_metrics[et,1]))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test Accuracy score\", \"{:.5f}\".format(test_metrics[et,2]))\n",
    "    print()\n",
    "output_data['test_metrics'] = test_metrics\n",
    "memUse = ps.memory_info()\n",
    "print('Virtual memory:', memUse.vms*1e-09,'Gb')\n",
    "print('RSS Memory:', memUse.rss*1e-09,'Gb')\n",
    "train_time=time.time()-pre_train_time\n",
    "output_data['pre_train_time'] = pre_train_time\n",
    "output_data['train_time'] = train_time\n",
    "output_data['edge2name'] = edge2name\n",
    "output_data['drug2idx'] = drug2idx\n",
    "output_data['gene2idx'] = gene2idx\n",
    "output_data['vms'] = memUse.vms\n",
    "output_data['rss'] = memUse.rss\n",
    "with open(out_file,'wb') as f:\n",
    "    pickle.dump(output_data, f, protocol=2)\n",
    "print('Total time:', datetime.timedelta(seconds=time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
