{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECAGON Training\n",
    "Test notebook for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psutil & time BEGIN\n",
    "start = time.time() #in seconds\n",
    "pid = os.getpid()\n",
    "ps= psutil.Process(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data from previous computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input file. Goes as parameter in script\n",
    "in_file = './data/data_structures/DECAGON/DECAGON_toy_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = in_file.split('_')\n",
    "DSE = False\n",
    "if 'DSE' in words: DSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzero_feat Imported successfully\n",
      "edge_type2dim Imported successfully\n",
      "adj_mats_orig Imported successfully\n",
      "edge_type2decoder Imported successfully\n",
      "degrees Imported successfully\n",
      "edge_types Imported successfully\n",
      "num_edge_types Imported successfully\n",
      "num_feat Imported successfully\n",
      "feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "with open(in_file, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(gene2idx)\n",
    "n_drugs = len(drug2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)\n",
    "print(n_genes,n_drugs,n_se_combo,n_se_mono,DSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "def accuracy(edges_pos,edges_neg,pred):\n",
    "    \"\"\"Gives the accuracy of the model given a set of positive and negative entries of \n",
    "    a matrix, and the probability scores of each entry. The method uses np.round to turn\n",
    "    probabilities into labels 0 or 1 and feed them to the accuracy_score method of sci-kit\n",
    "    learn.\n",
    "    \"\"\"\n",
    "    pos_labels = np.ones(np.shape(edges_pos)[0])\n",
    "    neg_labels = np.zeros(np.shape(edges_neg)[0])\n",
    "    labels = np.hstack((pos_labels,neg_labels))\n",
    "    pos_preds=[]\n",
    "    scores = np.round(sigmoid(pred))\n",
    "    for i,j in edges_pos:\n",
    "        pos_preds.append(scores[i,j])\n",
    "    neg_preds=[]\n",
    "    for i,j in edges_neg:\n",
    "        neg_preds.append(scores[i,j])\n",
    "    predictions=np.hstack((pos_preds,neg_preds))\n",
    "    return metrics.accuracy_score(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "\n",
    "    # Predict on set of edges\n",
    "    preds = []\n",
    "    #actual = []\n",
    "    #predicted = []\n",
    "    edge_ind = 0\n",
    "    for u, v in edges_pos[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 1, 'Problem 1'\n",
    "\n",
    "        #actual.append(edge_ind)\n",
    "        #predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "\n",
    "        #predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    #predicted = list(zip(*sorted(predicted, reverse=True, key=itemgetter(0))))[1]\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    #apk_sc = rank_metrics.apk(actual, predicted, k=50)\n",
    "    acc = metrics.accuracy_score(labels_all, np.round(preds_all))\n",
    "\n",
    "    return roc_sc, aupr_sc, acc\n",
    "\n",
    "\n",
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_size = 0.15\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 10, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 128, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')\n",
    "# Important -- Do not evaluate/print validation performance every iteration as it can take\n",
    "# substantial amount of time\n",
    "#PRINT_PROGRESS_EVERY = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHETAZO!! Soluciona el bug de Jupyter con tensorflow que proporciona un flag -f\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create minibatch iterator, model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 1, 0)\n",
      "Train edges= 9322\n",
      "Val edges= 1997\n",
      "Test edges= 1997\n",
      "Minibatch edge type: (1, 0, 0)\n",
      "Train edges= 9322\n",
      "Val edges= 1997\n",
      "Test edges= 1997\n",
      "Minibatch edge type: (0, 0, 0)\n",
      "Train edges= 9110\n",
      "Val edges= 1952\n",
      "Test edges= 1952\n",
      "Minibatch edge type: (0, 0, 1)\n",
      "Train edges= 9110\n",
      "Val edges= 1952\n",
      "Test edges= 1952\n",
      "Minibatch edge type: (1, 1, 0)\n",
      "Train edges= 5372\n",
      "Val edges= 1150\n",
      "Test edges= 1150\n",
      "Minibatch edge type: (1, 1, 1)\n",
      "Train edges= 1946\n",
      "Val edges= 0416\n",
      "Test edges= 0416\n",
      "Minibatch edge type: (1, 1, 2)\n",
      "Train edges= 0644\n",
      "Val edges= 0138\n",
      "Test edges= 0138\n",
      "Minibatch edge type: (1, 1, 3)\n",
      "Train edges= 5372\n",
      "Val edges= 1150\n",
      "Test edges= 1150\n",
      "Minibatch edge type: (1, 1, 4)\n",
      "Train edges= 1946\n",
      "Val edges= 0416\n",
      "Test edges= 0416\n",
      "Minibatch edge type: (1, 1, 5)\n",
      "Train edges= 0644\n",
      "Val edges= 0138\n",
      "Test edges= 0138\n"
     ]
    }
   ],
   "source": [
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    val_test_size=val_test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "WARNING:tensorflow:From decagon/deep/layers.py:93: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_training/sandboxish\n"
     ]
    }
   ],
   "source": [
    "#out_file = 'results_training/TRAIN_'+words[2]+DSE*('_DSE_'+str(n_se_mono))+'_genes_'+\\\n",
    "#            str(n_genes)+'_drugs_'+str(n_drugs)+'_se_'+str(n_se_combo)+'_epochs_'+\\\n",
    "#            str(FLAGS.epochs)+'_h1_'+str(FLAGS.hidden1)+'_h2_'+str(FLAGS.hidden2)+\\\n",
    "#            '_lr_'+str(FLAGS.learning_rate)+'_dropout_'+str(FLAGS.dropout)\n",
    "out_file = 'results_training/sandboxish'\n",
    "print(out_file)\n",
    "output_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Epoch: 0001 Iter: 0001 Edge: 0002 train_loss= 161.41995 val_roc= 0.62672 val_auprc= 0.60959 val_acc= 0.59144 time= 0.16558\n",
      "Epoch: 0001 Iter: 0002 Edge: 0000 train_loss= 145.39981 val_roc= 0.62651 val_auprc= 0.61276 val_acc= 0.59164 time= 0.18084\n",
      "Epoch: 0001 Iter: 0003 Edge: 0001 train_loss= 152.58696 val_roc= 0.64067 val_auprc= 0.62084 val_acc= 0.59915 time= 0.48760\n",
      "Epoch: 0001 Iter: 0004 Edge: 0006 train_loss= 174.53687 val_roc= 0.64057 val_auprc= 0.59998 val_acc= 0.61957 time= 0.02974\n",
      "Epoch: 0001 Iter: 0008 Edge: 0003 train_loss= 165.33005 val_roc= 0.60394 val_auprc= 0.59783 val_acc= 0.57787 time= 0.49870\n",
      "Epoch: 0001 Iter: 0012 Edge: 0005 train_loss= 175.33916 val_roc= 0.65800 val_auprc= 0.64688 val_acc= 0.59135 time= 0.05336\n",
      "Epoch: 0001 Iter: 0020 Edge: 0008 train_loss= 175.43875 val_roc= 0.59778 val_auprc= 0.58730 val_acc= 0.57332 time= 0.10703\n",
      "Epoch: 0001 Iter: 0028 Edge: 0004 train_loss= 175.00732 val_roc= 0.61438 val_auprc= 0.59304 val_acc= 0.57609 time= 0.10899\n",
      "Epoch: 0001 Iter: 0056 Edge: 0007 train_loss= 175.92224 val_roc= 0.59047 val_auprc= 0.57535 val_acc= 0.57348 time= 0.27478\n",
      "Epoch: 0001 Iter: 0088 Edge: 0009 train_loss= 175.05852 val_roc= 0.69775 val_auprc= 0.70202 val_acc= 0.61232 time= 0.04517\n",
      "Epoch: 0002 Iter: 0001 Edge: 0002 train_loss= 162.68741 val_roc= 0.65128 val_auprc= 0.63276 val_acc= 0.61117 time= 0.17174\n",
      "Epoch: 0002 Iter: 0002 Edge: 0000 train_loss= 148.40460 val_roc= 0.63472 val_auprc= 0.61773 val_acc= 0.59915 time= 0.17049\n",
      "Epoch: 0002 Iter: 0003 Edge: 0001 train_loss= 150.25179 val_roc= 0.64475 val_auprc= 0.62639 val_acc= 0.59239 time= 0.48454\n",
      "Epoch: 0002 Iter: 0004 Edge: 0004 train_loss= 174.01309 val_roc= 0.64305 val_auprc= 0.62300 val_acc= 0.59348 time= 0.11046\n",
      "Epoch: 0002 Iter: 0008 Edge: 0009 train_loss= 172.50949 val_roc= 0.71981 val_auprc= 0.72939 val_acc= 0.62319 time= 0.04753\n",
      "Epoch: 0002 Iter: 0012 Edge: 0008 train_loss= 173.46049 val_roc= 0.61911 val_auprc= 0.60347 val_acc= 0.58654 time= 0.10687\n",
      "Epoch: 0002 Iter: 0024 Edge: 0006 train_loss= 170.79660 val_roc= 0.67664 val_auprc= 0.63347 val_acc= 0.62319 time= 0.02848\n",
      "Epoch: 0002 Iter: 0052 Edge: 0005 train_loss= 170.19177 val_roc= 0.66392 val_auprc= 0.63779 val_acc= 0.62500 time= 0.05081\n",
      "Epoch: 0002 Iter: 0064 Edge: 0007 train_loss= 174.16745 val_roc= 0.61089 val_auprc= 0.59472 val_acc= 0.57783 time= 0.27339\n",
      "Epoch: 0002 Iter: 0124 Edge: 0003 train_loss= 161.94995 val_roc= 0.64812 val_auprc= 0.63312 val_acc= 0.60938 time= 0.46956\n",
      "Epoch: 0003 Iter: 0001 Edge: 0002 train_loss= 151.08099 val_roc= 0.66872 val_auprc= 0.64721 val_acc= 0.61629 time= 0.17436\n",
      "Epoch: 0003 Iter: 0002 Edge: 0000 train_loss= 149.98993 val_roc= 0.65808 val_auprc= 0.64226 val_acc= 0.62569 time= 0.17824\n",
      "Epoch: 0003 Iter: 0003 Edge: 0001 train_loss= 139.69598 val_roc= 0.65339 val_auprc= 0.63195 val_acc= 0.61042 time= 0.45964\n",
      "Epoch: 0003 Iter: 0004 Edge: 0004 train_loss= 166.37683 val_roc= 0.66107 val_auprc= 0.63912 val_acc= 0.61652 time= 0.10981\n",
      "Epoch: 0003 Iter: 0008 Edge: 0006 train_loss= 167.05247 val_roc= 0.69161 val_auprc= 0.65049 val_acc= 0.64130 time= 0.02802\n",
      "Epoch: 0003 Iter: 0020 Edge: 0008 train_loss= 171.15648 val_roc= 0.64542 val_auprc= 0.63419 val_acc= 0.59495 time= 0.10647\n",
      "Epoch: 0003 Iter: 0024 Edge: 0007 train_loss= 174.40831 val_roc= 0.62302 val_auprc= 0.59986 val_acc= 0.58870 time= 0.27279\n",
      "Epoch: 0003 Iter: 0036 Edge: 0005 train_loss= 169.93343 val_roc= 0.68451 val_auprc= 0.66461 val_acc= 0.63221 time= 0.04886\n",
      "Epoch: 0003 Iter: 0044 Edge: 0003 train_loss= 150.24988 val_roc= 0.67367 val_auprc= 0.65066 val_acc= 0.62398 time= 0.48073\n",
      "Epoch: 0003 Iter: 0052 Edge: 0009 train_loss= 170.08072 val_roc= 0.70978 val_auprc= 0.70372 val_acc= 0.62681 time= 0.04470\n",
      "Epoch: 0004 Iter: 0001 Edge: 0002 train_loss= 157.90862 val_roc= 0.67621 val_auprc= 0.64976 val_acc= 0.62269 time= 0.17414\n",
      "Epoch: 0004 Iter: 0002 Edge: 0000 train_loss= 137.87932 val_roc= 0.66331 val_auprc= 0.64678 val_acc= 0.61342 time= 0.17826\n",
      "Epoch: 0004 Iter: 0003 Edge: 0001 train_loss= 145.97919 val_roc= 0.66447 val_auprc= 0.65033 val_acc= 0.62018 time= 0.49356\n",
      "Epoch: 0004 Iter: 0004 Edge: 0004 train_loss= 160.88867 val_roc= 0.66936 val_auprc= 0.63985 val_acc= 0.62261 time= 0.10724\n",
      "Epoch: 0004 Iter: 0008 Edge: 0005 train_loss= 160.47333 val_roc= 0.70611 val_auprc= 0.70948 val_acc= 0.63822 time= 0.04859\n",
      "Epoch: 0004 Iter: 0024 Edge: 0007 train_loss= 164.52319 val_roc= 0.62696 val_auprc= 0.60181 val_acc= 0.59913 time= 0.27224\n",
      "Epoch: 0004 Iter: 0032 Edge: 0006 train_loss= 164.85324 val_roc= 0.71230 val_auprc= 0.68868 val_acc= 0.63768 time= 0.02842\n",
      "Epoch: 0004 Iter: 0040 Edge: 0003 train_loss= 144.00766 val_roc= 0.68712 val_auprc= 0.66386 val_acc= 0.62961 time= 0.48197\n",
      "Epoch: 0004 Iter: 0060 Edge: 0008 train_loss= 173.13321 val_roc= 0.66673 val_auprc= 0.65093 val_acc= 0.60457 time= 0.10816\n",
      "Epoch: 0004 Iter: 0064 Edge: 0009 train_loss= 166.24649 val_roc= 0.72075 val_auprc= 0.69833 val_acc= 0.63406 time= 0.04479\n",
      "Epoch: 0005 Iter: 0001 Edge: 0002 train_loss= 136.30286 val_roc= 0.68617 val_auprc= 0.65541 val_acc= 0.63038 time= 0.17617\n",
      "Epoch: 0005 Iter: 0002 Edge: 0000 train_loss= 121.46590 val_roc= 0.67377 val_auprc= 0.65413 val_acc= 0.61818 time= 0.17900\n",
      "Epoch: 0005 Iter: 0003 Edge: 0001 train_loss= 138.82666 val_roc= 0.67787 val_auprc= 0.66199 val_acc= 0.62844 time= 0.49667\n",
      "Epoch: 0005 Iter: 0004 Edge: 0004 train_loss= 166.36783 val_roc= 0.67986 val_auprc= 0.65134 val_acc= 0.64043 time= 0.11341\n",
      "Epoch: 0005 Iter: 0008 Edge: 0005 train_loss= 156.75568 val_roc= 0.72965 val_auprc= 0.73147 val_acc= 0.65144 time= 0.05051\n",
      "Epoch: 0005 Iter: 0012 Edge: 0008 train_loss= 162.36609 val_roc= 0.68211 val_auprc= 0.65878 val_acc= 0.61178 time= 0.10284\n",
      "Epoch: 0005 Iter: 0016 Edge: 0009 train_loss= 161.10428 val_roc= 0.73650 val_auprc= 0.70774 val_acc= 0.65217 time= 0.04348\n",
      "Epoch: 0005 Iter: 0020 Edge: 0007 train_loss= 160.13272 val_roc= 0.64125 val_auprc= 0.61106 val_acc= 0.61043 time= 0.26009\n",
      "Epoch: 0005 Iter: 0028 Edge: 0006 train_loss= 163.27994 val_roc= 0.72789 val_auprc= 0.69117 val_acc= 0.65580 time= 0.02738\n",
      "Epoch: 0005 Iter: 0076 Edge: 0003 train_loss= 159.56799 val_roc= 0.69996 val_auprc= 0.67585 val_acc= 0.64805 time= 0.47603\n",
      "Epoch: 0006 Iter: 0001 Edge: 0002 train_loss= 136.61346 val_roc= 0.69364 val_auprc= 0.66428 val_acc= 0.63268 time= 0.18227\n",
      "Epoch: 0006 Iter: 0002 Edge: 0000 train_loss= 128.61731 val_roc= 0.67999 val_auprc= 0.65800 val_acc= 0.62594 time= 0.18283\n",
      "Epoch: 0006 Iter: 0003 Edge: 0001 train_loss= 132.25706 val_roc= 0.68353 val_auprc= 0.66581 val_acc= 0.63420 time= 0.50407\n",
      "Epoch: 0006 Iter: 0004 Edge: 0006 train_loss= 162.55669 val_roc= 0.72453 val_auprc= 0.70148 val_acc= 0.65580 time= 0.03284\n",
      "Epoch: 0006 Iter: 0008 Edge: 0005 train_loss= 156.67630 val_roc= 0.74709 val_auprc= 0.74234 val_acc= 0.68750 time= 0.05183\n",
      "Epoch: 0006 Iter: 0016 Edge: 0008 train_loss= 162.43608 val_roc= 0.67875 val_auprc= 0.63960 val_acc= 0.62981 time= 0.10712\n",
      "Epoch: 0006 Iter: 0028 Edge: 0009 train_loss= 161.77280 val_roc= 0.71330 val_auprc= 0.69347 val_acc= 0.64493 time= 0.04764\n",
      "Epoch: 0006 Iter: 0032 Edge: 0007 train_loss= 158.18320 val_roc= 0.65153 val_auprc= 0.61910 val_acc= 0.61478 time= 0.27825\n",
      "Epoch: 0006 Iter: 0036 Edge: 0003 train_loss= 141.54190 val_roc= 0.71247 val_auprc= 0.68742 val_acc= 0.64524 time= 0.47844\n",
      "Epoch: 0006 Iter: 0052 Edge: 0004 train_loss= 159.09903 val_roc= 0.68738 val_auprc= 0.65784 val_acc= 0.63609 time= 0.11973\n",
      "Epoch: 0007 Iter: 0001 Edge: 0002 train_loss= 134.39517 val_roc= 0.69807 val_auprc= 0.66482 val_acc= 0.63397 time= 0.17632\n",
      "Epoch: 0007 Iter: 0002 Edge: 0000 train_loss= 127.79430 val_roc= 0.68531 val_auprc= 0.65897 val_acc= 0.62569 time= 0.18285\n",
      "Epoch: 0007 Iter: 0003 Edge: 0001 train_loss= 127.90477 val_roc= 0.68463 val_auprc= 0.67030 val_acc= 0.62994 time= 0.49347\n",
      "Epoch: 0007 Iter: 0004 Edge: 0007 train_loss= 159.62738 val_roc= 0.66776 val_auprc= 0.63838 val_acc= 0.62652 time= 0.28064\n",
      "Epoch: 0007 Iter: 0008 Edge: 0005 train_loss= 162.38528 val_roc= 0.74716 val_auprc= 0.74342 val_acc= 0.69231 time= 0.04988\n",
      "Epoch: 0007 Iter: 0020 Edge: 0006 train_loss= 152.01523 val_roc= 0.74202 val_auprc= 0.72385 val_acc= 0.67391 time= 0.03030\n",
      "Epoch: 0007 Iter: 0024 Edge: 0003 train_loss= 141.01733 val_roc= 0.72308 val_auprc= 0.69478 val_acc= 0.65881 time= 0.48187\n",
      "Epoch: 0007 Iter: 0032 Edge: 0009 train_loss= 157.81415 val_roc= 0.73320 val_auprc= 0.68951 val_acc= 0.64493 time= 0.05031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0007 Iter: 0044 Edge: 0004 train_loss= 162.65570 val_roc= 0.68885 val_auprc= 0.65391 val_acc= 0.64000 time= 0.10970\n",
      "Epoch: 0007 Iter: 0048 Edge: 0008 train_loss= 159.59547 val_roc= 0.68723 val_auprc= 0.64578 val_acc= 0.63582 time= 0.10767\n",
      "Epoch: 0008 Iter: 0001 Edge: 0002 train_loss= 141.78574 val_roc= 0.70150 val_auprc= 0.66783 val_acc= 0.64114 time= 0.16120\n",
      "Epoch: 0008 Iter: 0002 Edge: 0000 train_loss= 127.41438 val_roc= 0.68813 val_auprc= 0.66236 val_acc= 0.62369 time= 0.16909\n",
      "Epoch: 0008 Iter: 0003 Edge: 0001 train_loss= 121.40729 val_roc= 0.68899 val_auprc= 0.67799 val_acc= 0.63195 time= 0.48758\n",
      "Epoch: 0008 Iter: 0004 Edge: 0009 train_loss= 157.51274 val_roc= 0.72343 val_auprc= 0.68358 val_acc= 0.65580 time= 0.04569\n",
      "Epoch: 0008 Iter: 0008 Edge: 0003 train_loss= 148.59723 val_roc= 0.72832 val_auprc= 0.69972 val_acc= 0.66675 time= 0.47857\n",
      "Epoch: 0008 Iter: 0012 Edge: 0006 train_loss= 155.69644 val_roc= 0.75063 val_auprc= 0.73887 val_acc= 0.69203 time= 0.02738\n",
      "Epoch: 0008 Iter: 0020 Edge: 0005 train_loss= 156.48347 val_roc= 0.74575 val_auprc= 0.74966 val_acc= 0.67668 time= 0.05091\n",
      "Epoch: 0008 Iter: 0052 Edge: 0007 train_loss= 161.01593 val_roc= 0.66979 val_auprc= 0.64097 val_acc= 0.62826 time= 0.25893\n",
      "Epoch: 0008 Iter: 0056 Edge: 0008 train_loss= 158.64105 val_roc= 0.69246 val_auprc= 0.64843 val_acc= 0.64663 time= 0.10162\n",
      "Epoch: 0008 Iter: 0084 Edge: 0004 train_loss= 159.18878 val_roc= 0.70357 val_auprc= 0.66569 val_acc= 0.65304 time= 0.10871\n",
      "Epoch: 0009 Iter: 0001 Edge: 0002 train_loss= 135.66080 val_roc= 0.71164 val_auprc= 0.67757 val_acc= 0.65318 time= 0.18052\n",
      "Epoch: 0009 Iter: 0002 Edge: 0000 train_loss= 119.69606 val_roc= 0.68735 val_auprc= 0.66136 val_acc= 0.63145 time= 0.17084\n",
      "Epoch: 0009 Iter: 0003 Edge: 0001 train_loss= 122.40044 val_roc= 0.69269 val_auprc= 0.67719 val_acc= 0.63245 time= 0.48504\n",
      "Epoch: 0009 Iter: 0004 Edge: 0006 train_loss= 143.13391 val_roc= 0.78219 val_auprc= 0.77751 val_acc= 0.68841 time= 0.02926\n",
      "Epoch: 0009 Iter: 0008 Edge: 0004 train_loss= 159.74852 val_roc= 0.70891 val_auprc= 0.66710 val_acc= 0.65348 time= 0.11120\n",
      "Epoch: 0009 Iter: 0012 Edge: 0005 train_loss= 159.38025 val_roc= 0.74459 val_auprc= 0.74534 val_acc= 0.67067 time= 0.05670\n",
      "Epoch: 0009 Iter: 0016 Edge: 0003 train_loss= 149.93320 val_roc= 0.73621 val_auprc= 0.70249 val_acc= 0.67751 time= 0.49036\n",
      "Epoch: 0009 Iter: 0028 Edge: 0007 train_loss= 164.50060 val_roc= 0.68181 val_auprc= 0.64661 val_acc= 0.63696 time= 0.28932\n",
      "Epoch: 0009 Iter: 0036 Edge: 0008 train_loss= 166.51215 val_roc= 0.69720 val_auprc= 0.65370 val_acc= 0.66226 time= 0.10797\n",
      "Epoch: 0009 Iter: 0100 Edge: 0009 train_loss= 153.74315 val_roc= 0.74207 val_auprc= 0.70388 val_acc= 0.67391 time= 0.04507\n",
      "Epoch: 0010 Iter: 0001 Edge: 0002 train_loss= 130.35416 val_roc= 0.71203 val_auprc= 0.67817 val_acc= 0.64498 time= 0.18830\n",
      "Epoch: 0010 Iter: 0002 Edge: 0000 train_loss= 139.57954 val_roc= 0.69801 val_auprc= 0.66716 val_acc= 0.63320 time= 0.19392\n",
      "Epoch: 0010 Iter: 0003 Edge: 0001 train_loss= 131.60828 val_roc= 0.69553 val_auprc= 0.68184 val_acc= 0.63395 time= 0.50331\n",
      "Epoch: 0010 Iter: 0004 Edge: 0005 train_loss= 160.10785 val_roc= 0.76041 val_auprc= 0.75130 val_acc= 0.69712 time= 0.05092\n",
      "Epoch: 0010 Iter: 0012 Edge: 0006 train_loss= 162.82053 val_roc= 0.77552 val_auprc= 0.75794 val_acc= 0.72826 time= 0.02832\n",
      "Epoch: 0010 Iter: 0016 Edge: 0008 train_loss= 154.02411 val_roc= 0.71524 val_auprc= 0.66614 val_acc= 0.66947 time= 0.10848\n",
      "Epoch: 0010 Iter: 0020 Edge: 0003 train_loss= 148.38893 val_roc= 0.74488 val_auprc= 0.71802 val_acc= 0.66752 time= 0.49703\n",
      "Epoch: 0010 Iter: 0028 Edge: 0009 train_loss= 157.52716 val_roc= 0.73167 val_auprc= 0.69859 val_acc= 0.65217 time= 0.04563\n",
      "Epoch: 0010 Iter: 0044 Edge: 0007 train_loss= 160.60507 val_roc= 0.68468 val_auprc= 0.65319 val_acc= 0.63348 time= 0.27315\n",
      "Epoch: 0010 Iter: 0052 Edge: 0004 train_loss= 158.44878 val_roc= 0.70902 val_auprc= 0.66855 val_acc= 0.64565 time= 0.10432\n",
      "Optimization finished!\n",
      "Edge type= [00, 01, 00]\n",
      "Edge type: 0000 Test AUROC score 0.70259\n",
      "Edge type: 0000 Test AUPRC score 0.67596\n",
      "Edge type: 0000 Test Accuracy score 0.64196\n",
      "\n",
      "Edge type= [01, 00, 00]\n",
      "Edge type: 0001 Test AUROC score 0.70233\n",
      "Edge type: 0001 Test AUPRC score 0.67857\n",
      "Edge type: 0001 Test Accuracy score 0.64321\n",
      "\n",
      "Edge type= [00, 00, 00]\n",
      "Edge type: 0002 Test AUROC score 0.71116\n",
      "Edge type: 0002 Test AUPRC score 0.67121\n",
      "Edge type: 0002 Test Accuracy score 0.64088\n",
      "\n",
      "Edge type= [00, 00, 01]\n",
      "Edge type: 0003 Test AUROC score 0.76227\n",
      "Edge type: 0003 Test AUPRC score 0.72703\n",
      "Edge type: 0003 Test Accuracy score 0.69570\n",
      "\n",
      "Edge type= [01, 01, 00]\n",
      "Edge type: 0004 Test AUROC score 0.72729\n",
      "Edge type: 0004 Test AUPRC score 0.69816\n",
      "Edge type: 0004 Test Accuracy score 0.65435\n",
      "\n",
      "Edge type= [01, 01, 01]\n",
      "Edge type: 0005 Test AUROC score 0.74183\n",
      "Edge type: 0005 Test AUPRC score 0.71058\n",
      "Edge type: 0005 Test Accuracy score 0.67909\n",
      "\n",
      "Edge type= [01, 01, 02]\n",
      "Edge type: 0006 Test AUROC score 0.77872\n",
      "Edge type: 0006 Test AUPRC score 0.80160\n",
      "Edge type: 0006 Test Accuracy score 0.68841\n",
      "\n",
      "Edge type= [01, 01, 03]\n",
      "Edge type: 0007 Test AUROC score 0.69056\n",
      "Edge type: 0007 Test AUPRC score 0.65259\n",
      "Edge type: 0007 Test Accuracy score 0.63609\n",
      "\n",
      "Edge type= [01, 01, 04]\n",
      "Edge type: 0008 Test AUROC score 0.70573\n",
      "Edge type: 0008 Test AUPRC score 0.67505\n",
      "Edge type: 0008 Test Accuracy score 0.64183\n",
      "\n",
      "Edge type= [01, 01, 05]\n",
      "Edge type: 0009 Test AUROC score 0.79610\n",
      "Edge type: 0009 Test AUPRC score 0.76047\n",
      "Edge type: 0009 Test Accuracy score 0.71377\n",
      "\n",
      "Virtual memory: 3327901696\n",
      "RSS Memory: 385654784\n",
      "Total time: 301.56019783\n"
     ]
    }
   ],
   "source": [
    "# Metric structures initialization\n",
    "validation_metrics = np.zeros([num_edge_types,3,1])\n",
    "train_acc = np.zeros([FLAGS.epochs,num_edge_types])\n",
    "val_acc = np.zeros([FLAGS.epochs,num_edge_types])\n",
    "vm_layer = np.zeros([num_edge_types,3,1])\n",
    "# Start training\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    edge_count = range(num_edge_types)\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "        t = time.time()\n",
    "\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        train_cost = outs[1]\n",
    "        batch_edge_type = outs[2]\n",
    "        # Metrics\n",
    "        if batch_edge_type in edge_count:\n",
    "            val_auc, val_auprc, val_acs = get_accuracy_scores(\n",
    "                minibatch.val_edges, minibatch.val_edges_false,\n",
    "                minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n",
    "            step_time = time.time() - t\n",
    "            vm_layer[batch_edge_type,:,0] = [val_auc,val_auprc,val_acs]\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch + 1), \"Iter:\", \"%04d\" % (itr + 1), \n",
    "                  \"Edge:\", \"%04d\" % batch_edge_type,\n",
    "                  \"train_loss=\", \"{:.5f}\".format(train_cost),\n",
    "                  \"val_roc=\", \"{:.5f}\".format(val_auc),\n",
    "                  \"val_auprc=\", \"{:.5f}\".format(val_auprc),\n",
    "                  \"val_acc=\", \"{:.5f}\".format(val_acs),\n",
    "                  \"time=\", \"{:.5f}\".format(step_time))\n",
    "            edge_count.remove(batch_edge_type)\n",
    "        itr += 1\n",
    "    # Train accuracy over all train data per epoch\n",
    "    for r in range(num_edge_types):\n",
    "        i,j,k = minibatch.idx2edge_type[r]\n",
    "        true_train_edges = minibatch.train_edges[i,j][k]\n",
    "        false_train_edges = minibatch.train_edges_false[i,j][k]\n",
    "        true_val_edges = minibatch.val_edges[i,j][k]\n",
    "        false_val_edges = minibatch.val_edges_false[i,j][k]\n",
    "        feed_dict.update({placeholders['batch_edge_type_idx']:k})\n",
    "        feed_dict.update({placeholders['batch_row_edge_type']: i})\n",
    "        feed_dict.update({placeholders['batch_col_edge_type']: j})\n",
    "        pred = sess.run(opt.predictions,feed_dict=feed_dict)\n",
    "        train_acc[epoch,r] = accuracy(true_train_edges,false_train_edges,pred)\n",
    "        val_acc[epoch,r] = accuracy(true_val_edges,false_val_edges,pred)\n",
    "    validation_metrics = np.concatenate((validation_metrics,vm_layer),axis=2)\n",
    "    output_data['val_auc'] = validation_metrics[:,0,1:]\n",
    "    output_data['val_auprc'] = validation_metrics[:,1,1:]\n",
    "    output_data['train_acc'] = train_acc\n",
    "    output_data['val_acc'] = val_acc\n",
    "    output_data['epoch'] = epoch + 1\n",
    "    \n",
    "    with open(out_file,'wb') as f:\n",
    "        pickle.dump(output_data, f, protocol=2)\n",
    "    vm_layer = np.zeros([num_edge_types,3,1])\n",
    "    \n",
    "# End of training. Metric structure handling   \n",
    "print(\"Optimization finished!\")\n",
    "test_scores = np.zeros([num_edge_types,3])\n",
    "for et in range(num_edge_types):\n",
    "    roc_score, auprc_score, acc_score = get_accuracy_scores(\n",
    "        minibatch.test_edges, minibatch.test_edges_false, minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type=\", \"[%02d, %02d, %02d]\" % minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(roc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(auprc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test Accuracy score\", \"{:.5f}\".format(acc_score))\n",
    "    print()\n",
    "    test_scores[et,0] = roc_score\n",
    "    test_scores[et,1] = auprc_score\n",
    "    test_scores[et,2] = acc_score\n",
    "output_data['test_scores'] = test_scores\n",
    "memUse = ps.memory_info()\n",
    "print('Virtual memory:', memUse.vms)\n",
    "print('RSS Memory:', memUse.rss)\n",
    "total_time=time.time()-start\n",
    "output_data['time'] = total_time\n",
    "output_data['vms'] = memUse.vms\n",
    "output_data['rss'] = memUse.rss\n",
    "with open(out_file,'wb') as f:\n",
    "    pickle.dump(output_data, f, protocol=2)\n",
    "print(\"Total time:\",total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
