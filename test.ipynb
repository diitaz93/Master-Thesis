{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECAGON Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psutil & time BEGIN\n",
    "start = time.time() #in seconds\n",
    "pid = os.getpid()\n",
    "ps= psutil.Process(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data from previous computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzero_feat Imported successfully\n",
      "edge_type2dim Imported successfully\n",
      "adj_mats_orig Imported successfully\n",
      "edge_type2decoder Imported successfully\n",
      "degrees Imported successfully\n",
      "edge_types Imported successfully\n",
      "num_edge_types Imported successfully\n",
      "num_feat Imported successfully\n",
      "feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "filename = './data/data_structures/DECAGON_toy_test'\n",
    "with open(filename, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    edge_ind = 0\n",
    "    for u, v in edges_pos[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 1, 'Problem 1'\n",
    "\n",
    "        actual.append(edge_ind)\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    predicted = list(zip(*sorted(predicted, reverse=True, key=itemgetter(0))))[1]\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    apk_sc = rank_metrics.apk(actual, predicted, k=50)\n",
    "\n",
    "    return roc_sc, aupr_sc, apk_sc\n",
    "\n",
    "\n",
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_size = 0.05\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 10, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 512, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')\n",
    "# Important -- Do not evaluate/print validation performance every iteration as it can take\n",
    "# substantial amount of time\n",
    "PRINT_PROGRESS_EVERY = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHETAZO!! Soluciona el bug de Jupyter con tensorflow que proporciona un flag -f\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create minibatch iterator, model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 1, 0)\n",
      "Constructing test edges= 0000/0665\n",
      "Constructing val edges= 0000/0665\n",
      "Constructing val edges= 0000/0665\n",
      "Train edges= 11986\n",
      "Val edges= 0665\n",
      "Test edges= 0665\n",
      "Minibatch edge type: (1, 0, 0)\n",
      "Constructing test edges= 0000/0665\n",
      "Constructing val edges= 0000/0665\n",
      "Train edges= 11986\n",
      "Val edges= 0665\n",
      "Test edges= 0665\n",
      "Minibatch edge type: (0, 0, 0)\n",
      "Constructing test edges= 0000/0650\n",
      "Constructing val edges= 0000/0650\n",
      "Train edges= 11714\n",
      "Val edges= 0650\n",
      "Test edges= 0650\n",
      "Minibatch edge type: (0, 0, 1)\n",
      "Constructing test edges= 0000/0650\n",
      "Constructing val edges= 0000/0650\n",
      "Train edges= 11714\n",
      "Val edges= 0650\n",
      "Test edges= 0650\n",
      "Minibatch edge type: (1, 1, 0)\n",
      "Constructing test edges= 0000/0383\n",
      "Constructing val edges= 0000/0383\n",
      "Train edges= 6906\n",
      "Val edges= 0383\n",
      "Test edges= 0383\n",
      "Minibatch edge type: (1, 1, 1)\n",
      "Constructing test edges= 0000/0138\n",
      "Constructing val edges= 0000/0138\n",
      "Train edges= 2502\n",
      "Val edges= 0138\n",
      "Test edges= 0138\n",
      "Minibatch edge type: (1, 1, 2)\n",
      "Constructing test edges= 0000/0046\n",
      "Constructing val edges= 0000/0046\n",
      "Train edges= 0828\n",
      "Val edges= 0046\n",
      "Test edges= 0046\n",
      "Minibatch edge type: (1, 1, 3)\n",
      "Constructing test edges= 0000/0383\n",
      "Constructing val edges= 0000/0383\n",
      "Train edges= 6906\n",
      "Val edges= 0383\n",
      "Test edges= 0383\n",
      "Minibatch edge type: (1, 1, 4)\n",
      "Constructing test edges= 0000/0138\n",
      "Constructing val edges= 0000/0138\n",
      "Train edges= 2502\n",
      "Val edges= 0138\n",
      "Test edges= 0138\n",
      "Minibatch edge type: (1, 1, 5)\n",
      "Constructing test edges= 0000/0046\n",
      "Constructing val edges= 0000/0046\n",
      "Train edges= 0828\n",
      "Val edges= 0046\n",
      "Test edges= 0046\n"
     ]
    }
   ],
   "source": [
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    val_test_size=val_test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "WARNING:tensorflow:From decagon/deep/layers.py:93: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Epoch: 0001 Iter: 0001 Edge: 0002 train_loss= 557.94562 val_roc= 0.71192 val_auprc= 0.68438 val_apk= 0.65474 time= 0.07134\n",
      "Epoch: 0001 Iter: 0151 Edge: 0001 train_loss= 550.27295 val_roc= 0.71594 val_auprc= 0.68531 val_apk= 0.71362 time= 0.16719\n",
      "Epoch: 0002 Iter: 0001 Edge: 0002 train_loss= 552.69592 val_roc= 0.72050 val_auprc= 0.69492 val_apk= 0.63013 time= 0.07132\n",
      "Epoch: 0002 Iter: 0151 Edge: 0001 train_loss= 539.16388 val_roc= 0.72270 val_auprc= 0.68543 val_apk= 0.68936 time= 0.17845\n",
      "Epoch: 0003 Iter: 0001 Edge: 0002 train_loss= 553.98279 val_roc= 0.72247 val_auprc= 0.69524 val_apk= 0.58001 time= 0.07528\n",
      "Epoch: 0003 Iter: 0151 Edge: 0001 train_loss= 535.97430 val_roc= 0.72556 val_auprc= 0.68574 val_apk= 0.68847 time= 0.17800\n",
      "Epoch: 0004 Iter: 0001 Edge: 0002 train_loss= 546.29865 val_roc= 0.72842 val_auprc= 0.70356 val_apk= 0.66018 time= 0.07433\n",
      "Epoch: 0004 Iter: 0151 Edge: 0001 train_loss= 552.33130 val_roc= 0.72637 val_auprc= 0.68703 val_apk= 0.63862 time= 0.17393\n",
      "Epoch: 0005 Iter: 0001 Edge: 0002 train_loss= 533.62122 val_roc= 0.72213 val_auprc= 0.69702 val_apk= 0.67149 time= 0.07238\n",
      "Epoch: 0005 Iter: 0151 Edge: 0001 train_loss= 553.59985 val_roc= 0.72819 val_auprc= 0.69307 val_apk= 0.65970 time= 0.17870\n",
      "Epoch: 0006 Iter: 0001 Edge: 0002 train_loss= 549.16199 val_roc= 0.72510 val_auprc= 0.69000 val_apk= 0.59971 time= 0.07001\n",
      "Epoch: 0006 Iter: 0151 Edge: 0001 train_loss= 526.48212 val_roc= 0.72305 val_auprc= 0.69375 val_apk= 0.75298 time= 0.17094\n",
      "Epoch: 0007 Iter: 0001 Edge: 0002 train_loss= 536.84290 val_roc= 0.72979 val_auprc= 0.69583 val_apk= 0.58852 time= 0.07491\n",
      "Epoch: 0007 Iter: 0151 Edge: 0001 train_loss= 514.82184 val_roc= 0.72831 val_auprc= 0.69539 val_apk= 0.70860 time= 0.17868\n",
      "Epoch: 0008 Iter: 0001 Edge: 0002 train_loss= 554.86151 val_roc= 0.73305 val_auprc= 0.69826 val_apk= 0.63788 time= 0.08148\n",
      "Epoch: 0008 Iter: 0151 Edge: 0001 train_loss= 536.98419 val_roc= 0.72902 val_auprc= 0.69641 val_apk= 0.71442 time= 0.18374\n",
      "Epoch: 0009 Iter: 0001 Edge: 0002 train_loss= 530.15295 val_roc= 0.73160 val_auprc= 0.70351 val_apk= 0.70290 time= 0.07443\n",
      "Epoch: 0009 Iter: 0151 Edge: 0001 train_loss= 533.85687 val_roc= 0.73093 val_auprc= 0.69204 val_apk= 0.65929 time= 0.18235\n",
      "Epoch: 0010 Iter: 0001 Edge: 0002 train_loss= 504.81073 val_roc= 0.73223 val_auprc= 0.70428 val_apk= 0.73416 time= 0.07566\n",
      "Epoch: 0010 Iter: 0151 Edge: 0001 train_loss= 508.94452 val_roc= 0.73762 val_auprc= 0.69796 val_apk= 0.64965 time= 0.18026\n",
      "Optimization finished!\n",
      "Edge type= [00, 01, 00]\n",
      "Edge type: 0000 Test AUROC score 0.73073\n",
      "Edge type: 0000 Test AUPRC score 0.70167\n",
      "Edge type: 0000 Test AP@k score 0.68273\n",
      "\n",
      "Edge type= [01, 00, 00]\n",
      "Edge type: 0001 Test AUROC score 0.72111\n",
      "Edge type: 0001 Test AUPRC score 0.67861\n",
      "Edge type: 0001 Test AP@k score 0.49946\n",
      "\n",
      "Edge type= [00, 00, 00]\n",
      "Edge type: 0002 Test AUROC score 0.73453\n",
      "Edge type: 0002 Test AUPRC score 0.69452\n",
      "Edge type: 0002 Test AP@k score 0.58692\n",
      "\n",
      "Edge type= [00, 00, 01]\n",
      "Edge type: 0003 Test AUROC score 0.80844\n",
      "Edge type: 0003 Test AUPRC score 0.76656\n",
      "Edge type: 0003 Test AP@k score 0.63935\n",
      "\n",
      "Edge type= [01, 01, 00]\n",
      "Edge type: 0004 Test AUROC score 0.77740\n",
      "Edge type: 0004 Test AUPRC score 0.72634\n",
      "Edge type: 0004 Test AP@k score 0.57031\n",
      "\n",
      "Edge type= [01, 01, 01]\n",
      "Edge type: 0005 Test AUROC score 0.74454\n",
      "Edge type: 0005 Test AUPRC score 0.70429\n",
      "Edge type: 0005 Test AP@k score 0.58011\n",
      "\n",
      "Edge type= [01, 01, 02]\n",
      "Edge type: 0006 Test AUROC score 0.75567\n",
      "Edge type: 0006 Test AUPRC score 0.69963\n",
      "Edge type: 0006 Test AP@k score 0.54536\n",
      "\n",
      "Edge type= [01, 01, 03]\n",
      "Edge type: 0007 Test AUROC score 0.73493\n",
      "Edge type: 0007 Test AUPRC score 0.68451\n",
      "Edge type: 0007 Test AP@k score 0.45073\n",
      "\n",
      "Edge type= [01, 01, 04]\n",
      "Edge type: 0008 Test AUROC score 0.73094\n",
      "Edge type: 0008 Test AUPRC score 0.69825\n",
      "Edge type: 0008 Test AP@k score 0.58707\n",
      "\n",
      "Edge type= [01, 01, 05]\n",
      "Edge type: 0009 Test AUROC score 0.75331\n",
      "Edge type: 0009 Test AUPRC score 0.74018\n",
      "Edge type: 0009 Test AP@k score 0.56983\n",
      "\n",
      "Virtual memory: 3327107072\n",
      "RSS Memory: 394539008\n",
      "Total time: 276.809416056\n"
     ]
    }
   ],
   "source": [
    "acc_scores = np.array([None,None,None,None,None])\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        train_cost = outs[1]\n",
    "        batch_edge_type = outs[2]\n",
    "\n",
    "        if itr % PRINT_PROGRESS_EVERY == 0:\n",
    "            val_auc, val_auprc, val_apk = get_accuracy_scores(\n",
    "                minibatch.val_edges, minibatch.val_edges_false,\n",
    "                minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n",
    "            step_time = time.time() - t\n",
    "            acc_scores = np.vstack([acc_scores,[val_auc,val_auprc,val_apk,train_cost,step_time]])\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch + 1), \"Iter:\", \"%04d\" % (itr + 1), \"Edge:\", \"%04d\" % batch_edge_type,\n",
    "                  \"train_loss=\", \"{:.5f}\".format(train_cost),\n",
    "                  \"val_roc=\", \"{:.5f}\".format(val_auc), \"val_auprc=\", \"{:.5f}\".format(val_auprc),\n",
    "                  \"val_apk=\", \"{:.5f}\".format(val_apk), \"time=\", \"{:.5f}\".format(step_time))\n",
    "        itr += 1\n",
    "        \n",
    "acc_scores=acc_scores[1:,:]\n",
    "output_data = {}\n",
    "output_data['val_auc'] = acc_scores[:,0]\n",
    "output_data['val_auprc'] = acc_scores[:,1]\n",
    "output_data['val_apk'] = acc_scores[:,2]\n",
    "output_data['train_cost'] = acc_scores[:,3]\n",
    "output_data['step_time'] = acc_scores[:,4]\n",
    "print(\"Optimization finished!\")\n",
    "for et in range(num_edge_types):\n",
    "    roc_score, auprc_score, apk_score = get_accuracy_scores(\n",
    "        minibatch.test_edges, minibatch.test_edges_false, minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type=\", \"[%02d, %02d, %02d]\" % minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(roc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(auprc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AP@k score\", \"{:.5f}\".format(apk_score))\n",
    "    print()\n",
    "memUse = ps.memory_info()\n",
    "print('Virtual memory:', memUse.vms)\n",
    "print('RSS Memory:', memUse.rss)\n",
    "total_time=time.time()-start\n",
    "output_data['time'] = total_time\n",
    "output_data['vms'] = memUse.vms\n",
    "output_data['rss'] = memUse.rss\n",
    "print(\"Total time:\",total_time)\n",
    "filename = 'results_training/TRAIN_toy_test_epochs'+str(FLAGS.epochs)+'_h1'+str(FLAGS.hidden1)+\\\n",
    "           '_h2'+str(FLAGS.hidden2)+'_lr'+str(FLAGS.learning_rate)+'dropout'+str(FLAGS.dropout)\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(output_data, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
