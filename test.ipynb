{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECAGON Training\n",
    "Test notebook for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psutil & time BEGIN\n",
    "start = time.time() #in seconds\n",
    "pid = os.getpid()\n",
    "ps= psutil.Process(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data from previous computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input file. Goes as parameter in script\n",
    "in_file = './data/data_structures/DECAGON/DECAGON_toy_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = in_file.split('_')\n",
    "DSE = False\n",
    "if 'DSE' in words: DSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzero_feat Imported successfully\n",
      "edge_type2dim Imported successfully\n",
      "adj_mats_orig Imported successfully\n",
      "edge_type2decoder Imported successfully\n",
      "degrees Imported successfully\n",
      "edge_types Imported successfully\n",
      "num_edge_types Imported successfully\n",
      "num_feat Imported successfully\n",
      "feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "with open(in_file, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = len(gene2idx)\n",
    "n_drugs = len(drug2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)\n",
    "print(n_genes,n_drugs,n_se_combo,n_se_mono,DSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    edge_ind = 0\n",
    "    for u, v in edges_pos[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 1, 'Problem 1'\n",
    "\n",
    "        actual.append(edge_ind)\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    predicted = list(zip(*sorted(predicted, reverse=True, key=itemgetter(0))))[1]\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    apk_sc = rank_metrics.apk(actual, predicted, k=50)\n",
    "\n",
    "    return roc_sc, aupr_sc, apk_sc\n",
    "\n",
    "\n",
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_size = 0.15\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 50, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 128, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')\n",
    "# Important -- Do not evaluate/print validation performance every iteration as it can take\n",
    "# substantial amount of time\n",
    "PRINT_PROGRESS_EVERY = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHETAZO!! Soluciona el bug de Jupyter con tensorflow que proporciona un flag -f\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create minibatch iterator, model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 1, 0)\n",
      "Constructing test edges= 0000/1997\n",
      "Constructing test edges= 1000/1997\n",
      "Constructing val edges= 0000/1997\n",
      "Constructing val edges= 1000/1997\n",
      "Train edges= 9322\n",
      "Val edges= 1997\n",
      "Test edges= 1997\n",
      "Minibatch edge type: (1, 0, 0)\n",
      "Constructing test edges= 0000/1997\n",
      "Constructing test edges= 1000/1997\n",
      "Constructing val edges= 0000/1997\n",
      "Constructing val edges= 1000/1997\n",
      "Train edges= 9322\n",
      "Val edges= 1997\n",
      "Test edges= 1997\n",
      "Minibatch edge type: (0, 0, 0)\n",
      "Constructing test edges= 0000/1952\n",
      "Constructing test edges= 1000/1952\n",
      "Constructing val edges= 0000/1952\n",
      "Constructing val edges= 1000/1952\n",
      "Train edges= 9110\n",
      "Val edges= 1952\n",
      "Test edges= 1952\n",
      "Minibatch edge type: (0, 0, 1)\n",
      "Constructing test edges= 0000/1952\n",
      "Constructing test edges= 1000/1952\n",
      "Constructing val edges= 0000/1952\n",
      "Constructing val edges= 1000/1952\n",
      "Train edges= 9110\n",
      "Val edges= 1952\n",
      "Test edges= 1952\n",
      "Minibatch edge type: (1, 1, 0)\n",
      "Constructing test edges= 0000/1150\n",
      "Constructing test edges= 1000/1150\n",
      "Constructing val edges= 0000/1150\n",
      "Constructing val edges= 1000/1150\n",
      "Train edges= 5372\n",
      "Val edges= 1150\n",
      "Test edges= 1150\n",
      "Minibatch edge type: (1, 1, 1)\n",
      "Constructing test edges= 0000/0416\n",
      "Constructing val edges= 0000/0416\n",
      "Train edges= 1946\n",
      "Val edges= 0416\n",
      "Test edges= 0416\n",
      "Minibatch edge type: (1, 1, 2)\n",
      "Constructing test edges= 0000/0138\n",
      "Constructing val edges= 0000/0138\n",
      "Train edges= 0644\n",
      "Val edges= 0138\n",
      "Test edges= 0138\n",
      "Minibatch edge type: (1, 1, 3)\n",
      "Constructing test edges= 0000/1150\n",
      "Constructing test edges= 1000/1150\n",
      "Constructing val edges= 0000/1150\n",
      "Constructing val edges= 0000/1150\n",
      "Constructing val edges= 1000/1150\n",
      "Train edges= 5372\n",
      "Val edges= 1150\n",
      "Test edges= 1150\n",
      "Minibatch edge type: (1, 1, 4)\n",
      "Constructing test edges= 0000/0416\n",
      "Constructing val edges= 0000/0416\n",
      "Train edges= 1946\n",
      "Val edges= 0416\n",
      "Test edges= 0416\n",
      "Minibatch edge type: (1, 1, 5)\n",
      "Constructing test edges= 0000/0138\n",
      "Constructing val edges= 0000/0138\n",
      "Train edges= 0644\n",
      "Val edges= 0138\n",
      "Test edges= 0138\n"
     ]
    }
   ],
   "source": [
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    val_test_size=val_test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0): 2,\n",
       " (0, 0, 1): 3,\n",
       " (0, 1, 0): 0,\n",
       " (1, 0, 0): 1,\n",
       " (1, 1, 0): 4,\n",
       " (1, 1, 1): 5,\n",
       " (1, 1, 2): 6,\n",
       " (1, 1, 3): 7,\n",
       " (1, 1, 4): 8,\n",
       " (1, 1, 5): 9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch.edge_type2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "WARNING:tensorflow:From decagon/deep/layers.py:93: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Print() takes at least 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-89bb157a9285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Print() takes at least 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "tf.Print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_training/sandboxish\n"
     ]
    }
   ],
   "source": [
    "#out_file = 'results_training/TRAIN_'+words[2]+DSE*('_DSE_'+str(n_se_mono))+'_genes_'+\\\n",
    "#            str(n_genes)+'_drugs_'+str(n_drugs)+'_se_'+str(n_se_combo)+'_epochs_'+\\\n",
    "#            str(FLAGS.epochs)+'_h1_'+str(FLAGS.hidden1)+'_h2_'+str(FLAGS.hidden2)+\\\n",
    "#            '_lr_'+str(FLAGS.learning_rate)+'_dropout_'+str(FLAGS.dropout)\n",
    "out_file = 'results_training/sandboxish'\n",
    "print(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2062ba3dc7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             train_auc, train_auprc, train_apk = get_accuracy_scores(\n\u001b[1;32m     27\u001b[0m                 \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m#val_auc, val_auprc, val_apk = get_accuracy_scores(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m              \u001b[0;31m#   minibatch.val_edges, minibatch.val_edges_false,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-dfa82f35de1b>\u001b[0m in \u001b[0;36mget_accuracy_scores\u001b[0;34m(edges_pos, edges_neg, edge_type)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mroc_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0maupr_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mapk_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/sklearn/metrics/base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    269\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "output_data = {}\n",
    "acc_scores = np.zeros([num_edge_types,4,1])\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    acc_layer = np.zeros([num_edge_types,4,1])\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    edge_count = range(num_edge_types)\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        train_cost = outs[1]\n",
    "        batch_edge_type = outs[2]\n",
    "\n",
    "        #if itr % PRINT_PROGRESS_EVERY == 0:\n",
    "        if batch_edge_type in edge_count:\n",
    "            val_auc, val_auprc, val_apk = get_accuracy_scores(\n",
    "                minibatch.val_edges, minibatch.val_edges_false,\n",
    "                minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n",
    "            step_time = time.time() - t\n",
    "            acc_layer[batch_edge_type,:,0] = [val_auc,val_auprc,val_apk,train_cost]\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch + 1), \"Iter:\", \"%04d\" % (itr + 1), \"Edge:\", \"%04d\" % batch_edge_type,\n",
    "                  \"train_loss=\", \"{:.5f}\".format(train_cost),\n",
    "                  \"val_roc=\", \"{:.5f}\".format(val_auc), \"val_auprc=\", \"{:.5f}\".format(val_auprc),\n",
    "                  \"val_apk=\", \"{:.5f}\".format(val_apk), \"time=\", \"{:.5f}\".format(step_time))\n",
    "            edge_count.remove(batch_edge_type)\n",
    "        itr += 1\n",
    "    acc_scores = np.concatenate((acc_scores,acc_layer),axis=2)\n",
    "    output_data['val_auc'] = acc_scores[:,0,1:]\n",
    "    output_data['val_auprc'] = acc_scores[:,1,1:]\n",
    "    output_data['val_apk'] = acc_scores[:,2,1:]\n",
    "    output_data['train_cost'] = acc_scores[:,3,1:]\n",
    "    output_data['epoch'] = epoch + 1\n",
    "    with open(out_file,'wb') as f:\n",
    "        pickle.dump(output_data, f, protocol=2)\n",
    "    acc_layer = np.zeros([num_edge_types,4,1])\n",
    "    \n",
    "print(\"Optimization finished!\")\n",
    "final_scores = np.zeros([num_edge_types,4,1])\n",
    "for et in range(num_edge_types):\n",
    "    roc_score, auprc_score, apk_score = get_accuracy_scores(\n",
    "        minibatch.test_edges, minibatch.test_edges_false, minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type=\", \"[%02d, %02d, %02d]\" % minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(roc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(auprc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AP@k score\", \"{:.5f}\".format(apk_score))\n",
    "    print()\n",
    "    final_scores[et,0,0] = roc_score\n",
    "    final_scores[et,1,0] = auprc_score\n",
    "    final_scores[et,2,0] = apk_score\n",
    "acc_scores = np.concatenate((acc_scores,final_scores),axis=2)\n",
    "output_data['val_auc'] = acc_scores[:,0,1:]\n",
    "output_data['val_auprc'] = acc_scores[:,1,1:]\n",
    "output_data['val_apk'] = acc_scores[:,2,1:]\n",
    "output_data['train_cost'] = acc_scores[:,3,1:]\n",
    "memUse = ps.memory_info()\n",
    "print('Virtual memory:', memUse.vms)\n",
    "print('RSS Memory:', memUse.rss)\n",
    "total_time=time.time()-start\n",
    "output_data['time'] = total_time\n",
    "output_data['vms'] = memUse.vms\n",
    "output_data['rss'] = memUse.rss\n",
    "with open(out_file,'wb') as f:\n",
    "    pickle.dump(output_data, f, protocol=2)\n",
    "print(\"Total time:\",total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
