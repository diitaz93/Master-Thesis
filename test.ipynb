{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECAGON Training\n",
    "Test notebook for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psutil & time BEGIN\n",
    "start = time.time() #in seconds\n",
    "pid = os.getpid()\n",
    "ps= psutil.Process(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data from previous computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input file. Goes as parameter in script\n",
    "in_file = './data/data_structures/DECAGON/DECAGON_toy_genes_500_drugs_400_se_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = in_file.split('_')\n",
    "DSE = False\n",
    "BDM = False\n",
    "DOCK = False\n",
    "BIND = False\n",
    "if 'DSE' in words: DSE = True\n",
    "if 'BDM' in words: BDM = True\n",
    "if 'docking' in words: DOCK = True\n",
    "elif 'binding' in words: BIND = True\n",
    "d_text = DOCK*'_docking'+BIND*'_binding'\n",
    "noise = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge2name Imported successfully\n",
      "se_mono_name2idx Imported successfully\n",
      "gene2idx Imported successfully\n",
      "nonzero_feat Imported successfully\n",
      "edge_type2dim Imported successfully\n",
      "adj_mats_orig Imported successfully\n",
      "edge_type2decoder Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "degrees Imported successfully\n",
      "edge_types Imported successfully\n",
      "num_edge_types Imported successfully\n",
      "num_feat Imported successfully\n",
      "feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "with open(in_file, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 400 4 600 False\n"
     ]
    }
   ],
   "source": [
    "n_genes = len(gene2idx)\n",
    "n_drugs = len(drug2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)\n",
    "print(n_genes,n_drugs,n_se_combo,n_se_mono,DSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    \"\"\" Returns the AUROC, AUPRC and Accuracy of the dataset corresponding to the edge\n",
    "    'edge_type' given as a tuple. The parameters 'edges_pos' and 'edges_neg' are the list \n",
    "    of edges of positive and negative interactions respectively of a given dataset, i.e., \n",
    "    train, test or validation.\n",
    "    \"\"\"\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "    # Predict on set of edges\n",
    "    preds = []\n",
    "    for u, v in edges_pos:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] > 0, 'Problem 1'\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    acc = metrics.accuracy_score(labels_all, np.round(preds_all))\n",
    "\n",
    "    return roc_sc, aupr_sc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_size = 0.15\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 10, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 128, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHETAZO!! Soluciona el bug de Jupyter con tensorflow que proporciona un flag -f\n",
    "flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_structures/MINIBATCH/MINIBATCH_toy_genes_500_drugs_400_se_4_batchsize_128_valsize_0.15\n"
     ]
    }
   ],
   "source": [
    "if noise == 0:\n",
    "    noise_str = ''\n",
    "else:\n",
    "    noise_str = '_noise_' + str(noise)\n",
    "\n",
    "mb_file = 'data/data_structures/MINIBATCH/MINIBATCH_'+words[2]+d_text+\\\n",
    "            '_genes_'+str(n_genes)+'_drugs_'+\\\n",
    "            str(n_drugs)+'_se_'+str(n_se_combo)+'_batchsize_'+str(FLAGS.batch_size)+\\\n",
    "            '_valsize_'+str(val_test_size) + noise_str\n",
    "print(mb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mb_file, 'rb') as f:\n",
    "    minibatch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch.feat = feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "WARNING:tensorflow:From decagon/deep/layers.py:93: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}\n",
    "pre_train_time = time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_training/TRAIN_toy_genes_500_drugs_400_se_4_epochs_10_h1_64_h2_32_lr_0.001_dropout_0.1_valsize_0.15\n"
     ]
    }
   ],
   "source": [
    "out_file = 'results_training/TRAIN_'+words[2]+d_text+DSE*('_DSE_'+str(n_se_mono))+BDM*('_BDM')\\\n",
    "            +'_genes_'+str(n_genes)+'_drugs_'+str(n_drugs)+'_se_'+str(n_se_combo)+'_epochs_'+\\\n",
    "            str(FLAGS.epochs)+'_h1_'+str(FLAGS.hidden1)+'_h2_'+str(FLAGS.hidden2)+\\\n",
    "            '_lr_'+str(FLAGS.learning_rate)+'_dropout_'+str(FLAGS.dropout)+'_valsize_'+\\\n",
    "            str(val_test_size) + noise_str\n",
    "#out_file = 'results_training/sandboxish'\n",
    "print(out_file)\n",
    "output_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "======================================================================================================================\n",
      "Epoch 0001 finished!\n",
      "Time= 7.33325\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.8293 Validation= 0.6550 AUPRC:Train= 0.8723 Validation= 0.6046 Accuracy:Train= 0.8123 Validation= 0.6038\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.8376 Validation= 0.6216 AUPRC:Train= 0.8851 Validation= 0.6427 Accuracy:Train= 0.7925 Validation= 0.5377\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9643 Validation= 0.7716 AUPRC:Train= 0.9450 Validation= 0.7566 Accuracy:Train= 0.9165 Validation= 0.7554\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5086 Validation= 0.4986 AUPRC:Train= 0.5075 Validation= 0.5035 Accuracy:Train= 0.5061 Validation= 0.4923\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.4986 Validation= 0.4984 AUPRC:Train= 0.4973 Validation= 0.4913 Accuracy:Train= 0.4962 Validation= 0.4977\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5146 Validation= 0.5087 AUPRC:Train= 0.5107 Validation= 0.5019 Accuracy:Train= 0.5132 Validation= 0.5213\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.5780 Validation= 0.5568 AUPRC:Train= 0.5672 Validation= 0.5493 Accuracy:Train= 0.5599 Validation= 0.5351\n",
      "======================================================================================================================\n",
      "Epoch 0002 finished!\n",
      "Time= 6.14785\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9295 Validation= 0.7490 AUPRC:Train= 0.9389 Validation= 0.7269 Accuracy:Train= 0.8735 Validation= 0.6226\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9103 Validation= 0.6867 AUPRC:Train= 0.9359 Validation= 0.7397 Accuracy:Train= 0.8498 Validation= 0.6038\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9793 Validation= 0.8130 AUPRC:Train= 0.9630 Validation= 0.7953 Accuracy:Train= 0.9490 Validation= 0.8261\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5100 Validation= 0.4891 AUPRC:Train= 0.5071 Validation= 0.4924 Accuracy:Train= 0.5068 Validation= 0.4923\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5076 Validation= 0.4959 AUPRC:Train= 0.5033 Validation= 0.4930 Accuracy:Train= 0.5057 Validation= 0.4917\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5120 Validation= 0.5135 AUPRC:Train= 0.5147 Validation= 0.5084 Accuracy:Train= 0.5041 Validation= 0.5270\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.5827 Validation= 0.5383 AUPRC:Train= 0.5790 Validation= 0.5395 Accuracy:Train= 0.5524 Validation= 0.5351\n",
      "======================================================================================================================\n",
      "Epoch 0003 finished!\n",
      "Time= 6.16893\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9301 Validation= 0.7896 AUPRC:Train= 0.9398 Validation= 0.7745 Accuracy:Train= 0.8794 Validation= 0.6792\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9492 Validation= 0.7067 AUPRC:Train= 0.9616 Validation= 0.7394 Accuracy:Train= 0.8636 Validation= 0.6226\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9903 Validation= 0.8358 AUPRC:Train= 0.9792 Validation= 0.8483 Accuracy:Train= 0.9652 Validation= 0.8207\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5108 Validation= 0.4898 AUPRC:Train= 0.5111 Validation= 0.4936 Accuracy:Train= 0.5068 Validation= 0.4908\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5188 Validation= 0.4918 AUPRC:Train= 0.5114 Validation= 0.4956 Accuracy:Train= 0.5081 Validation= 0.4990\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5302 Validation= 0.5170 AUPRC:Train= 0.5272 Validation= 0.5035 Accuracy:Train= 0.5243 Validation= 0.5124\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.6032 Validation= 0.4795 AUPRC:Train= 0.5816 Validation= 0.4903 Accuracy:Train= 0.5693 Validation= 0.4825\n",
      "======================================================================================================================\n",
      "Epoch 0004 finished!\n",
      "Time= 6.15905\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9665 Validation= 0.7882 AUPRC:Train= 0.9637 Validation= 0.7788 Accuracy:Train= 0.9111 Validation= 0.6604\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9804 Validation= 0.7868 AUPRC:Train= 0.9857 Validation= 0.8184 Accuracy:Train= 0.9308 Validation= 0.6415\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9958 Validation= 0.8565 AUPRC:Train= 0.9953 Validation= 0.8720 Accuracy:Train= 0.9698 Validation= 0.8261\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5141 Validation= 0.4920 AUPRC:Train= 0.5136 Validation= 0.4966 Accuracy:Train= 0.5078 Validation= 0.4863\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5279 Validation= 0.4918 AUPRC:Train= 0.5201 Validation= 0.4999 Accuracy:Train= 0.5174 Validation= 0.4980\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5544 Validation= 0.5077 AUPRC:Train= 0.5473 Validation= 0.5060 Accuracy:Train= 0.5300 Validation= 0.5079\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.6352 Validation= 0.5060 AUPRC:Train= 0.6100 Validation= 0.5181 Accuracy:Train= 0.5674 Validation= 0.5000\n",
      "======================================================================================================================\n",
      "Epoch 0005 finished!\n",
      "Time= 6.16380\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9772 Validation= 0.8070 AUPRC:Train= 0.9742 Validation= 0.8006 Accuracy:Train= 0.9348 Validation= 0.7170\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9854 Validation= 0.8085 AUPRC:Train= 0.9879 Validation= 0.8376 Accuracy:Train= 0.9308 Validation= 0.6604\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9978 Validation= 0.8622 AUPRC:Train= 0.9974 Validation= 0.8804 Accuracy:Train= 0.9780 Validation= 0.8587\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5168 Validation= 0.4929 AUPRC:Train= 0.5165 Validation= 0.4978 Accuracy:Train= 0.5111 Validation= 0.4916\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5321 Validation= 0.4913 AUPRC:Train= 0.5238 Validation= 0.4979 Accuracy:Train= 0.5189 Validation= 0.4931\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5737 Validation= 0.5240 AUPRC:Train= 0.5645 Validation= 0.5065 Accuracy:Train= 0.5444 Validation= 0.5146\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.6498 Validation= 0.4792 AUPRC:Train= 0.6179 Validation= 0.4933 Accuracy:Train= 0.5955 Validation= 0.4737\n",
      "======================================================================================================================\n",
      "Epoch 0006 finished!\n",
      "Time= 6.22984\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9858 Validation= 0.8063 AUPRC:Train= 0.9833 Validation= 0.8268 Accuracy:Train= 0.9407 Validation= 0.7170\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9899 Validation= 0.7910 AUPRC:Train= 0.9917 Validation= 0.8107 Accuracy:Train= 0.9565 Validation= 0.6509\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9963 Validation= 0.8710 AUPRC:Train= 0.9902 Validation= 0.9128 Accuracy:Train= 0.9791 Validation= 0.8533\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5250 Validation= 0.4965 AUPRC:Train= 0.5219 Validation= 0.4978 Accuracy:Train= 0.5189 Validation= 0.4998\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5382 Validation= 0.4989 AUPRC:Train= 0.5297 Validation= 0.4997 Accuracy:Train= 0.5271 Validation= 0.4934\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.5900 Validation= 0.5182 AUPRC:Train= 0.5767 Validation= 0.5077 Accuracy:Train= 0.5581 Validation= 0.5045\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.6706 Validation= 0.5008 AUPRC:Train= 0.6466 Validation= 0.5267 Accuracy:Train= 0.6124 Validation= 0.4912\n",
      "======================================================================================================================\n",
      "Epoch 0007 finished!\n",
      "Time= 6.20060\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9897 Validation= 0.8117 AUPRC:Train= 0.9875 Validation= 0.8328 Accuracy:Train= 0.9466 Validation= 0.7264\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9927 Validation= 0.8042 AUPRC:Train= 0.9933 Validation= 0.8175 Accuracy:Train= 0.9625 Validation= 0.6321\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9969 Validation= 0.8736 AUPRC:Train= 0.9879 Validation= 0.9130 Accuracy:Train= 0.9849 Validation= 0.8696\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5254 Validation= 0.4979 AUPRC:Train= 0.5238 Validation= 0.4997 Accuracy:Train= 0.5182 Validation= 0.4987\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5429 Validation= 0.4945 AUPRC:Train= 0.5339 Validation= 0.4958 Accuracy:Train= 0.5307 Validation= 0.4861\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.6103 Validation= 0.5112 AUPRC:Train= 0.5953 Validation= 0.5054 Accuracy:Train= 0.5795 Validation= 0.5034\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7036 Validation= 0.5362 AUPRC:Train= 0.6723 Validation= 0.5448 Accuracy:Train= 0.6442 Validation= 0.5175\n",
      "======================================================================================================================\n",
      "Epoch 0008 finished!\n",
      "Time= 6.17848\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9849 Validation= 0.7985 AUPRC:Train= 0.9755 Validation= 0.8011 Accuracy:Train= 0.9565 Validation= 0.6792\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9977 Validation= 0.8238 AUPRC:Train= 0.9975 Validation= 0.8559 Accuracy:Train= 0.9545 Validation= 0.6509\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9990 Validation= 0.8775 AUPRC:Train= 0.9991 Validation= 0.9200 Accuracy:Train= 0.9780 Validation= 0.8587\n",
      "Metrics for  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:Train= 0.5316 Validation= 0.4991 AUPRC:Train= 0.5280 Validation= 0.5018 Accuracy:Train= 0.5242 Validation= 0.4997\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5471 Validation= 0.4957 AUPRC:Train= 0.5383 Validation= 0.4956 Accuracy:Train= 0.5311 Validation= 0.4980\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.6337 Validation= 0.5262 AUPRC:Train= 0.6162 Validation= 0.5155 Accuracy:Train= 0.6036 Validation= 0.5213\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7034 Validation= 0.5057 AUPRC:Train= 0.6770 Validation= 0.5342 Accuracy:Train= 0.6536 Validation= 0.5000\n",
      "======================================================================================================================\n",
      "Epoch 0009 finished!\n",
      "Time= 6.16144\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9845 Validation= 0.7761 AUPRC:Train= 0.9759 Validation= 0.7691 Accuracy:Train= 0.9605 Validation= 0.6509\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9933 Validation= 0.8014 AUPRC:Train= 0.9946 Validation= 0.8385 Accuracy:Train= 0.9447 Validation= 0.6415\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9976 Validation= 0.8694 AUPRC:Train= 0.9952 Validation= 0.9157 Accuracy:Train= 0.9861 Validation= 0.8587\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5386 Validation= 0.5090 AUPRC:Train= 0.5327 Validation= 0.5051 Accuracy:Train= 0.5291 Validation= 0.5074\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5570 Validation= 0.4950 AUPRC:Train= 0.5460 Validation= 0.4940 Accuracy:Train= 0.5417 Validation= 0.4960\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.6534 Validation= 0.5433 AUPRC:Train= 0.6319 Validation= 0.5243 Accuracy:Train= 0.6163 Validation= 0.5180\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7217 Validation= 0.4925 AUPRC:Train= 0.7040 Validation= 0.5225 Accuracy:Train= 0.6498 Validation= 0.4737\n",
      "======================================================================================================================\n",
      "Epoch 0010 finished!\n",
      "Time= 6.17199\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9876 Validation= 0.8003 AUPRC:Train= 0.9814 Validation= 0.8148 Accuracy:Train= 0.9644 Validation= 0.7075\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9975 Validation= 0.8067 AUPRC:Train= 0.9976 Validation= 0.8403 Accuracy:Train= 0.9704 Validation= 0.6698\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9965 Validation= 0.8776 AUPRC:Train= 0.9865 Validation= 0.9211 Accuracy:Train= 0.9861 Validation= 0.8696\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.5393 Validation= 0.5085 AUPRC:Train= 0.5337 Validation= 0.5060 Accuracy:Train= 0.5291 Validation= 0.5101\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.5638 Validation= 0.4974 AUPRC:Train= 0.5514 Validation= 0.4977 Accuracy:Train= 0.5449 Validation= 0.4937\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.6596 Validation= 0.5248 AUPRC:Train= 0.6390 Validation= 0.5127 Accuracy:Train= 0.6199 Validation= 0.5090\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.7440 Validation= 0.4872 AUPRC:Train= 0.7275 Validation= 0.5255 Accuracy:Train= 0.6573 Validation= 0.5175\n",
      "Optimization finished!\n",
      "Edge type= DTI\n",
      "Edge type: 0000 Test AUROC score 0.76860\n",
      "Edge type: 0000 Test AUPRC score 0.76933\n",
      "Edge type: 0000 Test Accuracy score 0.71698\n",
      "\n",
      "Edge type= TDI\n",
      "Edge type: 0001 Test AUROC score 0.81666\n",
      "Edge type: 0001 Test AUPRC score 0.85494\n",
      "Edge type: 0001 Test Accuracy score 0.68868\n",
      "\n",
      "Edge type= PPI\n",
      "Edge type: 0002 Test AUROC score 0.83648\n",
      "Edge type: 0002 Test AUPRC score 0.89408\n",
      "Edge type: 0002 Test Accuracy score 0.85326\n",
      "\n",
      "Edge type= 0\n",
      "Edge type: 0003 Test AUROC score 0.52355\n",
      "Edge type: 0003 Test AUPRC score 0.52113\n",
      "Edge type: 0003 Test Accuracy score 0.52121\n",
      "\n",
      "Edge type= 1\n",
      "Edge type: 0004 Test AUROC score 0.53040\n",
      "Edge type: 0004 Test AUPRC score 0.51973\n",
      "Edge type: 0004 Test Accuracy score 0.53111\n",
      "\n",
      "Edge type= 2\n",
      "Edge type: 0005 Test AUROC score 0.54506\n",
      "Edge type: 0005 Test AUPRC score 0.54439\n",
      "Edge type: 0005 Test Accuracy score 0.53371\n",
      "\n",
      "Edge type= 3\n",
      "Edge type: 0006 Test AUROC score 0.62358\n",
      "Edge type: 0006 Test AUPRC score 0.59407\n",
      "Edge type: 0006 Test Accuracy score 0.63158\n",
      "\n",
      "Virtual memory: 3.259588608 Gb\n",
      "RSS Memory: 0.347918336 Gb\n",
      "Total time: 0:07:25.367894\n"
     ]
    }
   ],
   "source": [
    "# Metric structures initialization\n",
    "val_metrics = np.zeros([FLAGS.epochs,num_edge_types,3])\n",
    "train_metrics = np.zeros([FLAGS.epochs,num_edge_types,3])\n",
    "# Start training\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    t = time.time()\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        if (itr+1)%1000==0:print('Iteration',itr)\n",
    "        itr += 1\n",
    "    # Train & validation accuracy over all train data per epoch\n",
    "    print('======================================================================================================================')\n",
    "    print(\"Epoch\", \"%04d\" % (epoch + 1),'finished!')\n",
    "    print(\"Time=\", \"{:.5f}\".format(time.time()-t))\n",
    "    for r in range(num_edge_types):\n",
    "        i,j,k = minibatch.idx2edge_type[r]\n",
    "        print('Metrics for ', edge2name[i,j][k])\n",
    "        train_metrics[epoch,r,:] = get_accuracy_scores(\n",
    "            minibatch.train_edges[i,j][k], minibatch.train_edges_false[i,j][k],(i,j,k))\n",
    "        val_metrics[epoch,r,:] = get_accuracy_scores(\n",
    "            minibatch.val_edges[i,j][k], minibatch.val_edges_false[i,j][k],(i,j,k))\n",
    "        print(\"AUROC:Train=\", \"{:.4f}\".format(train_metrics[epoch,r,0])\n",
    "              ,\"Validation=\", \"{:.4f}\".format(val_metrics[epoch,r,0])\n",
    "              ,\"AUPRC:Train=\", \"{:.4f}\".format(train_metrics[epoch,r,1])\n",
    "              ,\"Validation=\", \"{:.4f}\".format(val_metrics[epoch,r,1])\n",
    "              ,\"Accuracy:Train=\", \"{:.4f}\".format(train_metrics[epoch,r,2])\n",
    "              ,\"Validation=\", \"{:.4f}\".format(val_metrics[epoch,r,2]))\n",
    "    output_data['val_metrics'] = val_metrics\n",
    "    output_data['train_metrics'] = train_metrics\n",
    "    output_data['epoch'] = epoch + 1\n",
    "    with open(out_file,'wb') as f:\n",
    "        pickle.dump(output_data, f, protocol=2)\n",
    "    \n",
    "# End of training. Metric structure handling   \n",
    "print(\"Optimization finished!\")\n",
    "test_metrics = np.zeros([num_edge_types,3])\n",
    "for et in range(num_edge_types):\n",
    "    i,j,k = minibatch.idx2edge_type[et]\n",
    "    test_metrics[et,:] = get_accuracy_scores(\n",
    "        minibatch.test_edges[i,j][k], minibatch.test_edges_false[i,j][k], (i,j,k))\n",
    "    print(\"Edge type=\", edge2name[i,j][k])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(test_metrics[et,0]))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(test_metrics[et,1]))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test Accuracy score\", \"{:.5f}\".format(test_metrics[et,2]))\n",
    "    print()\n",
    "output_data['test_metrics'] = test_metrics\n",
    "memUse = ps.memory_info()\n",
    "print('Virtual memory:', memUse.vms*1e-09,'Gb')\n",
    "print('RSS Memory:', memUse.rss*1e-09,'Gb')\n",
    "train_time=time.time()-pre_train_time\n",
    "output_data['pre_train_time'] = pre_train_time\n",
    "output_data['train_time'] = train_time\n",
    "output_data['edge2name'] = edge2name\n",
    "output_data['drug2idx'] = drug2idx\n",
    "output_data['gene2idx'] = gene2idx\n",
    "output_data['vms'] = memUse.vms\n",
    "output_data['rss'] = memUse.rss\n",
    "with open(out_file,'wb') as f:\n",
    "    pickle.dump(output_data, f, protocol=2)\n",
    "print('Total time:', datetime.timedelta(seconds=time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
