{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECAGON Training\n",
    "Test notebook for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psutil & time BEGIN\n",
    "start = time.time() #in seconds\n",
    "pid = os.getpid()\n",
    "ps= psutil.Process(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data from previous computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input file. Goes as parameter in script\n",
    "in_file = './data/data_structures/DECAGON/DECAGON_toy_genes_500_drugs_400_se_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = in_file.split('_')\n",
    "DSE = False\n",
    "if 'DSE' in words: DSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se_mono_name2idx Imported successfully\n",
      "gene2idx Imported successfully\n",
      "nonzero_feat Imported successfully\n",
      "edge_type2dim Imported successfully\n",
      "adj_mats_orig Imported successfully\n",
      "edge_type2decoder Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "degrees Imported successfully\n",
      "edge_types Imported successfully\n",
      "num_edge_types Imported successfully\n",
      "num_feat Imported successfully\n",
      "feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "with open(in_file, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 400 4 600 False\n"
     ]
    }
   ],
   "source": [
    "n_genes = len(gene2idx)\n",
    "n_drugs = len(drug2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)\n",
    "print(n_genes,n_drugs,n_se_combo,n_se_mono,DSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "def accuracy(edges_pos,edges_neg,pred):\n",
    "    \"\"\"Gives the accuracy of the model given a set of positive and negative entries of \n",
    "    a matrix, and the probability scores of each entry. The method uses np.round to turn\n",
    "    probabilities into labels 0 or 1 and feed them to the accuracy_score method of sci-kit\n",
    "    learn.\n",
    "    \"\"\"\n",
    "    pos_labels = np.ones(np.shape(edges_pos)[0])\n",
    "    neg_labels = np.zeros(np.shape(edges_neg)[0])\n",
    "    labels = np.hstack((pos_labels,neg_labels))\n",
    "    pos_preds=[]\n",
    "    scores = np.round(sigmoid(pred))\n",
    "    for i,j in edges_pos:\n",
    "        pos_preds.append(scores[i,j])\n",
    "    neg_preds=[]\n",
    "    for i,j in edges_neg:\n",
    "        neg_preds.append(scores[i,j])\n",
    "    predictions=np.hstack((pos_preds,neg_preds))\n",
    "    return metrics.accuracy_score(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "\n",
    "    # Predict on set of edges\n",
    "    preds = []\n",
    "    #actual = []\n",
    "    #predicted = []\n",
    "    edge_ind = 0\n",
    "    for u, v in edges_pos[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 1, 'Problem 1'\n",
    "\n",
    "        #actual.append(edge_ind)\n",
    "        #predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "\n",
    "        #predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    #predicted = list(zip(*sorted(predicted, reverse=True, key=itemgetter(0))))[1]\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    #apk_sc = rank_metrics.apk(actual, predicted, k=50)\n",
    "    acc = metrics.accuracy_score(labels_all, np.round(preds_all))\n",
    "\n",
    "    return roc_sc, aupr_sc, acc\n",
    "\n",
    "\n",
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_size = 0.15\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 10, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 128, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')\n",
    "# Important -- Do not evaluate/print validation performance every iteration as it can take\n",
    "# substantial amount of time\n",
    "#PRINT_PROGRESS_EVERY = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHETAZO!! Soluciona el bug de Jupyter con tensorflow que proporciona un flag -f\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create minibatch iterator, model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 1, 0)\n",
      "Constructing test edges= 0000/0053\n",
      "Constructing val edges= 0000/0053\n",
      "Constructing train edges= 0000/0253\n",
      "Train edges= 0253\n",
      "Val edges= 0053\n",
      "Test edges= 0053\n",
      "Minibatch edge type: (1, 0, 0)\n",
      "Constructing test edges= 0000/0053\n",
      "Constructing val edges= 0000/0053\n",
      "Constructing train edges= 0000/0253\n",
      "Train edges= 0253\n",
      "Val edges= 0053\n",
      "Test edges= 0053\n",
      "Minibatch edge type: (0, 0, 0)\n",
      "Constructing test edges= 0000/0092\n",
      "Constructing val edges= 0000/0092\n",
      "Constructing train edges= 0000/0431\n",
      "Train edges= 0431\n",
      "Val edges= 0092\n",
      "Test edges= 0092\n",
      "Minibatch edge type: (0, 0, 1)\n",
      "Constructing test edges= 0000/0092\n",
      "Constructing val edges= 0000/0092\n",
      "Constructing train edges= 0000/0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decagon/deep/minibatch.py:78: RuntimeWarning: divide by zero encountered in power\n",
      "  rowdegree_mat_inv = sp.diags(np.nan_to_num(np.power(rowsum, -0.5)).flatten())\n",
      "decagon/deep/minibatch.py:79: RuntimeWarning: divide by zero encountered in power\n",
      "  coldegree_mat_inv = sp.diags(np.nan_to_num(np.power(colsum, -0.5)).flatten())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train edges= 0431\n",
      "Val edges= 0092\n",
      "Test edges= 0092\n",
      "Minibatch edge type: (1, 1, 0)\n",
      "Constructing test edges= 0000/3112\n",
      "Constructing test edges= 1000/3112\n",
      "Constructing test edges= 2000/3112\n",
      "Constructing test edges= 3000/3112\n",
      "Constructing val edges= 0000/3112\n",
      "Constructing val edges= 1000/3112\n",
      "Constructing val edges= 2000/3112\n",
      "Constructing val edges= 3000/3112\n",
      "Constructing train edges= 0000/14529\n",
      "Constructing train edges= 1000/14529\n",
      "Constructing train edges= 2000/14529\n",
      "Constructing train edges= 3000/14529\n",
      "Constructing train edges= 4000/14529\n",
      "Constructing train edges= 5000/14529\n",
      "Constructing train edges= 6000/14529\n",
      "Constructing train edges= 7000/14529\n",
      "Constructing train edges= 8000/14529\n",
      "Constructing train edges= 9000/14529\n",
      "Constructing train edges= 9000/14529\n",
      "Constructing train edges= 10000/14529\n",
      "Constructing train edges= 10000/14529\n",
      "Constructing train edges= 11000/14529\n",
      "Constructing train edges= 11000/14529\n",
      "Constructing train edges= 11000/14529\n",
      "Constructing train edges= 11000/14529\n",
      "Constructing train edges= 12000/14529\n",
      "Constructing train edges= 12000/14529\n",
      "Constructing train edges= 13000/14529\n",
      "Constructing train edges= 14000/14529\n",
      "Train edges= 14529\n",
      "Val edges= 3112\n",
      "Test edges= 3112\n",
      "Minibatch edge type: (1, 1, 1)\n",
      "Constructing test edges= 0000/1511\n",
      "Constructing test edges= 1000/1511\n",
      "Constructing val edges= 0000/1511\n",
      "Constructing val edges= 1000/1511\n",
      "Constructing train edges= 0000/7054\n",
      "Constructing train edges= 1000/7054\n",
      "Constructing train edges= 2000/7054\n",
      "Constructing train edges= 3000/7054\n",
      "Constructing train edges= 4000/7054\n",
      "Constructing train edges= 5000/7054\n",
      "Constructing train edges= 6000/7054\n",
      "Constructing train edges= 7000/7054\n",
      "Train edges= 7054\n",
      "Val edges= 1511\n",
      "Test edges= 1511\n",
      "Minibatch edge type: (1, 1, 2)\n",
      "Constructing test edges= 0000/0445\n",
      "Constructing val edges= 0000/0445\n",
      "Constructing train edges= 0000/2081\n",
      "Constructing train edges= 1000/2081\n",
      "Constructing train edges= 2000/2081\n",
      "Train edges= 2081\n",
      "Val edges= 0445\n",
      "Test edges= 0445\n",
      "Minibatch edge type: (1, 1, 3)\n",
      "Constructing test edges= 0000/0057\n",
      "Constructing val edges= 0000/0057\n",
      "Constructing train edges= 0000/0267\n",
      "Train edges= 0267\n",
      "Val edges= 0057\n",
      "Test edges= 0057\n",
      "Minibatch edge type: (1, 1, 4)\n",
      "Constructing test edges= 0000/3112\n",
      "Constructing test edges= 0000/3112\n",
      "Constructing test edges= 1000/3112\n",
      "Constructing test edges= 2000/3112\n",
      "Constructing test edges= 3000/3112\n",
      "Constructing val edges= 0000/3112\n",
      "Constructing val edges= 1000/3112\n",
      "Constructing val edges= 2000/3112\n",
      "Constructing val edges= 3000/3112\n",
      "Constructing train edges= 0000/14529\n",
      "Constructing train edges= 1000/14529\n",
      "Constructing train edges= 1000/14529\n",
      "Constructing train edges= 2000/14529\n",
      "Constructing train edges= 3000/14529\n",
      "Constructing train edges= 3000/14529\n",
      "Constructing train edges= 4000/14529\n",
      "Constructing train edges= 5000/14529\n",
      "Constructing train edges= 6000/14529\n",
      "Constructing train edges= 7000/14529\n",
      "Constructing train edges= 8000/14529\n",
      "Constructing train edges= 9000/14529\n",
      "Constructing train edges= 10000/14529\n",
      "Constructing train edges= 11000/14529\n",
      "Constructing train edges= 12000/14529\n",
      "Constructing train edges= 13000/14529\n",
      "Constructing train edges= 14000/14529\n",
      "Constructing train edges= 14000/14529\n",
      "Constructing train edges= 14000/14529\n",
      "Train edges= 14529\n",
      "Val edges= 3112\n",
      "Test edges= 3112\n",
      "Minibatch edge type: (1, 1, 5)\n",
      "Constructing test edges= 0000/1511\n",
      "Constructing test edges= 1000/1511\n",
      "Constructing val edges= 0000/1511\n",
      "Constructing val edges= 1000/1511\n",
      "Constructing train edges= 0000/7054\n",
      "Constructing train edges= 1000/7054\n",
      "Constructing train edges= 2000/7054\n",
      "Constructing train edges= 3000/7054\n",
      "Constructing train edges= 4000/7054\n",
      "Constructing train edges= 5000/7054\n",
      "Constructing train edges= 5000/7054\n",
      "Constructing train edges= 5000/7054\n",
      "Constructing train edges= 6000/7054\n",
      "Constructing train edges= 7000/7054\n",
      "Train edges= 7054\n",
      "Val edges= 1511\n",
      "Test edges= 1511\n",
      "Minibatch edge type: (1, 1, 6)\n",
      "Constructing test edges= 0000/0445\n",
      "Constructing val edges= 0000/0445\n",
      "Constructing train edges= 0000/2081\n",
      "Constructing train edges= 1000/2081\n",
      "Constructing train edges= 2000/2081\n",
      "Train edges= 2081\n",
      "Val edges= 0445\n",
      "Test edges= 0445\n",
      "Minibatch edge type: (1, 1, 7)\n",
      "Constructing test edges= 0000/0057\n",
      "Constructing val edges= 0000/0057\n",
      "Constructing train edges= 0000/0267\n",
      "Train edges= 0267\n",
      "Val edges= 0057\n",
      "Test edges= 0057\n"
     ]
    }
   ],
   "source": [
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    val_test_size=val_test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "WARNING:tensorflow:From decagon/deep/layers.py:93: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_training/TRAIN_toy_genes_500_drugs_400_se_4_epochs_10_h1_64_h2_32_lr_0.001_dropout_0.1\n"
     ]
    }
   ],
   "source": [
    "out_file = 'results_training/TRAIN_'+words[2]+DSE*('_DSE_'+str(n_se_mono))+'_genes_'+\\\n",
    "            str(n_genes)+'_drugs_'+str(n_drugs)+'_se_'+str(n_se_combo)+'_epochs_'+\\\n",
    "            str(FLAGS.epochs)+'_h1_'+str(FLAGS.hidden1)+'_h2_'+str(FLAGS.hidden2)+\\\n",
    "            '_lr_'+str(FLAGS.learning_rate)+'_dropout_'+str(FLAGS.dropout)\n",
    "#out_file = 'results_training/sandboxish'\n",
    "print(out_file)\n",
    "output_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Epoch: 0001 Iter: 0001 Edge: 0002 train_loss= 179.18739 val_roc= 0.49256 val_auprc= 0.48815 val_acc= 0.50000 time= 1.49997\n",
      "Epoch: 0001 Iter: 0002 Edge: 0000 train_loss= 175.39772 val_roc= 0.52011 val_auprc= 0.57994 val_acc= 0.48113 time= 0.03065\n",
      "Epoch: 0001 Iter: 0003 Edge: 0001 train_loss= 176.76938 val_roc= 0.52261 val_auprc= 0.54693 val_acc= 0.50943 time= 0.03113\n",
      "Epoch: 0001 Iter: 0004 Edge: 0007 train_loss= 177.52856 val_roc= 0.51000 val_auprc= 0.49024 val_acc= 0.52632 time= 0.02362\n",
      "Epoch: 0001 Iter: 0008 Edge: 0008 train_loss= 177.55795 val_roc= 0.49749 val_auprc= 0.50342 val_acc= 0.50129 time= 0.76034\n",
      "Epoch: 0001 Iter: 0012 Edge: 0005 train_loss= 177.39355 val_roc= 0.47524 val_auprc= 0.48183 val_acc= 0.48015 time= 0.13594\n",
      "Epoch: 0001 Iter: 0016 Edge: 0006 train_loss= 177.40193 val_roc= 0.50038 val_auprc= 0.50803 val_acc= 0.50225 time= 0.05727\n",
      "Epoch: 0001 Iter: 0020 Edge: 0004 train_loss= 177.37308 val_roc= 0.50264 val_auprc= 0.49904 val_acc= 0.50241 time= 0.27470\n",
      "Epoch: 0001 Iter: 0024 Edge: 0010 train_loss= 177.47736 val_roc= 0.49702 val_auprc= 0.50286 val_acc= 0.50112 time= 0.11292\n",
      "Epoch: 0001 Iter: 0028 Edge: 0003 train_loss= 178.90189 val_roc= 0.53119 val_auprc= 0.55569 val_acc= 0.52717 time= 0.03906\n",
      "Epoch: 0001 Iter: 0032 Edge: 0009 train_loss= 177.35973 val_roc= 0.50024 val_auprc= 0.49235 val_acc= 0.50430 time= 0.36011\n",
      "Epoch: 0001 Iter: 0048 Edge: 0011 train_loss= 177.50363 val_roc= 0.45860 val_auprc= 0.49369 val_acc= 0.44737 time= 0.03038\n",
      "Epoch: 0002 Iter: 0001 Edge: 0002 train_loss= 70.31836 val_roc= 0.81155 val_auprc= 0.80437 val_acc= 0.76630 time= 0.03063\n",
      "Epoch: 0002 Iter: 0002 Edge: 0000 train_loss= 216.26425 val_roc= 0.69740 val_auprc= 0.72940 val_acc= 0.66038 time= 0.02449\n",
      "Epoch: 0002 Iter: 0003 Edge: 0001 train_loss= 234.47101 val_roc= 0.73407 val_auprc= 0.75296 val_acc= 0.60377 time= 0.03054\n",
      "Epoch: 0002 Iter: 0004 Edge: 0011 train_loss= 177.42186 val_roc= 0.45275 val_auprc= 0.52841 val_acc= 0.46491 time= 0.03073\n",
      "Epoch: 0002 Iter: 0008 Edge: 0006 train_loss= 177.41307 val_roc= 0.52845 val_auprc= 0.51774 val_acc= 0.51124 time= 0.05677\n",
      "Epoch: 0002 Iter: 0020 Edge: 0008 train_loss= 177.43152 val_roc= 0.50181 val_auprc= 0.50646 val_acc= 0.50787 time= 0.76914\n",
      "Epoch: 0002 Iter: 0024 Edge: 0004 train_loss= 177.55348 val_roc= 0.48226 val_auprc= 0.48943 val_acc= 0.49068 time= 0.27793\n",
      "Epoch: 0002 Iter: 0040 Edge: 0003 train_loss= 174.69354 val_roc= 0.63126 val_auprc= 0.63862 val_acc= 0.61957 time= 0.03984\n",
      "Epoch: 0002 Iter: 0044 Edge: 0009 train_loss= 177.43213 val_roc= 0.52571 val_auprc= 0.52527 val_acc= 0.50960 time= 0.38258\n",
      "Epoch: 0002 Iter: 0048 Edge: 0007 train_loss= 177.49290 val_roc= 0.44260 val_auprc= 0.46690 val_acc= 0.49123 time= 0.02384\n",
      "Epoch: 0002 Iter: 0116 Edge: 0005 train_loss= 177.48462 val_roc= 0.51782 val_auprc= 0.50722 val_acc= 0.51092 time= 0.13879\n",
      "Epoch: 0002 Iter: 0140 Edge: 0010 train_loss= 177.47035 val_roc= 0.50015 val_auprc= 0.50880 val_acc= 0.51573 time= 0.11355\n",
      "Epoch: 0003 Iter: 0001 Edge: 0002 train_loss= 48.84098 val_roc= 0.85113 val_auprc= 0.83810 val_acc= 0.81522 time= 0.02643\n",
      "Epoch: 0003 Iter: 0002 Edge: 0000 train_loss= 112.86432 val_roc= 0.77714 val_auprc= 0.77760 val_acc= 0.66981 time= 0.02269\n",
      "Epoch: 0003 Iter: 0003 Edge: 0001 train_loss= 143.26385 val_roc= 0.75116 val_auprc= 0.79549 val_acc= 0.61321 time= 0.02984\n",
      "Epoch: 0003 Iter: 0004 Edge: 0003 train_loss= 151.56648 val_roc= 0.90040 val_auprc= 0.88930 val_acc= 0.80978 time= 0.03675\n",
      "Epoch: 0003 Iter: 0008 Edge: 0004 train_loss= 177.31967 val_roc= 0.48983 val_auprc= 0.48880 val_acc= 0.49357 time= 0.26069\n",
      "Epoch: 0003 Iter: 0012 Edge: 0009 train_loss= 177.34651 val_roc= 0.51761 val_auprc= 0.51439 val_acc= 0.50496 time= 0.35611\n",
      "Epoch: 0003 Iter: 0020 Edge: 0008 train_loss= 177.50058 val_roc= 0.50271 val_auprc= 0.50397 val_acc= 0.50514 time= 0.81176\n",
      "Epoch: 0003 Iter: 0028 Edge: 0006 train_loss= 177.40100 val_roc= 0.51947 val_auprc= 0.50912 val_acc= 0.51236 time= 0.05582\n",
      "Epoch: 0003 Iter: 0032 Edge: 0010 train_loss= 177.37112 val_roc= 0.52142 val_auprc= 0.52108 val_acc= 0.51910 time= 0.11499\n",
      "Epoch: 0003 Iter: 0048 Edge: 0011 train_loss= 177.48772 val_roc= 0.53740 val_auprc= 0.51717 val_acc= 0.54386 time= 0.02890\n",
      "Epoch: 0003 Iter: 0052 Edge: 0007 train_loss= 177.39684 val_roc= 0.50446 val_auprc= 0.49664 val_acc= 0.50000 time= 0.02241\n",
      "Epoch: 0003 Iter: 0144 Edge: 0005 train_loss= 177.40039 val_roc= 0.50499 val_auprc= 0.50037 val_acc= 0.50199 time= 0.15074\n",
      "Epoch: 0004 Iter: 0001 Edge: 0002 train_loss= 41.80133 val_roc= 0.88788 val_auprc= 0.92074 val_acc= 0.84783 time= 0.02649\n",
      "Epoch: 0004 Iter: 0002 Edge: 0000 train_loss= 69.97685 val_roc= 0.78925 val_auprc= 0.76180 val_acc= 0.65094 time= 0.02245\n",
      "Epoch: 0004 Iter: 0003 Edge: 0001 train_loss= 94.87754 val_roc= 0.79708 val_auprc= 0.82456 val_acc= 0.66038 time= 0.02925\n",
      "Epoch: 0004 Iter: 0004 Edge: 0008 train_loss= 177.26288 val_roc= 0.50909 val_auprc= 0.50317 val_acc= 0.50691 time= 0.77142\n",
      "Epoch: 0004 Iter: 0008 Edge: 0007 train_loss= 177.34958 val_roc= 0.52016 val_auprc= 0.52649 val_acc= 0.54386 time= 0.02223\n",
      "Epoch: 0004 Iter: 0016 Edge: 0005 train_loss= 177.32643 val_roc= 0.50702 val_auprc= 0.50342 val_acc= 0.50199 time= 0.13929\n",
      "Epoch: 0004 Iter: 0020 Edge: 0010 train_loss= 177.42862 val_roc= 0.52262 val_auprc= 0.52110 val_acc= 0.51011 time= 0.12080\n",
      "Epoch: 0004 Iter: 0032 Edge: 0003 train_loss= 130.95433 val_roc= 0.94778 val_auprc= 0.94247 val_acc= 0.86957 time= 0.03762\n",
      "Epoch: 0004 Iter: 0052 Edge: 0006 train_loss= 177.34106 val_roc= 0.52049 val_auprc= 0.50825 val_acc= 0.51011 time= 0.05594\n",
      "Epoch: 0004 Iter: 0064 Edge: 0009 train_loss= 177.26480 val_roc= 0.51845 val_auprc= 0.51404 val_acc= 0.49967 time= 0.37857\n",
      "Epoch: 0004 Iter: 0068 Edge: 0011 train_loss= 176.95605 val_roc= 0.53863 val_auprc= 0.52992 val_acc= 0.54386 time= 0.02948\n",
      "Epoch: 0004 Iter: 0096 Edge: 0004 train_loss= 177.46603 val_roc= 0.48853 val_auprc= 0.49105 val_acc= 0.49357 time= 0.26717\n",
      "Epoch: 0005 Iter: 0001 Edge: 0002 train_loss= 30.99196 val_roc= 0.89934 val_auprc= 0.92165 val_acc= 0.82609 time= 0.03232\n",
      "Epoch: 0005 Iter: 0002 Edge: 0000 train_loss= 59.78176 val_roc= 0.81310 val_auprc= 0.81916 val_acc= 0.66038 time= 0.02769\n",
      "Epoch: 0005 Iter: 0003 Edge: 0001 train_loss= 63.82929 val_roc= 0.80883 val_auprc= 0.84037 val_acc= 0.67925 time= 0.03468\n",
      "Epoch: 0005 Iter: 0004 Edge: 0009 train_loss= 177.32431 val_roc= 0.52270 val_auprc= 0.51691 val_acc= 0.51324 time= 0.39355\n",
      "Epoch: 0005 Iter: 0012 Edge: 0010 train_loss= 176.78896 val_roc= 0.52654 val_auprc= 0.52085 val_acc= 0.52022 time= 0.11596\n",
      "Epoch: 0005 Iter: 0020 Edge: 0007 train_loss= 176.95795 val_roc= 0.57156 val_auprc= 0.57958 val_acc= 0.51754 time= 0.02679\n",
      "Epoch: 0005 Iter: 0028 Edge: 0011 train_loss= 176.24239 val_roc= 0.56079 val_auprc= 0.55531 val_acc= 0.58772 time= 0.02974\n",
      "Epoch: 0005 Iter: 0036 Edge: 0006 train_loss= 177.45807 val_roc= 0.53686 val_auprc= 0.54117 val_acc= 0.52697 time= 0.05950\n",
      "Epoch: 0005 Iter: 0040 Edge: 0005 train_loss= 177.21545 val_roc= 0.51275 val_auprc= 0.51281 val_acc= 0.50629 time= 0.14060\n",
      "Epoch: 0005 Iter: 0044 Edge: 0003 train_loss= 112.81566 val_roc= 0.96078 val_auprc= 0.95658 val_acc= 0.91304 time= 0.04096\n",
      "Epoch: 0005 Iter: 0080 Edge: 0008 train_loss= 177.23022 val_roc= 0.50833 val_auprc= 0.50248 val_acc= 0.50787 time= 0.84523\n",
      "Epoch: 0005 Iter: 0088 Edge: 0004 train_loss= 177.65408 val_roc= 0.48737 val_auprc= 0.49075 val_acc= 0.49277 time= 0.28791\n",
      "Epoch: 0006 Iter: 0001 Edge: 0002 train_loss= 35.55840 val_roc= 0.89414 val_auprc= 0.92486 val_acc= 0.84239 time= 0.02625\n",
      "Epoch: 0006 Iter: 0002 Edge: 0000 train_loss= 61.25698 val_roc= 0.82022 val_auprc= 0.82613 val_acc= 0.66038 time= 0.02675\n",
      "Epoch: 0006 Iter: 0003 Edge: 0001 train_loss= 42.99514 val_roc= 0.79922 val_auprc= 0.83835 val_acc= 0.68868 time= 0.03108\n",
      "Epoch: 0006 Iter: 0004 Edge: 0005 train_loss= 176.45091 val_roc= 0.51572 val_auprc= 0.51377 val_acc= 0.51158 time= 0.14552\n",
      "Epoch: 0006 Iter: 0008 Edge: 0011 train_loss= 175.33359 val_roc= 0.55186 val_auprc= 0.55206 val_acc= 0.54386 time= 0.03006\n",
      "Epoch: 0006 Iter: 0012 Edge: 0004 train_loss= 177.39603 val_roc= 0.50414 val_auprc= 0.49893 val_acc= 0.51044 time= 0.27418\n",
      "Epoch: 0006 Iter: 0016 Edge: 0009 train_loss= 177.17487 val_roc= 0.52790 val_auprc= 0.51904 val_acc= 0.51985 time= 0.36390\n",
      "Epoch: 0006 Iter: 0020 Edge: 0006 train_loss= 176.63266 val_roc= 0.54252 val_auprc= 0.55251 val_acc= 0.54045 time= 0.05327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0006 Iter: 0024 Edge: 0010 train_loss= 176.22765 val_roc= 0.52582 val_auprc= 0.52961 val_acc= 0.51348 time= 0.11395\n",
      "Epoch: 0006 Iter: 0064 Edge: 0007 train_loss= 176.21634 val_roc= 0.62512 val_auprc= 0.60165 val_acc= 0.59649 time= 0.02402\n",
      "Epoch: 0006 Iter: 0076 Edge: 0003 train_loss= 116.87613 val_roc= 0.97342 val_auprc= 0.98170 val_acc= 0.92391 time= 0.03597\n",
      "Epoch: 0006 Iter: 0096 Edge: 0008 train_loss= 177.40314 val_roc= 0.50502 val_auprc= 0.50549 val_acc= 0.50225 time= 0.78162\n",
      "Epoch: 0007 Iter: 0001 Edge: 0002 train_loss= 25.87891 val_roc= 0.91777 val_auprc= 0.93839 val_acc= 0.84783 time= 0.02656\n",
      "Epoch: 0007 Iter: 0002 Edge: 0000 train_loss= 41.68299 val_roc= 0.83553 val_auprc= 0.84242 val_acc= 0.63208 time= 0.02402\n",
      "Epoch: 0007 Iter: 0003 Edge: 0001 train_loss= 47.79922 val_roc= 0.82129 val_auprc= 0.86232 val_acc= 0.70755 time= 0.03006\n",
      "Epoch: 0007 Iter: 0004 Edge: 0010 train_loss= 174.92267 val_roc= 0.53920 val_auprc= 0.53648 val_acc= 0.52921 time= 0.11705\n",
      "Epoch: 0007 Iter: 0008 Edge: 0005 train_loss= 176.63730 val_roc= 0.52530 val_auprc= 0.52019 val_acc= 0.51621 time= 0.13824\n",
      "Epoch: 0007 Iter: 0012 Edge: 0003 train_loss= 98.95556 val_roc= 0.97684 val_auprc= 0.98446 val_acc= 0.91304 time= 0.04172\n",
      "Epoch: 0007 Iter: 0020 Edge: 0008 train_loss= 176.78510 val_roc= 0.51241 val_auprc= 0.50872 val_acc= 0.51269 time= 0.79007\n",
      "Epoch: 0007 Iter: 0024 Edge: 0004 train_loss= 177.26936 val_roc= 0.51073 val_auprc= 0.50978 val_acc= 0.50835 time= 0.25667\n",
      "Epoch: 0007 Iter: 0048 Edge: 0007 train_loss= 176.18069 val_roc= 0.64204 val_auprc= 0.60040 val_acc= 0.59649 time= 0.02095\n",
      "Epoch: 0007 Iter: 0064 Edge: 0011 train_loss= 174.58090 val_roc= 0.55894 val_auprc= 0.55682 val_acc= 0.54386 time= 0.02866\n",
      "Epoch: 0007 Iter: 0116 Edge: 0006 train_loss= 176.63196 val_roc= 0.56015 val_auprc= 0.55222 val_acc= 0.53034 time= 0.05421\n",
      "Epoch: 0007 Iter: 0156 Edge: 0009 train_loss= 177.37836 val_roc= 0.53162 val_auprc= 0.52376 val_acc= 0.50695 time= 0.34880\n",
      "Epoch: 0008 Iter: 0001 Edge: 0002 train_loss= 27.06668 val_roc= 0.91623 val_auprc= 0.94188 val_acc= 0.84239 time= 0.02612\n",
      "Epoch: 0008 Iter: 0002 Edge: 0000 train_loss= 16.86098 val_roc= 0.81061 val_auprc= 0.81064 val_acc= 0.64151 time= 0.02380\n",
      "Epoch: 0008 Iter: 0003 Edge: 0001 train_loss= 45.36688 val_roc= 0.82093 val_auprc= 0.85654 val_acc= 0.67925 time= 0.02925\n",
      "Epoch: 0008 Iter: 0004 Edge: 0008 train_loss= 177.98668 val_roc= 0.52254 val_auprc= 0.51705 val_acc= 0.51237 time= 0.81275\n",
      "Epoch: 0008 Iter: 0008 Edge: 0005 train_loss= 177.34363 val_roc= 0.52793 val_auprc= 0.52257 val_acc= 0.52780 time= 0.12962\n",
      "Epoch: 0008 Iter: 0012 Edge: 0004 train_loss= 177.91684 val_roc= 0.50405 val_auprc= 0.49732 val_acc= 0.50321 time= 0.26552\n",
      "Epoch: 0008 Iter: 0020 Edge: 0006 train_loss= 174.79147 val_roc= 0.55406 val_auprc= 0.54775 val_acc= 0.54494 time= 0.05336\n",
      "Epoch: 0008 Iter: 0024 Edge: 0007 train_loss= 175.15338 val_roc= 0.65836 val_auprc= 0.60802 val_acc= 0.59649 time= 0.02341\n",
      "Epoch: 0008 Iter: 0040 Edge: 0010 train_loss= 173.34293 val_roc= 0.55296 val_auprc= 0.54749 val_acc= 0.52135 time= 0.11233\n",
      "Epoch: 0008 Iter: 0060 Edge: 0011 train_loss= 173.44418 val_roc= 0.61496 val_auprc= 0.59196 val_acc= 0.58772 time= 0.03051\n",
      "Epoch: 0008 Iter: 0080 Edge: 0009 train_loss= 176.30655 val_roc= 0.53564 val_auprc= 0.52812 val_acc= 0.52482 time= 0.38327\n",
      "Epoch: 0008 Iter: 0088 Edge: 0003 train_loss= 99.50837 val_roc= 0.98003 val_auprc= 0.98617 val_acc= 0.92391 time= 0.03882\n",
      "Epoch: 0009 Iter: 0001 Edge: 0002 train_loss= 20.02192 val_roc= 0.92320 val_auprc= 0.94611 val_acc= 0.85326 time= 0.02586\n",
      "Epoch: 0009 Iter: 0002 Edge: 0000 train_loss= 45.27084 val_roc= 0.83197 val_auprc= 0.84051 val_acc= 0.66038 time= 0.02234\n",
      "Epoch: 0009 Iter: 0003 Edge: 0001 train_loss= 20.24268 val_roc= 0.82058 val_auprc= 0.85814 val_acc= 0.70755 time= 0.02935\n",
      "Epoch: 0009 Iter: 0004 Edge: 0006 train_loss= 175.53220 val_roc= 0.56004 val_auprc= 0.55487 val_acc= 0.53708 time= 0.05469\n",
      "Epoch: 0009 Iter: 0008 Edge: 0003 train_loss= 83.52633 val_roc= 0.97897 val_auprc= 0.98508 val_acc= 0.92391 time= 0.03621\n",
      "Epoch: 0009 Iter: 0020 Edge: 0010 train_loss= 176.28934 val_roc= 0.55775 val_auprc= 0.55319 val_acc= 0.55169 time= 0.10795\n",
      "Epoch: 0009 Iter: 0024 Edge: 0011 train_loss= 173.38025 val_roc= 0.62819 val_auprc= 0.60392 val_acc= 0.60526 time= 0.03004\n",
      "Epoch: 0009 Iter: 0028 Edge: 0004 train_loss= 178.36819 val_roc= 0.50044 val_auprc= 0.49584 val_acc= 0.50321 time= 0.28730\n",
      "Epoch: 0009 Iter: 0044 Edge: 0005 train_loss= 176.43546 val_roc= 0.52447 val_auprc= 0.52091 val_acc= 0.51952 time= 0.14299\n",
      "Epoch: 0009 Iter: 0052 Edge: 0009 train_loss= 176.17273 val_roc= 0.53997 val_auprc= 0.52890 val_acc= 0.52747 time= 0.38249\n",
      "Epoch: 0009 Iter: 0060 Edge: 0007 train_loss= 174.23083 val_roc= 0.64543 val_auprc= 0.61312 val_acc= 0.58772 time= 0.02386\n",
      "Epoch: 0009 Iter: 0108 Edge: 0008 train_loss= 176.40956 val_roc= 0.52605 val_auprc= 0.51941 val_acc= 0.51526 time= 0.80559\n",
      "Epoch: 0010 Iter: 0001 Edge: 0002 train_loss= 26.43416 val_roc= 0.93017 val_auprc= 0.94895 val_acc= 0.84239 time= 0.02540\n",
      "Epoch: 0010 Iter: 0002 Edge: 0000 train_loss= 16.44855 val_roc= 0.82805 val_auprc= 0.82696 val_acc= 0.64151 time= 0.02343\n",
      "Epoch: 0010 Iter: 0003 Edge: 0001 train_loss= 39.15507 val_roc= 0.79103 val_auprc= 0.82664 val_acc= 0.65094 time= 0.02848\n",
      "Epoch: 0010 Iter: 0004 Edge: 0009 train_loss= 176.19206 val_roc= 0.54472 val_auprc= 0.52933 val_acc= 0.52482 time= 0.37080\n",
      "Epoch: 0010 Iter: 0008 Edge: 0007 train_loss= 172.18985 val_roc= 0.70175 val_auprc= 0.65265 val_acc= 0.65789 time= 0.02216\n",
      "Epoch: 0010 Iter: 0012 Edge: 0003 train_loss= 79.54298 val_roc= 0.98251 val_auprc= 0.98833 val_acc= 0.93478 time= 0.03725\n",
      "Epoch: 0010 Iter: 0016 Edge: 0004 train_loss= 177.51675 val_roc= 0.51114 val_auprc= 0.50501 val_acc= 0.51093 time= 0.27062\n",
      "Epoch: 0010 Iter: 0028 Edge: 0010 train_loss= 177.07079 val_roc= 0.58304 val_auprc= 0.56808 val_acc= 0.56067 time= 0.11638\n",
      "Epoch: 0010 Iter: 0036 Edge: 0005 train_loss= 174.98973 val_roc= 0.53190 val_auprc= 0.52468 val_acc= 0.51919 time= 0.14483\n",
      "Epoch: 0010 Iter: 0044 Edge: 0011 train_loss= 169.59222 val_roc= 0.60419 val_auprc= 0.60175 val_acc= 0.58772 time= 0.02975\n",
      "Epoch: 0010 Iter: 0060 Edge: 0008 train_loss= 177.20576 val_roc= 0.53277 val_auprc= 0.52180 val_acc= 0.52298 time= 0.79688\n",
      "Epoch: 0010 Iter: 0096 Edge: 0006 train_loss= 171.99876 val_roc= 0.56892 val_auprc= 0.54984 val_acc= 0.55169 time= 0.05301\n",
      "Optimization finished!\n",
      "Edge type= [00, 01, 00]\n",
      "Edge type: 0000 Test AUROC score 0.76931\n",
      "Edge type: 0000 Test AUPRC score 0.74279\n",
      "Edge type: 0000 Test Accuracy score 0.58491\n",
      "\n",
      "Edge type= [01, 00, 00]\n",
      "Edge type: 0001 Test AUROC score 0.84834\n",
      "Edge type: 0001 Test AUPRC score 0.86627\n",
      "Edge type: 0001 Test Accuracy score 0.60377\n",
      "\n",
      "Edge type= [00, 00, 00]\n",
      "Edge type: 0002 Test AUROC score 0.91753\n",
      "Edge type: 0002 Test AUPRC score 0.93480\n",
      "Edge type: 0002 Test Accuracy score 0.80435\n",
      "\n",
      "Edge type= [00, 00, 01]\n",
      "Edge type: 0003 Test AUROC score 0.97578\n",
      "Edge type: 0003 Test AUPRC score 0.97893\n",
      "Edge type: 0003 Test Accuracy score 0.95109\n",
      "\n",
      "Edge type= [01, 01, 00]\n",
      "Edge type: 0004 Test AUROC score 0.52404\n",
      "Edge type: 0004 Test AUPRC score 0.51948\n",
      "Edge type: 0004 Test Accuracy score 0.51655\n",
      "\n",
      "Edge type= [01, 01, 01]\n",
      "Edge type: 0005 Test AUROC score 0.53023\n",
      "Edge type: 0005 Test AUPRC score 0.51894\n",
      "Edge type: 0005 Test Accuracy score 0.52085\n",
      "\n",
      "Edge type= [01, 01, 02]\n",
      "Edge type: 0006 Test AUROC score 0.59075\n",
      "Edge type: 0006 Test AUPRC score 0.57369\n",
      "Edge type: 0006 Test Accuracy score 0.56292\n",
      "\n",
      "Edge type= [01, 01, 03]\n",
      "Edge type: 0007 Test AUROC score 0.66882\n",
      "Edge type: 0007 Test AUPRC score 0.62718\n",
      "Edge type: 0007 Test Accuracy score 0.63158\n",
      "\n",
      "Edge type= [01, 01, 04]\n",
      "Edge type: 0008 Test AUROC score 0.52720\n",
      "Edge type: 0008 Test AUPRC score 0.51563\n",
      "Edge type: 0008 Test Accuracy score 0.52442\n",
      "\n",
      "Edge type= [01, 01, 05]\n",
      "Edge type: 0009 Test AUROC score 0.55209\n",
      "Edge type: 0009 Test AUPRC score 0.53203\n",
      "Edge type: 0009 Test Accuracy score 0.53541\n",
      "\n",
      "Edge type= [01, 01, 06]\n",
      "Edge type: 0010 Test AUROC score 0.58552\n",
      "Edge type: 0010 Test AUPRC score 0.57412\n",
      "Edge type: 0010 Test Accuracy score 0.55618\n",
      "\n",
      "Edge type= [01, 01, 07]\n",
      "Edge type: 0011 Test AUROC score 0.61157\n",
      "Edge type: 0011 Test AUPRC score 0.63734\n",
      "Edge type: 0011 Test Accuracy score 0.51754\n",
      "\n",
      "Virtual memory: 3310850048\n",
      "RSS Memory: 388349952\n",
      "Total time: 400.274919033\n"
     ]
    }
   ],
   "source": [
    "# Metric structures initialization\n",
    "validation_metrics = np.zeros([num_edge_types,3,1])\n",
    "train_acc = np.zeros([FLAGS.epochs,num_edge_types])\n",
    "val_acc = np.zeros([FLAGS.epochs,num_edge_types])\n",
    "vm_layer = np.zeros([num_edge_types,3,1])\n",
    "# Start training\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    edge_count = range(num_edge_types)\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "        t = time.time()\n",
    "\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        train_cost = outs[1]\n",
    "        batch_edge_type = outs[2]\n",
    "        # Metrics\n",
    "        if batch_edge_type in edge_count:\n",
    "            val_auc, val_auprc, val_acs = get_accuracy_scores(\n",
    "                minibatch.val_edges, minibatch.val_edges_false,\n",
    "                minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n",
    "            step_time = time.time() - t\n",
    "            vm_layer[batch_edge_type,:,0] = [val_auc,val_auprc,val_acs]\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch + 1), \"Iter:\", \"%04d\" % (itr + 1), \n",
    "                  \"Edge:\", \"%04d\" % batch_edge_type,\n",
    "                  \"train_loss=\", \"{:.5f}\".format(train_cost),\n",
    "                  \"val_roc=\", \"{:.5f}\".format(val_auc),\n",
    "                  \"val_auprc=\", \"{:.5f}\".format(val_auprc),\n",
    "                  \"val_acc=\", \"{:.5f}\".format(val_acs),\n",
    "                  \"time=\", \"{:.5f}\".format(step_time))\n",
    "            edge_count.remove(batch_edge_type)\n",
    "        itr += 1\n",
    "    # Train accuracy over all train data per epoch\n",
    "    for r in range(num_edge_types):\n",
    "        i,j,k = minibatch.idx2edge_type[r]\n",
    "        true_train_edges = minibatch.train_edges[i,j][k]\n",
    "        false_train_edges = minibatch.train_edges_false[i,j][k]\n",
    "        true_val_edges = minibatch.val_edges[i,j][k]\n",
    "        false_val_edges = minibatch.val_edges_false[i,j][k]\n",
    "        feed_dict.update({placeholders['batch_edge_type_idx']:k})\n",
    "        feed_dict.update({placeholders['batch_row_edge_type']: i})\n",
    "        feed_dict.update({placeholders['batch_col_edge_type']: j})\n",
    "        pred = sess.run(opt.predictions,feed_dict=feed_dict)\n",
    "        train_acc[epoch,r] = accuracy(true_train_edges,false_train_edges,pred)\n",
    "        val_acc[epoch,r] = accuracy(true_val_edges,false_val_edges,pred)\n",
    "    validation_metrics = np.concatenate((validation_metrics,vm_layer),axis=2)\n",
    "    output_data['val_auc'] = validation_metrics[:,0,1:]\n",
    "    output_data['val_auprc'] = validation_metrics[:,1,1:]\n",
    "    output_data['train_acc'] = train_acc\n",
    "    output_data['val_acc'] = val_acc\n",
    "    output_data['epoch'] = epoch + 1\n",
    "    \n",
    "    with open(out_file,'wb') as f:\n",
    "        pickle.dump(output_data, f, protocol=2)\n",
    "    vm_layer = np.zeros([num_edge_types,3,1])\n",
    "    \n",
    "# End of training. Metric structure handling   \n",
    "print(\"Optimization finished!\")\n",
    "test_scores = np.zeros([num_edge_types,3])\n",
    "for et in range(num_edge_types):\n",
    "    roc_score, auprc_score, acc_score = get_accuracy_scores(\n",
    "        minibatch.test_edges, minibatch.test_edges_false, minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type=\", \"[%02d, %02d, %02d]\" % minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(roc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(auprc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test Accuracy score\", \"{:.5f}\".format(acc_score))\n",
    "    print()\n",
    "    test_scores[et,0] = roc_score\n",
    "    test_scores[et,1] = auprc_score\n",
    "    test_scores[et,2] = acc_score\n",
    "output_data['test_scores'] = test_scores\n",
    "memUse = ps.memory_info()\n",
    "print('Virtual memory:', memUse.vms)\n",
    "print('RSS Memory:', memUse.rss)\n",
    "total_time=time.time()-start\n",
    "output_data['time'] = total_time\n",
    "output_data['vms'] = memUse.vms\n",
    "output_data['rss'] = memUse.rss\n",
    "with open(out_file,'wb') as f:\n",
    "    pickle.dump(output_data, f, protocol=2)\n",
    "print(\"Total time:\",total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
