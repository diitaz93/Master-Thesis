{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECAGON Training\n",
    "Test notebook for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, chain\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psutil & time BEGIN\n",
    "start = time.time() #in seconds\n",
    "pid = os.getpid()\n",
    "ps= psutil.Process(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data from previous computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input file. Goes as parameter in script\n",
    "in_file = './data/data_structures/DECAGON/DECAGON_real_binding_DSE_5233_BDM_genes_4116_drugs_58_se_7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = in_file.split('_')\n",
    "DSE = False\n",
    "BDM = False\n",
    "DOCK = False\n",
    "BIND = False\n",
    "if 'DSE' in words: DSE = True\n",
    "if 'BDM' in words: BDM = True\n",
    "if 'docking' in words: DOCK = True\n",
    "elif 'binding' in words: BIND = True\n",
    "d_text = DOCK*'_docking'+BIND*'_binding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge2name Imported successfully\n",
      "se_mono_name2idx Imported successfully\n",
      "gene2idx Imported successfully\n",
      "nonzero_feat Imported successfully\n",
      "edge_type2dim Imported successfully\n",
      "adj_mats_orig Imported successfully\n",
      "edge_type2decoder Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "degrees Imported successfully\n",
      "edge_types Imported successfully\n",
      "num_edge_types Imported successfully\n",
      "num_feat Imported successfully\n",
      "feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "with open(in_file, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4116 58 7 5233 True\n"
     ]
    }
   ],
   "source": [
    "n_genes = len(gene2idx)\n",
    "n_drugs = len(drug2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)\n",
    "print(n_genes,n_drugs,n_se_combo,n_se_mono,DSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    \"\"\" Returns the AUROC, AUPRC and Accuracy of the dataset corresponding to the edge\n",
    "    'edge_type' given as a tuple. The parameters 'edges_pos' and 'edges_neg' are the list \n",
    "    of edges of positive and negative interactions respectively of a given dataset, i.e., \n",
    "    train, test or validation.\n",
    "    \"\"\"\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "    # Predict on set of edges\n",
    "    preds = []\n",
    "    for u, v in edges_pos:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] > 0, 'Problem 1'\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    acc = metrics.accuracy_score(labels_all, np.round(preds_all))\n",
    "\n",
    "    return roc_sc, aupr_sc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_size = 0.15\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 10, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 128, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHETAZO!! Soluciona el bug de Jupyter con tensorflow que proporciona un flag -f\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create minibatch iterator, model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 1, 0)\n",
      "Constructing test edges= 0000/0053\n",
      "Constructing val edges= 0000/0053\n",
      "Constructing train edges= 0000/0253\n",
      "Train edges= 0253\n",
      "Val edges= 0053\n",
      "Test edges= 0053\n",
      "Minibatch edge type: (1, 0, 0)\n",
      "Constructing test edges= 0000/0053\n",
      "Constructing val edges= 0000/0053\n",
      "Constructing train edges= 0000/0253\n",
      "Train edges= 0253\n",
      "Val edges= 0053\n",
      "Test edges= 0053\n",
      "Minibatch edge type: (0, 0, 0)\n",
      "Constructing test edges= 0000/0092\n",
      "Constructing val edges= 0000/0092\n",
      "Constructing train edges= 0000/0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decagon/deep/minibatch.py:78: RuntimeWarning: divide by zero encountered in power\n",
      "  rowdegree_mat_inv = sp.diags(np.nan_to_num(np.power(rowsum, -0.5)).flatten())\n",
      "decagon/deep/minibatch.py:79: RuntimeWarning: divide by zero encountered in power\n",
      "  coldegree_mat_inv = sp.diags(np.nan_to_num(np.power(colsum, -0.5)).flatten())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train edges= 0431\n",
      "Val edges= 0092\n",
      "Test edges= 0092\n",
      "Minibatch edge type: (1, 1, 0)\n",
      "Constructing test edges= 0000/3112\n",
      "Constructing test edges= 0000/3112\n",
      "Constructing test edges= 1000/3112\n",
      "Constructing test edges= 2000/3112\n",
      "Constructing test edges= 3000/3112\n",
      "Constructing val edges= 0000/3112\n",
      "Constructing val edges= 1000/3112\n",
      "Constructing val edges= 2000/3112\n",
      "Constructing val edges= 3000/3112\n",
      "Constructing val edges= 3000/3112\n",
      "Constructing train edges= 0000/14529\n",
      "Constructing train edges= 1000/14529\n",
      "Constructing train edges= 2000/14529\n",
      "Constructing train edges= 2000/14529\n",
      "Constructing train edges= 3000/14529\n",
      "Constructing train edges= 4000/14529\n",
      "Constructing train edges= 5000/14529\n",
      "Constructing train edges= 6000/14529\n",
      "Constructing train edges= 6000/14529\n",
      "Constructing train edges= 7000/14529\n",
      "Constructing train edges= 8000/14529\n",
      "Constructing train edges= 9000/14529\n",
      "Constructing train edges= 9000/14529\n",
      "Constructing train edges= 10000/14529\n",
      "Constructing train edges= 10000/14529\n",
      "Constructing train edges= 10000/14529\n",
      "Constructing train edges= 11000/14529\n",
      "Constructing train edges= 12000/14529\n",
      "Constructing train edges= 12000/14529\n",
      "Constructing train edges= 12000/14529\n",
      "Constructing train edges= 12000/14529\n",
      "Constructing train edges= 13000/14529\n",
      "Constructing train edges= 14000/14529\n",
      "Train edges= 14529\n",
      "Val edges= 3112\n",
      "Test edges= 3112\n",
      "Minibatch edge type: (1, 1, 1)\n",
      "Constructing test edges= 0000/1511\n",
      "Constructing test edges= 1000/1511\n",
      "Constructing val edges= 0000/1511\n",
      "Constructing val edges= 1000/1511\n",
      "Constructing train edges= 0000/7054\n",
      "Constructing train edges= 1000/7054\n",
      "Constructing train edges= 2000/7054\n",
      "Constructing train edges= 3000/7054\n",
      "Constructing train edges= 4000/7054\n",
      "Constructing train edges= 5000/7054\n",
      "Constructing train edges= 6000/7054\n",
      "Constructing train edges= 7000/7054\n",
      "Train edges= 7054\n",
      "Val edges= 1511\n",
      "Test edges= 1511\n",
      "Minibatch edge type: (1, 1, 2)\n",
      "Constructing test edges= 0000/0445\n",
      "Constructing val edges= 0000/0445\n",
      "Constructing train edges= 0000/2081\n",
      "Constructing train edges= 1000/2081\n",
      "Constructing train edges= 2000/2081\n",
      "Train edges= 2081\n",
      "Val edges= 0445\n",
      "Test edges= 0445\n",
      "Minibatch edge type: (1, 1, 3)\n",
      "Constructing test edges= 0000/0057\n",
      "Constructing val edges= 0000/0057\n",
      "Constructing train edges= 0000/0267\n",
      "Train edges= 0267\n",
      "Val edges= 0057\n",
      "Test edges= 0057\n"
     ]
    }
   ],
   "source": [
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    val_test_size=val_test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0): 2,\n",
       " (0, 1, 0): 0,\n",
       " (1, 0, 0): 1,\n",
       " (1, 1, 0): 3,\n",
       " (1, 1, 1): 4,\n",
       " (1, 1, 2): 5,\n",
       " (1, 1, 3): 6}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch.edge_type2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "WARNING:tensorflow:From decagon/deep/layers.py:93: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}\n",
    "pre_train_time = time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_training/TRAIN_real_binding_DSE_5233_BDM_genes_4116_drugs_58_se_7_epochs_10_h1_64_h2_32_lr_0.001_dropout_0.1_valsize_0.15\n"
     ]
    }
   ],
   "source": [
    "out_file = 'results_training/TRAIN_'+words[2]+d_text+DSE*('_DSE_'+str(n_se_mono))+BDM*('_BDM')\\\n",
    "            +'_genes_'+str(n_genes)+'_drugs_'+str(n_drugs)+'_se_'+str(n_se_combo)+'_epochs_'+\\\n",
    "            str(FLAGS.epochs)+'_h1_'+str(FLAGS.hidden1)+'_h2_'+str(FLAGS.hidden2)+\\\n",
    "            '_lr_'+str(FLAGS.learning_rate)+'_dropout_'+str(FLAGS.dropout)+'_valsize_'+\\\n",
    "            str(val_test_size)\n",
    "#out_file = 'results_training/sandboxish'\n",
    "print(out_file)\n",
    "output_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "======================================================================================================================\n",
      "Epoch 0001 finished!\n",
      "Time= 6.52644\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9964 Validation= 0.8775 AUPRC:Train= 0.9958 Validation= 0.8709 Accuracy:Train= 0.9921 Validation= 0.6415\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 1.0000 Validation= 0.8750 AUPRC:Train= 1.0000 Validation= 0.9031 Accuracy:Train= 0.9980 Validation= 0.6698\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9994 Validation= 0.8716 AUPRC:Train= 0.9993 Validation= 0.9166 Accuracy:Train= 0.9965 Validation= 0.8261\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.6986 Validation= 0.5717 AUPRC:Train= 0.6658 Validation= 0.5639 Accuracy:Train= 0.6462 Validation= 0.5514\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7681 Validation= 0.6056 AUPRC:Train= 0.7283 Validation= 0.5855 Accuracy:Train= 0.7046 Validation= 0.5748\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.8934 Validation= 0.6849 AUPRC:Train= 0.8472 Validation= 0.6564 Accuracy:Train= 0.8251 Validation= 0.6135\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8985 Validation= 0.5543 AUPRC:Train= 0.8582 Validation= 0.6031 Accuracy:Train= 0.8258 Validation= 0.5263\n",
      "======================================================================================================================\n",
      "Epoch 0002 finished!\n",
      "Time= 6.33137\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9973 Validation= 0.8807 AUPRC:Train= 0.9969 Validation= 0.8759 Accuracy:Train= 0.9901 Validation= 0.6321\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 1.0000 Validation= 0.8669 AUPRC:Train= 1.0000 Validation= 0.8960 Accuracy:Train= 0.9980 Validation= 0.6698\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9996 Validation= 0.8690 AUPRC:Train= 0.9996 Validation= 0.9110 Accuracy:Train= 0.9942 Validation= 0.8152\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.7008 Validation= 0.5769 AUPRC:Train= 0.6678 Validation= 0.5667 Accuracy:Train= 0.6469 Validation= 0.5578\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7709 Validation= 0.6077 AUPRC:Train= 0.7303 Validation= 0.5927 Accuracy:Train= 0.7056 Validation= 0.5668\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.8962 Validation= 0.6893 AUPRC:Train= 0.8490 Validation= 0.6531 Accuracy:Train= 0.8352 Validation= 0.6202\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8906 Validation= 0.5620 AUPRC:Train= 0.8407 Validation= 0.6046 Accuracy:Train= 0.8258 Validation= 0.5175\n",
      "======================================================================================================================\n",
      "Epoch 0003 finished!\n",
      "Time= 6.29203\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9967 Validation= 0.8836 AUPRC:Train= 0.9961 Validation= 0.8764 Accuracy:Train= 0.9921 Validation= 0.6321\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 0.9999 Validation= 0.8750 AUPRC:Train= 0.9999 Validation= 0.9031 Accuracy:Train= 0.9941 Validation= 0.6509\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 1.0000 Validation= 0.8706 AUPRC:Train= 1.0000 Validation= 0.9145 Accuracy:Train= 0.9954 Validation= 0.8315\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.6994 Validation= 0.5723 AUPRC:Train= 0.6657 Validation= 0.5635 Accuracy:Train= 0.6466 Validation= 0.5530\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7712 Validation= 0.6091 AUPRC:Train= 0.7334 Validation= 0.5915 Accuracy:Train= 0.7036 Validation= 0.5698\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.8962 Validation= 0.6876 AUPRC:Train= 0.8468 Validation= 0.6482 Accuracy:Train= 0.8313 Validation= 0.6101\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8928 Validation= 0.5531 AUPRC:Train= 0.8450 Validation= 0.5949 Accuracy:Train= 0.8090 Validation= 0.5175\n",
      "======================================================================================================================\n",
      "Epoch 0004 finished!\n",
      "Time= 6.26479\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9969 Validation= 0.8825 AUPRC:Train= 0.9965 Validation= 0.8809 Accuracy:Train= 0.9901 Validation= 0.6321\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 1.0000 Validation= 0.8693 AUPRC:Train= 1.0000 Validation= 0.8996 Accuracy:Train= 1.0000 Validation= 0.6321\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 1.0000 Validation= 0.8710 AUPRC:Train= 1.0000 Validation= 0.9150 Accuracy:Train= 0.9977 Validation= 0.8043\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.7008 Validation= 0.5751 AUPRC:Train= 0.6675 Validation= 0.5656 Accuracy:Train= 0.6456 Validation= 0.5543\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7744 Validation= 0.6138 AUPRC:Train= 0.7345 Validation= 0.5945 Accuracy:Train= 0.7065 Validation= 0.5821\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.8999 Validation= 0.6879 AUPRC:Train= 0.8491 Validation= 0.6443 Accuracy:Train= 0.8347 Validation= 0.6034\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8895 Validation= 0.5617 AUPRC:Train= 0.8326 Validation= 0.6079 Accuracy:Train= 0.8277 Validation= 0.5175\n",
      "======================================================================================================================\n",
      "Epoch 0005 finished!\n",
      "Time= 6.24138\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9973 Validation= 0.8839 AUPRC:Train= 0.9970 Validation= 0.8874 Accuracy:Train= 0.9901 Validation= 0.6415\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 1.0000 Validation= 0.8679 AUPRC:Train= 1.0000 Validation= 0.8990 Accuracy:Train= 0.9980 Validation= 0.6321\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9999 Validation= 0.8741 AUPRC:Train= 0.9999 Validation= 0.9181 Accuracy:Train= 0.9965 Validation= 0.8098\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.7018 Validation= 0.5739 AUPRC:Train= 0.6690 Validation= 0.5619 Accuracy:Train= 0.6474 Validation= 0.5551\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7784 Validation= 0.6157 AUPRC:Train= 0.7400 Validation= 0.5959 Accuracy:Train= 0.7119 Validation= 0.5774\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.8990 Validation= 0.6935 AUPRC:Train= 0.8510 Validation= 0.6564 Accuracy:Train= 0.8352 Validation= 0.6258\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8894 Validation= 0.5577 AUPRC:Train= 0.8281 Validation= 0.5966 Accuracy:Train= 0.8258 Validation= 0.5000\n",
      "======================================================================================================================\n",
      "Epoch 0006 finished!\n",
      "Time= 6.25793\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9983 Validation= 0.8875 AUPRC:Train= 0.9982 Validation= 0.8865 Accuracy:Train= 0.9921 Validation= 0.6415\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 1.0000 Validation= 0.8683 AUPRC:Train= 1.0000 Validation= 0.8977 Accuracy:Train= 1.0000 Validation= 0.6604\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 1.0000 Validation= 0.8738 AUPRC:Train= 1.0000 Validation= 0.9175 Accuracy:Train= 0.9954 Validation= 0.8152\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.7014 Validation= 0.5743 AUPRC:Train= 0.6679 Validation= 0.5655 Accuracy:Train= 0.6493 Validation= 0.5506\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7766 Validation= 0.6168 AUPRC:Train= 0.7368 Validation= 0.5986 Accuracy:Train= 0.7114 Validation= 0.5834\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.8979 Validation= 0.6862 AUPRC:Train= 0.8492 Validation= 0.6506 Accuracy:Train= 0.8359 Validation= 0.6225\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8914 Validation= 0.5673 AUPRC:Train= 0.8362 Validation= 0.6032 Accuracy:Train= 0.8333 Validation= 0.5175\n",
      "======================================================================================================================\n",
      "Epoch 0007 finished!\n",
      "Time= 6.24219\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9973 Validation= 0.8868 AUPRC:Train= 0.9969 Validation= 0.8804 Accuracy:Train= 0.9921 Validation= 0.6321\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 1.0000 Validation= 0.8690 AUPRC:Train= 1.0000 Validation= 0.8984 Accuracy:Train= 1.0000 Validation= 0.6604\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9998 Validation= 0.8724 AUPRC:Train= 0.9998 Validation= 0.9174 Accuracy:Train= 0.9942 Validation= 0.8315\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.7025 Validation= 0.5729 AUPRC:Train= 0.6689 Validation= 0.5615 Accuracy:Train= 0.6502 Validation= 0.5559\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7759 Validation= 0.6123 AUPRC:Train= 0.7371 Validation= 0.5911 Accuracy:Train= 0.7096 Validation= 0.5745\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.8993 Validation= 0.6869 AUPRC:Train= 0.8502 Validation= 0.6537 Accuracy:Train= 0.8414 Validation= 0.6157\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8875 Validation= 0.5586 AUPRC:Train= 0.8335 Validation= 0.5930 Accuracy:Train= 0.8296 Validation= 0.5088\n",
      "======================================================================================================================\n",
      "Epoch 0008 finished!\n",
      "Time= 6.30745\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9968 Validation= 0.8847 AUPRC:Train= 0.9963 Validation= 0.8833 Accuracy:Train= 0.9921 Validation= 0.6321\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 1.0000 Validation= 0.8669 AUPRC:Train= 1.0000 Validation= 0.8970 Accuracy:Train= 1.0000 Validation= 0.6509\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9996 Validation= 0.8697 AUPRC:Train= 0.9996 Validation= 0.9162 Accuracy:Train= 0.9954 Validation= 0.8370\n",
      "Metrics for  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:Train= 0.7036 Validation= 0.5747 AUPRC:Train= 0.6692 Validation= 0.5656 Accuracy:Train= 0.6513 Validation= 0.5530\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7817 Validation= 0.6110 AUPRC:Train= 0.7410 Validation= 0.5913 Accuracy:Train= 0.7151 Validation= 0.5778\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.8988 Validation= 0.6863 AUPRC:Train= 0.8470 Validation= 0.6465 Accuracy:Train= 0.8364 Validation= 0.6090\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8951 Validation= 0.5605 AUPRC:Train= 0.8386 Validation= 0.5914 Accuracy:Train= 0.8408 Validation= 0.5351\n",
      "======================================================================================================================\n",
      "Epoch 0009 finished!\n",
      "Time= 6.28891\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9972 Validation= 0.8772 AUPRC:Train= 0.9967 Validation= 0.8775 Accuracy:Train= 0.9921 Validation= 0.6226\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 1.0000 Validation= 0.8715 AUPRC:Train= 1.0000 Validation= 0.9009 Accuracy:Train= 1.0000 Validation= 0.6509\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 1.0000 Validation= 0.8744 AUPRC:Train= 1.0000 Validation= 0.9175 Accuracy:Train= 0.9965 Validation= 0.8043\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.7046 Validation= 0.5761 AUPRC:Train= 0.6711 Validation= 0.5662 Accuracy:Train= 0.6495 Validation= 0.5498\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7809 Validation= 0.6125 AUPRC:Train= 0.7389 Validation= 0.5961 Accuracy:Train= 0.7139 Validation= 0.5791\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.9029 Validation= 0.6871 AUPRC:Train= 0.8509 Validation= 0.6442 Accuracy:Train= 0.8429 Validation= 0.6067\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8947 Validation= 0.5596 AUPRC:Train= 0.8379 Validation= 0.5994 Accuracy:Train= 0.8502 Validation= 0.5439\n",
      "======================================================================================================================\n",
      "Epoch 0010 finished!\n",
      "Time= 6.30902\n",
      "Metrics for  DTI\n",
      "AUROC:Train= 0.9984 Validation= 0.8839 AUPRC:Train= 0.9983 Validation= 0.8952 Accuracy:Train= 0.9921 Validation= 0.6321\n",
      "Metrics for  TDI\n",
      "AUROC:Train= 1.0000 Validation= 0.8676 AUPRC:Train= 1.0000 Validation= 0.8996 Accuracy:Train= 0.9960 Validation= 0.6509\n",
      "Metrics for  PPI\n",
      "AUROC:Train= 0.9999 Validation= 0.8704 AUPRC:Train= 0.9999 Validation= 0.9139 Accuracy:Train= 0.9954 Validation= 0.8261\n",
      "Metrics for  0\n",
      "AUROC:Train= 0.7056 Validation= 0.5768 AUPRC:Train= 0.6733 Validation= 0.5704 Accuracy:Train= 0.6498 Validation= 0.5514\n",
      "Metrics for  1\n",
      "AUROC:Train= 0.7804 Validation= 0.6114 AUPRC:Train= 0.7389 Validation= 0.5949 Accuracy:Train= 0.7088 Validation= 0.5745\n",
      "Metrics for  2\n",
      "AUROC:Train= 0.9017 Validation= 0.6896 AUPRC:Train= 0.8512 Validation= 0.6493 Accuracy:Train= 0.8462 Validation= 0.6101\n",
      "Metrics for  3\n",
      "AUROC:Train= 0.8928 Validation= 0.5645 AUPRC:Train= 0.8369 Validation= 0.6075 Accuracy:Train= 0.8277 Validation= 0.5175\n",
      "Optimization finished!\n",
      "Edge type= DTI\n",
      "Edge type: 0000 Test AUROC score 0.79815\n",
      "Edge type: 0000 Test AUPRC score 0.81854\n",
      "Edge type: 0000 Test Accuracy score 0.62264\n",
      "\n",
      "Edge type= TDI\n",
      "Edge type: 0001 Test AUROC score 0.83268\n",
      "Edge type: 0001 Test AUPRC score 0.87689\n",
      "Edge type: 0001 Test Accuracy score 0.66038\n",
      "\n",
      "Edge type= PPI\n",
      "Edge type: 0002 Test AUROC score 0.85007\n",
      "Edge type: 0002 Test AUPRC score 0.89676\n",
      "Edge type: 0002 Test Accuracy score 0.81522\n",
      "\n",
      "Edge type= 0\n",
      "Edge type: 0003 Test AUROC score 0.58718\n",
      "Edge type: 0003 Test AUPRC score 0.57310\n",
      "Edge type: 0003 Test Accuracy score 0.55784\n",
      "\n",
      "Edge type= 1\n",
      "Edge type: 0004 Test AUROC score 0.62787\n",
      "Edge type: 0004 Test AUPRC score 0.59742\n",
      "Edge type: 0004 Test Accuracy score 0.58901\n",
      "\n",
      "Edge type= 2\n",
      "Edge type: 0005 Test AUROC score 0.66369\n",
      "Edge type: 0005 Test AUPRC score 0.63517\n",
      "Edge type: 0005 Test Accuracy score 0.60899\n",
      "\n",
      "Edge type= 3\n",
      "Edge type: 0006 Test AUROC score 0.59464\n",
      "Edge type: 0006 Test AUPRC score 0.60300\n",
      "Edge type: 0006 Test Accuracy score 0.54386\n",
      "\n",
      "Virtual memory: 3.268943872 Gb\n",
      "RSS Memory: 0.349007872 Gb\n",
      "Total time: 0:25:20.446792\n"
     ]
    }
   ],
   "source": [
    "# Metric structures initialization\n",
    "val_metrics = np.zeros([FLAGS.epochs,num_edge_types,3])\n",
    "train_metrics = np.zeros([FLAGS.epochs,num_edge_types,3])\n",
    "# Start training\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    t = time.time()\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        if (itr+1)%1000==0:print('Iteration',itr)\n",
    "        itr += 1\n",
    "    # Train & validation accuracy over all train data per epoch\n",
    "    print('======================================================================================================================')\n",
    "    print(\"Epoch\", \"%04d\" % (epoch + 1),'finished!')\n",
    "    print(\"Time=\", \"{:.5f}\".format(time.time()-t))\n",
    "    for r in range(num_edge_types):\n",
    "        i,j,k = minibatch.idx2edge_type[r]\n",
    "        print('Metrics for ', edge2name[i,j][k])\n",
    "        train_metrics[epoch,r,:] = get_accuracy_scores(\n",
    "            minibatch.train_edges[i,j][k], minibatch.train_edges_false[i,j][k],(i,j,k))\n",
    "        val_metrics[epoch,r,:] = get_accuracy_scores(\n",
    "            minibatch.val_edges[i,j][k], minibatch.val_edges_false[i,j][k],(i,j,k))\n",
    "        print(\"AUROC:Train=\", \"{:.4f}\".format(train_metrics[epoch,r,0])\n",
    "              ,\"Validation=\", \"{:.4f}\".format(val_metrics[epoch,r,0])\n",
    "              ,\"AUPRC:Train=\", \"{:.4f}\".format(train_metrics[epoch,r,1])\n",
    "              ,\"Validation=\", \"{:.4f}\".format(val_metrics[epoch,r,1])\n",
    "              ,\"Accuracy:Train=\", \"{:.4f}\".format(train_metrics[epoch,r,2])\n",
    "              ,\"Validation=\", \"{:.4f}\".format(val_metrics[epoch,r,2]))\n",
    "    output_data['val_metrics'] = val_metrics\n",
    "    output_data['train_metrics'] = train_metrics\n",
    "    output_data['epoch'] = epoch + 1\n",
    "    with open(out_file,'wb') as f:\n",
    "        pickle.dump(output_data, f, protocol=2)\n",
    "    \n",
    "# End of training. Metric structure handling   \n",
    "print(\"Optimization finished!\")\n",
    "test_metrics = np.zeros([num_edge_types,3])\n",
    "for et in range(num_edge_types):\n",
    "    i,j,k = minibatch.idx2edge_type[et]\n",
    "    test_metrics[et,:] = get_accuracy_scores(\n",
    "        minibatch.test_edges[i,j][k], minibatch.test_edges_false[i,j][k], (i,j,k))\n",
    "    print(\"Edge type=\", edge2name[i,j][k])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(test_metrics[et,0]))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(test_metrics[et,1]))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test Accuracy score\", \"{:.5f}\".format(test_metrics[et,2]))\n",
    "    print()\n",
    "output_data['test_metrics'] = test_metrics\n",
    "memUse = ps.memory_info()\n",
    "print('Virtual memory:', memUse.vms*1e-09,'Gb')\n",
    "print('RSS Memory:', memUse.rss*1e-09,'Gb')\n",
    "train_time=time.time()-pre_train_time\n",
    "output_data['pre_train_time'] = pre_train_time\n",
    "output_data['train_time'] = train_time\n",
    "output_data['edge2name'] = edge2name\n",
    "output_data['drug2idx'] = drug2idx\n",
    "output_data['gene2idx'] = gene2idx\n",
    "output_data['vms'] = memUse.vms\n",
    "output_data['rss'] = memUse.rss\n",
    "with open(out_file,'wb') as f:\n",
    "    pickle.dump(output_data, f, protocol=2)\n",
    "print('Total time:', datetime.timedelta(seconds=time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
