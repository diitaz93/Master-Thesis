{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "Notebook to test code before real implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ ONLY PYTHON 2 #########################\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, chain, product\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import pickle\n",
    "from pybdm import BDM\n",
    "from pybdm.utils import decompose_dataset\n",
    "from pybdm.partitions import PartitionIgnore\n",
    "from pybdm.partitions import PartitionRecursive\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import parallel_backend\n",
    "from data.algorithms import PerturbationExperiment, NodePerturbationExperiment\n",
    "import math\n",
    "import datetime as dt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load adj matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_structures/DS/DS_toy_DSE_600_PF_5_genes_500_drugs_400_se_4',\\\n",
    "          'rb') as f:\n",
    "    ppi_adj = pickle.load(f)['ppi_adj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BDM object and calculate edge complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdm = BDM(ndim=2, partition=PartitionRecursive)\n",
    "ppi_per = PerturbationExperiment(bdm,metric='bdm',bipartite_network=False)\n",
    "ppi_per.set_data(np.array(ppi_adj.todense()))\n",
    "# Algorithmic complexity\n",
    "edge_complexity = ppi_per.run()\n",
    "# Reshape in the adj matrix shape\n",
    "complexity_mat = edge_complexity.reshape(np.shape(ppi_adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the coordinates of positive edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 2)\n",
      "[[  0  94]\n",
      " [  0 143]\n",
      " [  1  10]\n",
      " [  2 167]\n",
      " [  3 152]]\n"
     ]
    }
   ],
   "source": [
    "coords,_,_ = sparse_to_tuple(ppi_adj)\n",
    "l= np.shape(coords)[0]\n",
    "print(np.shape(coords))\n",
    "print(coords[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select complexity values for true edges and take absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 1)\n",
      "[[0.03837811]\n",
      " [0.05435175]\n",
      " [0.04054595]\n",
      " [0.02965131]\n",
      " [0.05435175]]\n"
     ]
    }
   ],
   "source": [
    "true_cmplx = np.abs(complexity_mat[coords[:,0],coords[:,1]].reshape(615,1))\n",
    "print(np.shape(true_cmplx))\n",
    "print(true_cmplx[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate values with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 2)\n",
      "[[0.03837811 0.        ]\n",
      " [0.05435175 1.        ]\n",
      " [0.04054595 2.        ]\n",
      " [0.02965131 3.        ]\n",
      " [0.05435175 4.        ]]\n"
     ]
    }
   ],
   "source": [
    "a = np.concatenate((np.abs(true_cmplx),np.arange(615).reshape(615,1)),axis=1)\n",
    "print(np.shape(a))\n",
    "print(a[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 2)\n",
      "[[2.66108470e+01 5.89000000e+02]\n",
      " [2.66108470e+01 5.41000000e+02]\n",
      " [2.66025186e+01 2.41000000e+02]\n",
      " ...\n",
      " [2.96513078e-02 3.71000000e+02]\n",
      " [2.96513078e-02 1.32000000e+02]\n",
      " [2.96513078e-02 3.07000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "sorted_values = a[a[:,0].argsort()[::-1]]\n",
    "print(np.shape(sorted_values))\n",
    "print(sorted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard the lowest values of complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "(461, 2)\n",
      "[[ 26.610847   589.        ]\n",
      " [ 26.610847   541.        ]\n",
      " [ 26.60251864 241.        ]\n",
      " [ 26.60251864 306.        ]\n",
      " [ 26.59817317 304.        ]]\n"
     ]
    }
   ],
   "source": [
    "cut_frac = 0.25\n",
    "remain = np.arange(np.floor(l*(1-cut_frac)),dtype=int)\n",
    "new_values = sorted_values[remain,:]\n",
    "print(np.shape(new_values))\n",
    "print(new_values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select new true edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[476 435]\n",
      " [435 476]\n",
      " [195 251]\n",
      " [251 195]\n",
      " [250 192]]\n",
      "(461, 2)\n"
     ]
    }
   ],
   "source": [
    "indices = new_values[:,1].astype(int)\n",
    "new_coords = coords[indices,:]\n",
    "print(new_coords[:5])\n",
    "print(np.shape(new_coords))\n",
    "new_l = np.shape(new_coords)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of new adyacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ppi_adj = sp.csr_matrix((np.ones(new_l), (new_coords[:,0], new_coords[:,1])), shape=np.shape(ppi_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisar si adj mats contienen el 1 en la diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_structures/DS/DS_real_DSE_9700_genes_16837_drugs_636_se_7','rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi_adj_list[0].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWOSIDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv('../Thesis_datasets/TWOSIDES/small.csv',sep=',',usecols=[0,1,2,3,4,5])\n",
    "DEC = pd.read_csv('data/original_data/bio-decagon-combo.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dictionaries Side effects\n",
    "`meddra.tsv` is a database that contains names of side effects in both wanted ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_se = pd.read_csv('../Thesis_datasets/SIDER/meddra.tsv', sep = '\\t'\\\n",
    "                     ,header=None).rename(columns={0:'UMLS',1:'kind',2:'MedDRA',3:'name'})\n",
    "cui = pd.unique(map_se['UMLS'].values)\n",
    "meddra = pd.unique(map_se['MedDRA'].values)\n",
    "ses = pd.unique(map_se['name'].values)\n",
    "print('Total',len(map_se))\n",
    "print('CUI',len(cui))\n",
    "print('MedDRA',len(meddra))\n",
    "print('Side Effects',len(ses))\n",
    "map_se.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that translates UMLS CUIs to MedDRA IDs\n",
    "umls2meddra = defaultdict(set)\n",
    "for se in map_se.index:\n",
    "    umls2meddra[map_se.loc[se,'UMLS']] = map_se.loc[se,'MedDRA']\n",
    "# Dictionary that translates MedDRA IDs to UMLS CUIs\n",
    "meddra2umls = defaultdict(set)\n",
    "for se in map_se.index:\n",
    "    meddra2umls[map_se.loc[se,'MedDRA']] = map_se.loc[se,'UMLS']\n",
    "# Dictionary that translates UMLS CUIs to name\n",
    "names = map_se[map_se['kind'].str.match('PT',na=False)].reset_index(drop=True)\n",
    "print(len(names.index))\n",
    "UMLS2names = {}\n",
    "for se in names.index:\n",
    "    UMLS2names[names.loc[se,'UMLS']] = names.loc[se,'name']\n",
    "# Verify numbers\n",
    "print(len(umls2meddra))\n",
    "print(len(meddra2umls))\n",
    "print(len(UMLS2names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that translates UMLS CUIs to name\n",
    "names = map_se[map_se['kind'].str.match('PT',na=False)].reset_index(drop=True)\n",
    "print(len(names.index))\n",
    "UMLS2names = {}\n",
    "for se in names.index:\n",
    "    UMLS2names[names.loc[se,'UMLS']] = names.loc[se,'name']\n",
    "print(len(UMLS2names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for i in DF['condition_meddra_id']:\n",
    "    ids.append(meddra2umls[i])\n",
    "DF['Condition'] = ids\n",
    "DF = DF.drop(columns=['condition_meddra_id'])\n",
    "name_list = []\n",
    "for i in DF['Condition']:\n",
    "    name_list.append(UMLS2names[i])\n",
    "DF['Condition_name'] = name_list\n",
    "DF = DF.drop(columns=['condition_concept_name'])\n",
    "DF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_drug = pd.read_csv('../Thesis_datasets/SIDER/drug_names.tsv',sep = '\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing fixed unigram candidate sampler found in optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "a = [7,0,20,8,33,9]\n",
    "labels = tf.reshape(tf.constant(a,dtype=tf.int64),[6,1])\n",
    "sampled_ids, true_expected_count, sampled_expected_count = tf.nn.fixed_unigram_candidate_sampler(\n",
    "   true_classes = labels,\n",
    "   num_true = 1,\n",
    "   num_sampled = 20,\n",
    "   unique = False,\n",
    "   range_max = np.shape(a)[0],\n",
    "   unigrams = [ 10, 10, 10, 10, 50, 10 ]\n",
    ")\n",
    "sample = tf.gather( labels, sampled_ids )\n",
    "print(sess.run( true_expected_count ))\n",
    "print(sess.run( sampled_ids ))\n",
    "print(sess.run( sampled_expected_count ))\n",
    "print(sess.run( sample ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = 'data/data_structures/DECAGON/DECAGON_real_affinities_genes_16814_drugs_276_se_7'\n",
    "with open(in_file, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mats_orig[1,0][0].todense().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../Thesis_datasets/DrugBank/drugbank_all_full_database.xml/full database.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
