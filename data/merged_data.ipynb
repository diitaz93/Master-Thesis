{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged data\n",
    "Loads the bdm data calculated in the different servers and saves it in a single file to be loaded by the deep learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "The final version can receive as parameter the filename of the data shelf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing of toy data\n",
    "Run the following cell if the desired dataset is the toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddi_adj_list Imported successfully\n",
      "ddi_degrees_list Imported successfully\n",
      "dti_adj Imported successfully\n",
      "ppi_adj Imported successfully\n",
      "ppi_degrees Imported successfully\n",
      "drug_feat Imported successfully\n",
      "prot_feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "filename = './data_structures/DS_toy_genes16271_drugs639_se664'\n",
    "with open(filename, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")\n",
    "drug_feat = drug_feat.todense()\n",
    "prot_feat = prot_feat.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing of real data\n",
    "Run the following cell if the desired dataset is the real dataset from DECAGON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = './data_structures/DS_real_DSE_NPF_genes16271_drugs639_se964'\n",
    "with open(filename, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDM DDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = './data_structures/DDI_BDM_se964_drugs639_juadia48'\n",
    "with open(filename, 'rb') as f:\n",
    "    ddi = pickle.load(f)\n",
    "    for key in ddi.keys():\n",
    "        globals()[key]=ddi[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PPI resources')\n",
    "print('Time:',datetime.timedelta(seconds=time_ddi),'in',jobs_ddi,'cores')\n",
    "print('Virtual memory:',vms_ddi*1e-9,'GB. RSS memory:',rss_ddi*1e-9,'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation ddi-bdm feature vectors\n",
    "node_ddi = np.hstack([i.reshape(-1,1) for i in nodebdm_ddi_list])\n",
    "edge_ddi = np.hstack([i.reshape(-1,1) for i in edgebdm_ddi_list])\n",
    "to_add_bdm_ddi = np.hstack([node_ddi,edge_ddi])\n",
    "#verif\n",
    "print(to_add_bdm_ddi.shape,type(to_add_bdm_ddi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDM DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este archivo tiene los nombres de genes y drugs cambiados\n",
    "filename = './data_structures/DTI_BDM_genes16271_drugs639_juadia16'\n",
    "with open(filename, 'rb') as f:\n",
    "    dti = pickle.load(f)\n",
    "    for key in dti.keys():\n",
    "        globals()[key]=dti[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DTI resources')\n",
    "print('Time:',datetime.timedelta(seconds=time_dti),'in',jobs_dti,'cores')\n",
    "print('Virtual memory:',vms_dti*1e-9,'GB. RSS memory:',rss_dti*1e-9,'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking into account that the arrays were saved with the wrong names\n",
    "to_add_bdm_genes_dti = np.hstack([nodebdm_drugs_dti.reshape(-1,1),\n",
    "                                  edgebdm_drugs_dti.reshape(-1,1)])\n",
    "to_add_bdm_drugs_dti = np.hstack([nodebdm_genes_dti.reshape(-1,1),\n",
    "                                  edgebdm_genes_dti.reshape(-1,1)])\n",
    "#verif\n",
    "print(np.shape(to_add_bdm_genes_dti),type(to_add_bdm_genes_dti))\n",
    "print(np.shape(to_add_bdm_drugs_dti),type(to_add_bdm_drugs_dti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDM PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data_structures/PPI_BDM_genes16271_juadia48'\n",
    "with open(filename, 'rb') as f:\n",
    "    ppi = pickle.load(f)\n",
    "    for key in ppi.keys():\n",
    "        globals()[key]=ppi[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PPI resources')\n",
    "print('Time:',datetime.timedelta(seconds=time_ppi),'in',jobs_ppi,'cores')\n",
    "print('Virtual memory:',vms_ppi*1e-9,'GB. RSS memory:',rss_ppi*1e-9,'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add_bdm_ppi = np.hstack([nodebdm_ppi.reshape(-1,1),edgebdm_ppi.reshape(-1,1)])\n",
    "#verif\n",
    "print(np.shape(to_add_bdm_ppi),type(to_add_bdm_ppi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein Features\n",
    "prot_feat = np.hstack([prot_feat.todense(),to_add_bdm_genes_dti,to_add_bdm_ppi])\n",
    "#verif\n",
    "print(prot_feat.shape,type(prot_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Protein features\n",
    "norm_prot_feat = np.hstack([norm_prot_feat.todense(),to_add_bdm_genes_dti,to_add_bdm_ppi])\n",
    "print(norm_prot_feat.shape,type(norm_prot_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug features\n",
    "drug_feat = np.asarray(np.hstack([drug_feat.todense(),to_add_bdm_drugs_dti,to_add_bdm_ddi]))\n",
    "#verif\n",
    "print(drug_feat.shape, type(drug_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matrix processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16269 16269 630 630\n"
     ]
    }
   ],
   "source": [
    "# Drugs\n",
    "drug_nonzero_feat, drug_num_feat = 2*[drug_feat.shape[1]]\n",
    "drug_feat = sparse_to_tuple(sp.coo_matrix(drug_feat))\n",
    "# Use proteins\n",
    "gene_nonzero_feat, gene_num_feat = 2*[prot_feat.shape[1]]\n",
    "gene_feat = sparse_to_tuple(sp.coo_matrix(prot_feat))\n",
    "# Use normalized proteins\n",
    "#gene_nonzero_feat, gene_num_feat = 2*[norm_prot_feat.shape[1]]\n",
    "#gene_feat = sparse_to_tuple(sp.coo_matrix(norm_prot_feat))\n",
    "#verif\n",
    "print(gene_nonzero_feat,gene_num_feat,drug_nonzero_feat,drug_num_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Decagon dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mats_orig = {\n",
    "    (0, 0): [ppi_adj, ppi_adj.transpose(copy=True)],\n",
    "    (0, 1): [dti_adj],\n",
    "    (1, 0): [dti_adj.transpose(copy=True)],\n",
    "    (1, 1): ddi_adj_list + [x.transpose(copy=True) for x in ddi_adj_list],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = {\n",
    "    0: [ppi_degrees, ppi_degrees],\n",
    "    1: ddi_degrees_list + ddi_degrees_list, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type2decoder = {\n",
    "    (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types: 16\n"
     ]
    }
   ],
   "source": [
    "num_edge_types = sum(list(edge_types.values()))\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: drug_num_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: drug_nonzero_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: drug_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data_structures/DECAGON_toy_red'\n",
    "#filename = './data_structures/DECAGON_real_DSE_NPF_BDM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structures = {}\n",
    "# Graph data structures\n",
    "data_structures['adj_mats_orig'] = adj_mats_orig\n",
    "data_structures['degrees'] = degrees\n",
    "data_structures['edge_type2dim'] = edge_type2dim\n",
    "data_structures['edge_type2decoder'] = edge_type2decoder\n",
    "data_structures['edge_types'] = edge_types\n",
    "data_structures['num_edge_types'] = num_edge_types\n",
    "# Feature data structures\n",
    "data_structures['num_feat'] = num_feat\n",
    "data_structures['nonzero_feat'] = nonzero_feat\n",
    "data_structures['feat'] = feat\n",
    "# Dictionaries\n",
    "#data_structures['gene2idx'] = gene2idx\n",
    "#data_structures['drug2idx'] = drug2idx\n",
    "#data_structures['se_mono_name2idx'] = se_mono_name2idx\n",
    "#data_structures['se_combo_name2idx'] = se_combo_name2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(data_structures, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
