{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chop network with BDM\n",
    "Takes the data structures of a network and calculates BDM of the PPI matrix. Discards a given fraction of the edges and updates the DS file with the new ppi matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "from pybdm import BDM\n",
    "from pybdm.utils import decompose_dataset\n",
    "from pybdm.partitions import PartitionIgnore\n",
    "from pybdm.partitions import PartitionRecursive\n",
    "from algorithms import PerturbationExperiment, NodePerturbationExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = 'data_structures/DS/DS_toy_DSE_600_genes_500_drugs_400_se_4'\n",
    "# Fraction of edges to be discarded\n",
    "cut_frac = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for sparse matrices of DECAGON (only for option 2)\n",
    "# Call it from another file better??\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "se_mono_name2idx Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "ddi_adj_list Imported successfully\n",
      "ddi_degrees_list Imported successfully\n",
      "dti_adj Imported successfully\n",
      "ppi_adj Imported successfully\n",
      "ppi_degrees Imported successfully\n",
      "drug_feat Imported successfully\n",
      "prot_feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import original Data structures\n",
    "with open(in_file,'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")\n",
    "old_genes = len(gene2idx)\n",
    "old_drugs = len(drug2idx)\n",
    "old_se_combo = len(se_combo_name2idx)\n",
    "old_se_mono = len(se_mono_name2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_mat = ppi_adj.todense() # High memory requirement for big matrices\n",
    "# Calculate algorithmic complexity\n",
    "bdm = BDM(ndim=2, partition=PartitionRecursive)\n",
    "ppi_per = PerturbationExperiment(bdm,metric='bdm',bipartite_network=False)\n",
    "ppi_per.set_data(np.array(ppi_mat))\n",
    "edge_complexity = ppi_per.run()\n",
    "# Reshape to the adj matrix shape\n",
    "complexity_mat = edge_complexity.reshape(np.shape(ppi_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero entries before 615\n",
      "Nonzero entries after 360\n",
      "Is it symmetric? True\n"
     ]
    }
   ],
   "source": [
    "# OPTION 1: USE ELEMENTWISE MULT TO FORM DENSE MATRIX \n",
    "eps = 0.0001 # The addition of this value makes the number of nonzero to coincide\n",
    "# Elementwise multiplication\n",
    "true_cmplx = np.multiply(ppi_mat,complexity_mat+eps)\n",
    "# Take abs and sort from largest to smallest\n",
    "cmplx = np.squeeze(np.asarray(np.abs(true_cmplx[true_cmplx != 0])))\n",
    "sorted_cmplx = np.sort(cmplx)[::-1]\n",
    "# Get the cutting treshold based on the cutting fraction of data\n",
    "l = len(sorted_cmplx)\n",
    "threshold = sorted_cmplx[np.floor(l*(1-cut_frac)).astype(int)]\n",
    "# Choose the entries that exceed the threshold, discard the rest\n",
    "new_ppi_adj = (np.abs(true_cmplx)>threshold).astype(int)\n",
    "print('Nonzero entries before',np.count_nonzero(true_cmplx))\n",
    "print('Nonzero entries after',np.count_nonzero(new_ppi_adj))\n",
    "print('Is it symmetric?',np.array_equal(new_ppi_adj,new_ppi_adj.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: USE INDICES TO FORM SPARSE MATRIX (FAILS!, THE MATRIX IS NOT NECESSARLY SYMMETRIC)\n",
    "# Get coordinates and complexities of positive edges\n",
    "coords,_,_ = sparse_to_tuple(ppi_adj)\n",
    "l= np.shape(coords)[0]\n",
    "true_cmplx = np.abs(complexity_mat[coords[:,0],coords[:,1]].reshape(l,1))\n",
    "# Use dummy column to keep track of indices\n",
    "a = np.concatenate((np.abs(true_cmplx),np.arange(l).reshape(l,1)),axis=1)\n",
    "sorted_values = a[a[:,0].argsort()[::-1]]\n",
    "# Discard the lowest complexity edges\n",
    "remain = np.arange(np.floor(l*(1-cut_frac)),dtype=int)\n",
    "new_values = sorted_values[remain,:]\n",
    "indices = new_values[:,1].astype(int)\n",
    "new_coords = coords[indices,:]\n",
    "new_l = np.shape(new_coords)[0]\n",
    "# New adjacency matrix (sparse)\n",
    "new_ppi_adj = sp.csr_matrix((np.ones(new_l), (new_coords[:,0], new_coords[:,1])),\\\n",
    "                            shape=np.shape(ppi_adj))\n",
    "print(np.array_equal(new_ppi_adj.todense(),new_ppi_adj.todense().T))\n",
    "print(np.count_nonzero(new_ppi_adj.todense()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove genes and drugs that may have become disconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero rows/columns in ppi 253\n",
      "New shape ppi (247, 247)\n",
      "New shape of DTI (247, 400)\n",
      "Number of disconnected drugs 255\n",
      "Number of side effects without drug 0\n"
     ]
    }
   ],
   "source": [
    "# Find rows of zeros (indices)\n",
    "genes_zero = np.where(~new_ppi_adj.any(axis=1))[0]\n",
    "print('Number of zero rows/columns in PPI matrix: ',len(genes_zero))\n",
    "# If there are\n",
    "if len(genes_zero)>0:\n",
    "    #### PPI ####\n",
    "    # Delete those rows and columns\n",
    "    new_ppi_adj = np.delete(np.delete(new_ppi_adj,genes_zero,axis=1),genes_zero,axis=0)\n",
    "    print('New shape PPI matrix: ',np.shape(new_ppi_adj))\n",
    "     # Update index dictionary\n",
    "    gene_dict = {key:val for key, val in gene2idx.items() if val not in genes_zero}\n",
    "    gene2idx = {gene:i for i, gene in enumerate(gene_dict.keys())}\n",
    "    # Update degree list\n",
    "    new_ppi_degrees = np.array(new_ppi_adj.sum(axis=0).astype(int)).squeeze()\n",
    "    #### DTI ####\n",
    "    # Deletes the corresponding rows in DTI\n",
    "    new_dti_adj = dti_adj.todense()\n",
    "    new_dti_adj = np.delete(new_dti_adj,genes_zero,axis=0)\n",
    "    print('New shape of DTI matrix: ',np.shape(new_dti_adj))\n",
    "    #### DRUGS ####\n",
    "    # Finds drugs that became disconnected from network (indices)\n",
    "    drugs_zero = np.where(~new_dti_adj.any(axis=0))[1]\n",
    "    print('Number of disconnected drugs: ',len(drugs_zero))\n",
    "    if len(drugs_zero)>0:\n",
    "        # Remove drugs from DTI matrix\n",
    "        new_dti_adj = np.delete(new_dti_adj,drugs_zero,axis=1)\n",
    "        # Remove drugs from drug feature matrix\n",
    "        new_drug_feat = drug_feat.todense()\n",
    "        new_drug_feat = np.delete(new_drug_feat,drugs_zero,axis=0)\n",
    "        # Find drug side effects that have no drug\n",
    "        mono_zero = np.where(~new_drug_feat.any(axis=1))[1]\n",
    "        print('Number of side effects without drug: ',len(mono_zero))\n",
    "        if len(mono_zero)>0:\n",
    "            # Remove them from drug feature matrix\n",
    "            new_drug_feat = np.delete(new_drug_feat,mono_zero,axis=1)\n",
    "            # Update index dictionary\n",
    "            mono_dict = {key:val for key,val in se_mono_name2idx.keys() if val not in mono_zero}\n",
    "            se_mono_name2idx = {se: i for i, se in enumerate(mono_dict.keys())}\n",
    "        #### DDI ####\n",
    "        # Remove drugs from adjacency matrices\n",
    "        new_ddi_degrees_list = []\n",
    "        new_ddi_adj_list = []\n",
    "        for i in ddi_adj_list:\n",
    "            # Remove drugs from DDI matrices\n",
    "            ddi_mat = np.delete(np.delete(i.todense(),drugs_zero,axis=0),\\\n",
    "                                        drugs_zero,axis=1)\n",
    "            new_ddi_adj_list.append(sp.csr_matrix(ddi_mat))\n",
    "            # Update degree list\n",
    "            new_ddi_degrees_list.append(np.array(ddi_mat.sum(axis=0)).squeeze())\n",
    "        # Update index dictionary\n",
    "        drug_dict = {key:val for key, val in drug2idx.items() if val not in drugs_zero}\n",
    "        drug2idx = {drug: i for i, drug in enumerate(drug_dict.keys())}\n",
    "        print('New size of DDI matrices: ',np.shape(new_ddi_adj_list[0]))\n",
    "else:\n",
    "    print('No further modifications to the matrices are needed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247 145 4 600\n"
     ]
    }
   ],
   "source": [
    "n_genes = len(gene2idx)\n",
    "n_drugs = len(drug2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)\n",
    "print('Previous number of genes: ',old_genes)\n",
    "print('New number of genes: ',n_genes)\n",
    "print('Previous number of drugs: ',old_drugs)\n",
    "print('New number of drugs: ',n_drugs)\n",
    "print('Previous number of joint side effects: ',old_se_combo)\n",
    "print('New number of joint side effects: ',n_se_combo)\n",
    "print('Previous number of single side effects: ',old_se_mono)\n",
    "print('New number of single sige effects: ',n_se_mono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "# Dictionaries\n",
    "data['gene2idx'] = gene2idx\n",
    "data['drug2idx'] = drug2idx\n",
    "data['se_mono_name2idx'] = se_mono_name2idx\n",
    "data['se_combo_name2idx'] = se_combo_name2idx\n",
    "# DDI\n",
    "data['ddi_adj_list'] = new_ddi_adj_list\n",
    "data['ddi_degrees_list'] = new_ddi_degrees_list\n",
    "# DTI\n",
    "data['dti_adj'] = new_dti_adj\n",
    "# PPI\n",
    "data['ppi_adj'] = new_ppi_adj\n",
    "data['ppi_degrees'] = new_ppi_degrees\n",
    "# DSE\n",
    "data['drug_feat'] = new_drug_feat\n",
    "# BDM\n",
    "data['ppi_edge_bdm'] = edge_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_structures/CHOP/DS_toy_cutfrac_0.25_DSE_600_genes_247_drugs_145_se_4\n"
     ]
    }
   ],
   "source": [
    "# SAVING\n",
    "out_file = 'data_structures/CHOP/DS_' + sim_type + '_cutfrac_'+str(cut_frac) +\\\n",
    "        '_DSE_' + str(n_se_mono) + '_genes_' +str(n_genes) + '_drugs_' + str(n_drugs) +\\\n",
    "        '_se_' + str(n_se_combo)\n",
    "print(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_file,'wb') as f:\n",
    "    pickle.dump(new_ppi_adj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
