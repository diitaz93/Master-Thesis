{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected data structures\n",
    "Creates a file with DECAGON data structures of any size, taking the matrices calculated for the complete dataset. The code selects the parts of the matrices calculated for the complete dataset and assembles data structures for a given subset of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_file = './data_structures/DS/DS_toy_DSE_9688_PF_5_genes_16266_drugs_627_se_6'\n",
    "prot_status = None # can be 'PF', 'NPF' or None\n",
    "DSE = True\n",
    "BDM = True\n",
    "# Generate BDM filenames\n",
    "if BDM:\n",
    "    PPI_file = './data_structures/BDM/PPI_BDM_toy_genes_16271_juadia48'\n",
    "    DTI_file = './data_structures/BDM/DTI_BDM_toy_genes_16271_drugs_639_juadia8'\n",
    "    DDI_file = './data_structures/BDM/DDI_BDM_toy_se_964_drugs_639_juadia48'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel initialization\n",
    "PF = False\n",
    "NPF = False\n",
    "toy = False\n",
    "red = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data', 'structures/DS/DS', 'toy', 'DSE', '9688', 'PF', '5', 'genes', '16266', 'drugs', '627', 'se', '6']\n"
     ]
    }
   ],
   "source": [
    "# Name import and decomposition\n",
    "words = input_file.split('_')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterimes the valuye of toy\n",
    "if 'toy' in words:\n",
    "    toy=True\n",
    "# Protein sentinel update\n",
    "if prot_status == 'NPF':\n",
    "    NPF=True\n",
    "elif prot_status == 'PF':\n",
    "    PF=True\n",
    "if toy and NPF:\n",
    "    raise ValueError(\"Toy model does not have normalized protein features\") \n",
    "if int(words[-1]) < 964:\n",
    "    red = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_structures/DS/DS_toy_DSE_9702_PF_5_genes_16271_drugs_639_se_964\n"
     ]
    }
   ],
   "source": [
    "# Generate full filename if reduced, otherwise use given filename\n",
    "if red:\n",
    "    words [4] = '9702'\n",
    "    words [-5] = '16271'\n",
    "    words [-3] = '639'\n",
    "    words [-1] = '964'\n",
    "    filename_full = '_'.join(words)\n",
    "else: filename_full = input_file\n",
    "print(filename_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "se_mono_name2idx Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "ddi_adj_list Imported successfully\n",
      "ddi_degrees_list Imported successfully\n",
      "dti_adj Imported successfully\n",
      "ppi_adj Imported successfully\n",
      "ppi_degrees Imported successfully\n",
      "drug_feat Imported successfully\n",
      "prot_feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import full dataset\n",
    "with open(filename_full, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "se_mono_name2idx Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "ddi_adj_list Imported successfully\n",
      "ddi_degrees_list Imported successfully\n",
      "dti_adj Imported successfully\n",
      "ppi_adj Imported successfully\n",
      "ppi_degrees Imported successfully\n",
      "drug_feat Imported successfully\n",
      "prot_feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Change names of loaded datasets to avoid overwritting when loading reduced dataset\n",
    "if red:\n",
    "    ddi_adj_listcmp = ddi_adj_list\n",
    "    ddi_degrees_listcmp = ddi_degrees_list\n",
    "    dti_adjcmp = dti_adj\n",
    "    ppi_adjcmp = ppi_adj\n",
    "    ppi_degreescmp = ppi_degrees\n",
    "    drug_featcmp = drug_feat\n",
    "    gene2idxcmp = gene2idx\n",
    "    drug2idxcmp = drug2idx\n",
    "    se_mono_name2idxcmp = se_mono_name2idx\n",
    "    se_combo_name2idxcmp = se_combo_name2idx\n",
    "    prot_featcmp = prot_feat\n",
    "    if not toy: norm_prot_featcmp = norm_prot_feat\n",
    "    with open(input_file, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    # New dictionaries\n",
    "    gene2idx = { gene: gene2idxcmp[gene] for gene in gene2idx}\n",
    "    \n",
    "    drug2idx = { drug: drug2idxcmp[drug] for drug in drug2idx}\n",
    "    \n",
    "    se_mono_name2idx = { sem: se_mono_name2idxcmp[sem] for sem in se_mono_name2idx}\n",
    "    se_combo_name2idx = { sec: se_combo_name2idxcmp[sec] for sec in se_combo_name2idx}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_genes = list(gene2idx.values())\n",
    "idx_drugs = list(drug2idx.values())\n",
    "idx_se = list(se_combo_name2idx.values())\n",
    "n_drugs = len(drug2idx)\n",
    "n_genes = len(gene2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No feature case\n",
    "if prot_status==None:\n",
    "    prot_feat = sp.identity(n_genes)\n",
    "if not DSE:\n",
    "    drug_feat = sp.identity(n_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodebdm_ppi Imported successfully\n",
      "add_edgebdm_ppi Imported successfully\n",
      "rem_edgebdm_ppi Imported successfully\n",
      "vms_ppi Imported successfully\n",
      "rss_ppi Imported successfully\n",
      "time_ppi Imported successfully\n",
      "jobs_ppi Imported successfully\n",
      "(16266, 3)\n",
      "nodebdm_drugs_dti Imported successfully\n",
      "nodebdm_genes_dti Imported successfully\n",
      "add_edgebdm_drugs_dti Imported successfully\n",
      "add_edgebdm_genes_dti Imported successfully\n",
      "rem_edgebdm_drugs_dti Imported successfully\n",
      "rem_edgebdm_genes_dti Imported successfully\n",
      "vms_dti Imported successfully\n",
      "rss_dti Imported successfully\n",
      "time_dti Imported successfully\n",
      "jobs_dti Imported successfully\n",
      "Dimension checking\n",
      "Should be ~16k,3 (16266, 3)\n",
      "Should be ~630,3 (627, 3)\n",
      "nodebdm_ddi_list Imported successfully\n",
      "add_edgebdm_ddi_list Imported successfully\n",
      "rem_edgebdm_ddi_list Imported successfully\n",
      "vms_ddi Imported successfully\n",
      "rss_ddi Imported successfully\n",
      "time_ddi Imported successfully\n",
      "jobs_ddi Imported successfully\n",
      "(627, 18)\n"
     ]
    }
   ],
   "source": [
    "if BDM:\n",
    "    # PPI BDM dataset import\n",
    "    with open(PPI_file, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    nodebdm_ppi = nodebdm_ppi[idx_genes]\n",
    "    add_edgebdm_ppi = add_edgebdm_ppi[idx_genes]\n",
    "    rem_edgebdm_ppi = rem_edgebdm_ppi[idx_genes]\n",
    "    to_add_bdm_ppi = np.hstack([nodebdm_ppi.reshape(-1,1),add_edgebdm_ppi.reshape(-1,1),\n",
    "                                rem_edgebdm_ppi.reshape(-1,1)])\n",
    "    print(np.shape(to_add_bdm_ppi))\n",
    "    # DTI BDM dataset import\n",
    "    with open(DTI_file, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    nodebdm_drugs_dti = nodebdm_drugs_dti[idx_drugs]\n",
    "    nodebdm_genes_dti = nodebdm_genes_dti[idx_genes]\n",
    "    add_edgebdm_drugs_dti = add_edgebdm_drugs_dti[idx_drugs]\n",
    "    add_edgebdm_genes_dti = add_edgebdm_genes_dti[idx_genes]\n",
    "    rem_edgebdm_drugs_dti = rem_edgebdm_drugs_dti[idx_drugs]\n",
    "    rem_edgebdm_genes_dti = rem_edgebdm_genes_dti[idx_genes]\n",
    "    to_add_bdm_drugs_dti = np.hstack([nodebdm_drugs_dti.reshape(-1,1),\n",
    "                                      add_edgebdm_drugs_dti.reshape(-1,1),\n",
    "                                      rem_edgebdm_drugs_dti.reshape(-1,1)])\n",
    "    to_add_bdm_genes_dti = np.hstack([nodebdm_genes_dti.reshape(-1,1),\n",
    "                                      add_edgebdm_genes_dti.reshape(-1,1),\n",
    "                                      rem_edgebdm_genes_dti.reshape(-1,1)])\n",
    "    #verif\n",
    "    print('Dimension checking')\n",
    "    print('Should be ~16k,3',np.shape(to_add_bdm_genes_dti))\n",
    "    print('Should be ~630,3',np.shape(to_add_bdm_drugs_dti))\n",
    "    # DDI BDM dataset import\n",
    "    with open(DDI_file, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    nodebdm_ddi_list = [nodebdm_ddi_list[i][idx_drugs] for i in idx_se]\n",
    "    add_edgebdm_ddi_list = [add_edgebdm_ddi_list[i][idx_drugs] for i in idx_se]\n",
    "    rem_edgebdm_ddi_list = [rem_edgebdm_ddi_list[i][idx_drugs] for i in idx_se]\n",
    "    node_ddi = np.hstack([i.reshape(-1,1) for i in nodebdm_ddi_list])\n",
    "    add_edge_ddi = np.hstack([i.reshape(-1,1) for i in add_edgebdm_ddi_list])\n",
    "    rem_edge_ddi = np.hstack([i.reshape(-1,1) for i in rem_edgebdm_ddi_list])\n",
    "    to_add_bdm_ddi = np.hstack([node_ddi,add_edge_ddi,rem_edge_ddi])\n",
    "    print(np.shape(to_add_bdm_ddi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9709)\n",
      "(16266, 6)\n"
     ]
    }
   ],
   "source": [
    "# Protein Features\n",
    "if BDM:\n",
    "    if PF:\n",
    "        prot_feat = np.hstack([prot_feat.todense(),to_add_bdm_genes_dti,to_add_bdm_ppi])\n",
    "    # Normalized Protein features\n",
    "    elif NPF:\n",
    "        prot_feat = np.hstack([norm_prot_feat.todense(),to_add_bdm_genes_dti,to_add_bdm_ppi])\n",
    "    else:\n",
    "        prot_feat = np.hstack([to_add_bdm_genes_dti,to_add_bdm_ppi])\n",
    "    # Drug features\n",
    "    if DSE:\n",
    "        drug_feat = np.asarray(np.hstack([drug_feat.todense(),\n",
    "                                          to_add_bdm_drugs_dti,to_add_bdm_ddi]))\n",
    "    else:\n",
    "        drug_feat = np.hstack([to_add_bdm_drugs_dti,to_add_bdm_ddi])\n",
    "print(np.shape(drug_feat))\n",
    "print(np.shape(prot_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matrix processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug features\n",
    "drug_num_feat = drug_feat.shape[1]\n",
    "drug_nonzero_feat = len(np.nonzero(drug_feat)[0])\n",
    "drug_feat = sparse_to_tuple(sp.coo_matrix(drug_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein features\n",
    "gene_num_feat = prot_feat.shape[1]\n",
    "gene_nonzero_feat = len(np.nonzero(prot_feat)[0])\n",
    "gene_feat = sparse_to_tuple(sp.coo_matrix(prot_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Decagon dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mats_orig = {\n",
    "    (0, 0): [ppi_adj, ppi_adj.transpose(copy=True)],\n",
    "    (0, 1): [dti_adj],\n",
    "    (1, 0): [dti_adj.transpose(copy=True)],\n",
    "    (1, 1): ddi_adj_list + [x.transpose(copy=True) for x in ddi_adj_list],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = {\n",
    "    0: [ppi_degrees, ppi_degrees],\n",
    "    1: ddi_degrees_list + ddi_degrees_list, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type2decoder = {\n",
    "    (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types: 16\n"
     ]
    }
   ],
   "source": [
    "num_edge_types = sum(list(edge_types.values()))\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: drug_num_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: drug_nonzero_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: drug_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types: 16\n"
     ]
    }
   ],
   "source": [
    "adj_mats_orig = {\n",
    "    (0, 0): [ppi_adj, ppi_adj.transpose(copy=True)],\n",
    "    (0, 1): [dti_adj],\n",
    "    (1, 0): [dti_adj.transpose(copy=True)],\n",
    "    (1, 1): ddi_adj_list + [x.transpose(copy=True) for x in ddi_adj_list],\n",
    "}\n",
    "\n",
    "degrees = {\n",
    "    0: [ppi_degrees, ppi_degrees],\n",
    "    1: ddi_degrees_list + ddi_degrees_list, \n",
    "}\n",
    "\n",
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}\n",
    "\n",
    "edge_type2decoder = {\n",
    "    (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "}\n",
    "\n",
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}\n",
    "\n",
    "num_edge_types = sum(list(edge_types.values()))\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)\n",
    "\n",
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: drug_num_feat,\n",
    "}\n",
    "\n",
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: drug_nonzero_feat,\n",
    "}\n",
    "\n",
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: drug_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = not toy\n",
    "data_str = toy*'_toy' + real*'_real'\n",
    "PF_str = PF*'_PF_5'+NPF*'_NPF_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_structures/DECAGON/DECAGON_toy_DSE_9688_BDM_genes_16266_drugs_627_se_6\n"
     ]
    }
   ],
   "source": [
    "filename_out = './data_structures/DECAGON/DECAGON' + data_str + DSE*('_DSE_'+str(n_se_mono)) +\\\n",
    "PF_str + BDM*'_BDM' + '_genes_' + str(n_genes) + '_drugs_' + str(n_drugs) + '_se_' +\\\n",
    "str(n_se_combo)\n",
    "print(filename_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structures = {}\n",
    "# Graph data structures\n",
    "data_structures['adj_mats_orig'] = adj_mats_orig\n",
    "data_structures['degrees'] = degrees\n",
    "data_structures['edge_type2dim'] = edge_type2dim\n",
    "data_structures['edge_type2decoder'] = edge_type2decoder\n",
    "data_structures['edge_types'] = edge_types\n",
    "data_structures['num_edge_types'] = num_edge_types\n",
    "# Feature data structures\n",
    "data_structures['num_feat'] = num_feat\n",
    "data_structures['nonzero_feat'] = nonzero_feat\n",
    "data_structures['feat'] = feat\n",
    "# Dictionaries\n",
    "data_structures['gene2idx'] = gene2idx\n",
    "data_structures['drug2idx'] = drug2idx\n",
    "data_structures['se_mono_name2idx'] = se_mono_name2idx\n",
    "data_structures['se_combo_name2idx'] = se_combo_name2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename_out, 'wb') as f:\n",
    "    pickle.dump(data_structures, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
