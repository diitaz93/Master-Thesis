{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected data structures\n",
    "Creates a file with DECAGON data structures of any size, taking the matrices calculated for the complete dataset. The code selects the parts of the matrices calculated for the complete dataset and assembles data structures for a given subset of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_file = './data_structures/DS/DS_real_DSE_9079_genes_16665_drugs_362_se_7'\n",
    "prot_status = None # can be 'PF', 'NPF' or None\n",
    "DSE = True\n",
    "BDM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel initialization\n",
    "toy = False\n",
    "red = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data', 'structures/DS/DS', 'real', 'DSE', '9079', 'genes', '16665', 'drugs', '362', 'se', '7']\n"
     ]
    }
   ],
   "source": [
    "# Name import and decomposition\n",
    "words = input_file.split('_')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterimes the valuye of toy\n",
    "if 'toy' in words:\n",
    "    toy=True\n",
    "if int(words[-1]) < 964:\n",
    "    red = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate BDM filenames\n",
    "if BDM:\n",
    "    if toy:\n",
    "        PPI_file = './data_structures/BDM/'\n",
    "        DTI_file = './data_structures/BDM/'\n",
    "        DDI_file = './data_structures/BDM/'\n",
    "    else:\n",
    "        PPI_file = './data_structures/BDM/PPI_BINBDM_real_genes_16837'\n",
    "        DTI_file = './data_structures/BDM/DTI_BINBDM_real_genes_16837_drugs_639'\n",
    "        DDI_file = './data_structures/BDM/DDI_BINBDM_real_se_964_drugs_639'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_structures/DS/DS_real_DSE_9702_genes_19081_drugs_639_se_964\n"
     ]
    }
   ],
   "source": [
    "# Generate full filename if reduced, otherwise use given filename\n",
    "if red:\n",
    "    words [-7] = '9702'\n",
    "    words [-5] = '19081'\n",
    "    words [-3] = '639'\n",
    "    words [-1] = '964'\n",
    "    filename_full = '_'.join(words)\n",
    "else: filename_full = input_file\n",
    "print(filename_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "se_mono_name2idx Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "ddi_adj_list Imported successfully\n",
      "ddi_degrees_list Imported successfully\n",
      "dti_adj Imported successfully\n",
      "ppi_adj Imported successfully\n",
      "ppi_degrees Imported successfully\n",
      "drug_feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import full dataset\n",
    "with open(filename_full, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene2idx Imported successfully\n",
      "drug2idx Imported successfully\n",
      "se_mono_name2idx Imported successfully\n",
      "se_combo_name2idx Imported successfully\n",
      "ddi_adj_list Imported successfully\n",
      "ddi_degrees_list Imported successfully\n",
      "dti_adj Imported successfully\n",
      "ppi_adj Imported successfully\n",
      "ppi_degrees Imported successfully\n",
      "drug_feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Change names of loaded datasets to avoid overwritting when loading reduced dataset\n",
    "if red:\n",
    "    ddi_adj_listcmp = ddi_adj_list\n",
    "    ddi_degrees_listcmp = ddi_degrees_list\n",
    "    dti_adjcmp = dti_adj\n",
    "    ppi_adjcmp = ppi_adj\n",
    "    ppi_degreescmp = ppi_degrees\n",
    "    drug_featcmp = drug_feat\n",
    "    gene2idxcmp = gene2idx\n",
    "    drug2idxcmp = drug2idx\n",
    "    se_mono_name2idxcmp = se_mono_name2idx\n",
    "    se_combo_name2idxcmp = se_combo_name2idx\n",
    "    with open(input_file, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    # New dictionaries\n",
    "    gene2idx = { gene: gene2idxcmp[gene] for gene in gene2idx}\n",
    "    \n",
    "    drug2idx = { drug: drug2idxcmp[drug] for drug in drug2idx}\n",
    "    \n",
    "    se_mono_name2idx = { sem: se_mono_name2idxcmp[sem] for sem in se_mono_name2idx}\n",
    "    se_combo_name2idx = { sec: se_combo_name2idxcmp[sec] for sec in se_combo_name2idx}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_genes = list(gene2idx.values())\n",
    "idx_drugs = list(drug2idx.values())\n",
    "idx_se = list(se_combo_name2idx.values())\n",
    "n_drugs = len(drug2idx)\n",
    "n_genes = len(gene2idx)\n",
    "n_se_combo = len(se_combo_name2idx)\n",
    "n_se_mono = len(se_mono_name2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No feature case\n",
    "prot_feat = sp.identity(n_genes)\n",
    "if not DSE:\n",
    "    drug_feat = sp.identity(n_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodebdm_ppi Imported successfully\n",
      "rem_edgebdm_ppi Imported successfully\n",
      "vms_ppi Imported successfully\n",
      "rss_ppi Imported successfully\n",
      "time_ppi Imported successfully\n",
      "jobs_ppi Imported successfully\n",
      "partition_type Imported successfully\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 16839 is out of bounds for axis 0 with size 16837",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e28f3d189fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Imported successfully\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnodebdm_ppi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodebdm_ppi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_genes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#add_edgebdm_ppi = add_edgebdm_ppi[idx_genes]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrem_edgebdm_ppi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrem_edgebdm_ppi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_genes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 16839 is out of bounds for axis 0 with size 16837"
     ]
    }
   ],
   "source": [
    "if BDM:\n",
    "    # PPI BDM dataset import\n",
    "    with open(PPI_file, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    nodebdm_ppi = nodebdm_ppi[idx_genes]\n",
    "    #add_edgebdm_ppi = add_edgebdm_ppi[idx_genes]\n",
    "    rem_edgebdm_ppi = rem_edgebdm_ppi[idx_genes]\n",
    "    #to_add_bdm_ppi = np.hstack([nodebdm_ppi.reshape(-1,1),add_edgebdm_ppi.reshape(-1,1),\\\n",
    "    #                            rem_edgebdm_ppi.reshape(-1,1)])\n",
    "    to_add_bdm_ppi = np.hstack([nodebdm_ppi.reshape(-1,1),rem_edgebdm_ppi.reshape(-1,1)])\n",
    "    print(np.shape(to_add_bdm_ppi))\n",
    "    # DTI BDM dataset import\n",
    "    with open(DTI_file, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    nodebdm_drugs_dti = nodebdm_drugs_dti[idx_drugs]\n",
    "    nodebdm_genes_dti = nodebdm_genes_dti[idx_genes]\n",
    "    #add_edgebdm_drugs_dti = add_edgebdm_drugs_dti[idx_drugs]\n",
    "    #add_edgebdm_genes_dti = add_edgebdm_genes_dti[idx_genes]\n",
    "    rem_edgebdm_drugs_dti = rem_edgebdm_drugs_dti[idx_drugs]\n",
    "    rem_edgebdm_genes_dti = rem_edgebdm_genes_dti[idx_genes]\n",
    "    '''\n",
    "    to_add_bdm_drugs_dti = np.hstack([nodebdm_drugs_dti.reshape(-1,1),\\\n",
    "                                      add_edgebdm_drugs_dti.reshape(-1,1),\\\n",
    "                                      rem_edgebdm_drugs_dti.reshape(-1,1)])\n",
    "    to_add_bdm_genes_dti = np.hstack([nodebdm_genes_dti.reshape(-1,1),\\\n",
    "                                      add_edgebdm_genes_dti.reshape(-1,1),\\\n",
    "                                      rem_edgebdm_genes_dti.reshape(-1,1)])\n",
    "    '''\n",
    "    to_add_bdm_drugs_dti = np.hstack([nodebdm_drugs_dti.reshape(-1,1),\n",
    "                                      rem_edgebdm_drugs_dti.reshape(-1,1)])\n",
    "    to_add_bdm_genes_dti = np.hstack([nodebdm_genes_dti.reshape(-1,1),\n",
    "                                      rem_edgebdm_genes_dti.reshape(-1,1)])\n",
    " \n",
    "    #verif\n",
    "    print('Dimension checking')\n",
    "    print('Should be ~16k,2',np.shape(to_add_bdm_genes_dti))\n",
    "    print('Should be ~630,2',np.shape(to_add_bdm_drugs_dti))\n",
    "    # DDI BDM dataset import\n",
    "    with open(DDI_file, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    nodebdm_ddi_list = [nodebdm_ddi_list[i][idx_drugs] for i in idx_se]\n",
    "    #add_edgebdm_ddi_list = [add_edgebdm_ddi_list[i][idx_drugs] for i in idx_se]\n",
    "    rem_edgebdm_ddi_list = [rem_edgebdm_ddi_list[i][idx_drugs] for i in idx_se]\n",
    "    node_ddi = np.hstack([i.reshape(-1,1) for i in nodebdm_ddi_list])\n",
    "    #add_edge_ddi = np.hstack([i.reshape(-1,1) for i in add_edgebdm_ddi_list])\n",
    "    rem_edge_ddi = np.hstack([i.reshape(-1,1) for i in rem_edgebdm_ddi_list])\n",
    "    #to_add_bdm_ddi = np.hstack([node_ddi,add_edge_ddi,rem_edge_ddi])\n",
    "    to_add_bdm_ddi = np.hstack([node_ddi,rem_edge_ddi])\n",
    "    print(np.shape(to_add_bdm_ddi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein Features\n",
    "if BDM:\n",
    "    prot_feat = np.hstack([to_add_bdm_genes_dti,to_add_bdm_ppi])\n",
    "    # Drug features\n",
    "    if DSE:\n",
    "        drug_feat = np.asarray(np.hstack([drug_feat.todense(),\n",
    "                                          to_add_bdm_drugs_dti,to_add_bdm_ddi]))\n",
    "    else:\n",
    "        drug_feat = np.hstack([to_add_bdm_drugs_dti,to_add_bdm_ddi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Drug feature matrix',np.shape(drug_feat))\n",
    "print('Protein feature matrix',np.shape(prot_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matrix processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug features\n",
    "drug_num_feat = drug_feat.shape[1]\n",
    "drug_nonzero_feat = len(np.nonzero(drug_feat)[0])\n",
    "drug_feat = sparse_to_tuple(sp.coo_matrix(drug_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein features\n",
    "gene_num_feat = prot_feat.shape[1]\n",
    "gene_nonzero_feat = len(np.nonzero(prot_feat)[0])\n",
    "gene_feat = sparse_to_tuple(sp.coo_matrix(prot_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Decagon dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mats_orig = {\n",
    "    (0, 0): [ppi_adj],\n",
    "    (0, 1): [dti_adj],\n",
    "    (1, 0): [dti_adj.transpose(copy=True)],\n",
    "    (1, 1): ddi_adj_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = {\n",
    "    0: [ppi_degrees],\n",
    "    1: ddi_degrees_list \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type2decoder = {\n",
    "    (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_edge_types = sum(list(edge_types.values()))\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: drug_num_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: drug_nonzero_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: drug_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge2name = {\n",
    "    (0, 0): ['PPI'],\n",
    "    (0, 1): ['DTI'],\n",
    "    (1, 0): ['TDI'],\n",
    "    (1, 1): list(se_combo_name2idx.keys()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = not toy\n",
    "data_str = toy*'_toy' + real*'_real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_out = './data_structures/DECAGON/DECAGON' + data_str + DSE*('_DSE_'+str(n_se_mono)) +\\\n",
    "BDM*'_BDM' + '_genes_' + str(n_genes) + '_drugs_' + str(n_drugs) + '_se_' +\\\n",
    "str(n_se_combo)\n",
    "print(filename_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structures = {}\n",
    "# Graph data structures\n",
    "data_structures['adj_mats_orig'] = adj_mats_orig\n",
    "data_structures['degrees'] = degrees\n",
    "data_structures['edge_type2dim'] = edge_type2dim\n",
    "data_structures['edge_type2decoder'] = edge_type2decoder\n",
    "data_structures['edge_types'] = edge_types\n",
    "data_structures['num_edge_types'] = num_edge_types\n",
    "data_structures['edge2name'] = edge2name\n",
    "# Feature data structures\n",
    "data_structures['num_feat'] = num_feat\n",
    "data_structures['nonzero_feat'] = nonzero_feat\n",
    "data_structures['feat'] = feat\n",
    "# Dictionaries\n",
    "data_structures['gene2idx'] = gene2idx\n",
    "data_structures['drug2idx'] = drug2idx\n",
    "data_structures['se_mono_name2idx'] = se_mono_name2idx\n",
    "data_structures['se_combo_name2idx'] = se_combo_name2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename_out, 'wb') as f:\n",
    "    pickle.dump(data_structures, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
