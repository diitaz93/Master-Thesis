{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected data structures\n",
    "Creates a file with DECAGON data structures of a reduced dataset from the data from the original and reduced matrices, as well as from BDM complete files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "filename = './data_structures/DS_toy_genes16269_drugs630_se6'\n",
    "prot_status = None # can be 'PF', 'NPF' or None\n",
    "BDM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel initialization\n",
    "PF = False\n",
    "NPF = False\n",
    "red = False\n",
    "toy = False\n",
    "DSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data', 'structures/DS', 'toy', 'genes16269', 'drugs630', 'se6']\n"
     ]
    }
   ],
   "source": [
    "# Name import and decomposition\n",
    "words = filename.split('_')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel update\n",
    "if 'toy' in words:\n",
    "    toy=True\n",
    "if 'DSE' in words:\n",
    "    DSE=True\n",
    "if prot_status == 'NPF':\n",
    "    NPF=True\n",
    "if prot_status == 'PF':\n",
    "    PF=True\n",
    "# Number of side effects\n",
    "SE = int(words[-1][2:])\n",
    "if 964-SE > 0:\n",
    "    red = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_structures/DS_toy_genes16271_drugs639_se964\n"
     ]
    }
   ],
   "source": [
    "# Generate full filename if reduced, otherwise use given filename\n",
    "if red:\n",
    "    filename_full=''\n",
    "    for w in words[:-3]:\n",
    "        filename_full += w + '_'\n",
    "    filename_full += 'genes16271_drugs639_se964'\n",
    "else:\n",
    "    filename_full=filename\n",
    "print(filename_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_genes Imported successfully\n",
      "n_drugs Imported successfully\n",
      "n_se_combo Imported successfully\n",
      "n_se_mono Imported successfully\n",
      "ddi_adj_list Imported successfully\n",
      "ddi_degrees_list Imported successfully\n",
      "dti_adj Imported successfully\n",
      "ppi_adj Imported successfully\n",
      "ppi_degrees Imported successfully\n",
      "drug_feat Imported successfully\n",
      "prot_feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import full dataset\n",
    "with open(filename_full, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "    for key in DS.keys():\n",
    "        globals()[key]=DS[key]\n",
    "        print(key,\"Imported successfully\")\n",
    "if toy:\n",
    "    drug_feat = drug_feat.todense()\n",
    "    norm_prot_feat = prot_feat.todense()\n",
    "    prot_feat = prot_feat.todense() #Necessary?\n",
    "    gene2idx = {i:i for i in range(n_genes)}\n",
    "    drug2idx = {i:i for i in range(n_drugs)}\n",
    "    se_mono_name2idx = {i:i for i in range(n_se_mono)}\n",
    "    se_combo_name2idx = {i:i for i in range(n_se_combo)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change names if red\n",
    "if red:\n",
    "    ddi_adj_listcmp = ddi_adj_list\n",
    "    ddi_degrees_listcmp = ddi_degrees_list\n",
    "    dti_adjcmp = dti_adj\n",
    "    ppi_adjcmp = ppi_adj\n",
    "    ppi_degreescmp = ppi_degrees\n",
    "    drug_featcmp = drug_feat\n",
    "    prot_featcmp = prot_feat\n",
    "    norm_prot_featcmp = norm_prot_feat\n",
    "    gene2idxcmp = gene2idx\n",
    "    drug2idxcmp = drug2idx\n",
    "    se_mono_name2idxcmp = se_mono_name2idx\n",
    "    se_combo_name2idxcmp = se_combo_name2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_genes Imported successfully\n",
      "n_drugs Imported successfully\n",
      "n_secombo Imported successfully\n",
      "ddi_adj_list Imported successfully\n",
      "ddi_degrees_list Imported successfully\n",
      "dti_adj Imported successfully\n",
      "ppi_adj Imported successfully\n",
      "ppi_degrees Imported successfully\n",
      "drug_feat Imported successfully\n",
      "prot_feat Imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Load reduced dataset if red\n",
    "if red:\n",
    "    with open(filename, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    if toy:\n",
    "        drug_feat = drug_feat.todense()\n",
    "        norm_prot_feat = prot_feat.todense()\n",
    "        prot_feat = prot_feat.todense() #Necessary?\n",
    "        gene2idx = {i:i for i in range(n_genes)}\n",
    "        drug2idx = {i:i for i in range(n_drugs)}\n",
    "        se_mono_name2idx = {i:i for i in range(n_se_mono)}\n",
    "        se_combo_name2idx = {i:i for i in range(n_se_combo)}\n",
    "    # New dictionaries\n",
    "    gene2idx = { gene: gene2idxcmp[gene] for gene in gene2idx }\n",
    "    drug2idx = { drug: drug2idxcmp[drug] for drug in drug2idx }\n",
    "    se_mono = { sem: se_mono_name2idxcmp[sem] for sem in se_mono_name2idx }\n",
    "    se_combo = { sec: se_combo_name2idxcmp[sec] for sec in se_combo_name2idx }\n",
    "    idx_genes = list(gene2idx.values())\n",
    "    idx_drugs = list(drug2idx.values())\n",
    "    idx_se = list(se_combo.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16269"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gene2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prot_status==None:\n",
    "    prot_feat = sp.identity(n_genes)\n",
    "if not DSE:\n",
    "    drug_feat = sp.identity(n_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BDM:\n",
    "    # PPI BDM dataset import\n",
    "    filename = './data_structures/PPI_BDM_genes16271_juadia48'\n",
    "    with open(filename, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    nodebdm_ppi = nodebdm_ppi[idx_genes]\n",
    "    edgebdm_ppi = edgebdm_ppi[idx_genes]\n",
    "    to_add_bdm_ppi = np.hstack([nodebdm_ppi.reshape(-1,1),edgebdm_ppi.reshape(-1,1)])\n",
    "    # DTI BDM dataset import\n",
    "    filename = './data_structures/DTI_BDM_genes16271_drugs639_juadia16'\n",
    "    with open(filename, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    nodebdm_drugs_dti = nodebdm_drugs_dti[idx_genes]\n",
    "    nodebdm_genes_dti = nodebdm_genes_dti[idx_drugs]\n",
    "    edgebdm_drugs_dti = edgebdm_drugs_dti[idx_genes]\n",
    "    edgebdm_genes_dti = edgebdm_genes_dti[idx_drugs]\n",
    "    # Taking into account that the arrays were saved with the wrong names (Already corrected)\n",
    "    to_add_bdm_genes_dti = np.hstack([nodebdm_drugs_dti.reshape(-1,1),\n",
    "                                      edgebdm_drugs_dti.reshape(-1,1)])\n",
    "    to_add_bdm_drugs_dti = np.hstack([nodebdm_genes_dti.reshape(-1,1),\n",
    "                                      edgebdm_genes_dti.reshape(-1,1)])\n",
    "    #verif\n",
    "    print('Dimension checking')\n",
    "    print('Should be ~16k,2',np.shape(to_add_bdm_genes_dti))\n",
    "    print('Should be ~630,2',np.shape(to_add_bdm_drugs_dti))\n",
    "    # DDI BDM dataset import\n",
    "    filename = './data_structures/DDI_BDM_se964_drugs639_juadia48'\n",
    "    with open(filename, 'rb') as f:\n",
    "        DS = pickle.load(f)\n",
    "        for key in DS.keys():\n",
    "            globals()[key]=DS[key]\n",
    "            print(key,\"Imported successfully\")\n",
    "    nodebdm_ddi_list = [nodebdm_ddi_list[i][idx_drugs] for i in idx_se]\n",
    "    edgebdm_ddi_list = [edgebdm_ddi_list[i][idx_drugs] for i in idx_se]\n",
    "    node_ddi = np.hstack([i.reshape(-1,1) for i in nodebdm_ddi_list])\n",
    "    edge_ddi = np.hstack([i.reshape(-1,1) for i in edgebdm_ddi_list])\n",
    "    to_add_bdm_ddi = np.hstack([node_ddi,edge_ddi])\n",
    "    # Protein Features\n",
    "    if PF:\n",
    "        prot_feat = np.hstack([prot_feat.todense(),to_add_bdm_genes_dti,to_add_bdm_ppi])\n",
    "    # Normalized Protein features\n",
    "    elif NPF:\n",
    "        prot_feat = np.hstack([norm_prot_feat.todense(),to_add_bdm_genes_dti,to_add_bdm_ppi])\n",
    "    # Drug features\n",
    "    if DSE:\n",
    "        drug_feat = np.asarray(np.hstack([drug_feat.todense(),to_add_bdm_drugs_dti,to_add_bdm_ddi]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matrix processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug features\n",
    "drug_nonzero_feat, drug_num_feat = 2*[drug_feat.shape[1]]\n",
    "drug_feat = sparse_to_tuple(sp.coo_matrix(drug_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16271 16271 639 639\n"
     ]
    }
   ],
   "source": [
    "# Protein features\n",
    "gene_nonzero_feat, gene_num_feat = 2*[prot_feat.shape[1]]\n",
    "gene_feat = sparse_to_tuple(sp.coo_matrix(prot_feat))\n",
    "print(gene_nonzero_feat,gene_num_feat,drug_nonzero_feat,drug_num_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Decagon dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mats_orig = {\n",
    "    (0, 0): [ppi_adj, ppi_adj.transpose(copy=True)],\n",
    "    (0, 1): [dti_adj],\n",
    "    (1, 0): [dti_adj.transpose(copy=True)],\n",
    "    (1, 1): ddi_adj_list + [x.transpose(copy=True) for x in ddi_adj_list],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = {\n",
    "    0: [ppi_degrees, ppi_degrees],\n",
    "    1: ddi_degrees_list + ddi_degrees_list, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type2decoder = {\n",
    "    (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_edge_types = sum(list(edge_types.values()))\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: drug_num_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: drug_nonzero_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: drug_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mats_orig = {\n",
    "    (0, 0): [ppi_adj, ppi_adj.transpose(copy=True)],\n",
    "    (0, 1): [dti_adj],\n",
    "    (1, 0): [dti_adj.transpose(copy=True)],\n",
    "    (1, 1): ddi_adj_list + [x.transpose(copy=True) for x in ddi_adj_list],\n",
    "}\n",
    "\n",
    "degrees = {\n",
    "    0: [ppi_degrees, ppi_degrees],\n",
    "    1: ddi_degrees_list + ddi_degrees_list, \n",
    "}\n",
    "\n",
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}\n",
    "\n",
    "edge_type2decoder = {\n",
    "    (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "}\n",
    "\n",
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}\n",
    "\n",
    "num_edge_types = sum(list(edge_types.values()))\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)\n",
    "\n",
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: drug_num_feat,\n",
    "}\n",
    "\n",
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: drug_nonzero_feat,\n",
    "}\n",
    "\n",
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: drug_feat,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if toy:\n",
    "    data_str='toy_'\n",
    "else:\n",
    "    data_str='real_'\n",
    "PF_str = PF*'PF_'+NPF*'NPF_' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_out = './data_structures/DECAGON_' + data_str + red*'reduced_' + DSE*'DSE_' +\\\n",
    "PF_str + BDM*'BDM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structures = {}\n",
    "# Graph data structures\n",
    "data_structures['adj_mats_orig'] = adj_mats_orig\n",
    "data_structures['degrees'] = degrees\n",
    "data_structures['edge_type2dim'] = edge_type2dim\n",
    "data_structures['edge_type2decoder'] = edge_type2decoder\n",
    "data_structures['edge_types'] = edge_types\n",
    "data_structures['num_edge_types'] = num_edge_types\n",
    "# Feature data structures\n",
    "data_structures['num_feat'] = num_feat\n",
    "data_structures['nonzero_feat'] = nonzero_feat\n",
    "data_structures['feat'] = feat\n",
    "# Dictionaries\n",
    "data_structures['gene2idx'] = gene2idx\n",
    "data_structures['drug2idx'] = drug2idx\n",
    "data_structures['se_mono_name2idx'] = se_mono\n",
    "data_structures['se_combo_name2idx'] = se_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename_out, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(data_structures, f, protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
